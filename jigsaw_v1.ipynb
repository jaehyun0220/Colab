{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jigsaw_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun0220/Colab/blob/master/jigsaw_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwSigEpsgSCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 활용에 필요한 기본 패키지 로딩\n",
        "\n",
        "import sys #access to system parameters \n",
        "print(\"Python version: {}\". format(sys.version))\n",
        "\n",
        "import pandas as pd\n",
        "print(\"pandas version: {}\". format(pd.__version__))\n",
        "\n",
        "import sklearn #collection of machine learning algorithms\n",
        "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
        "\n",
        "import numpy as np #foundational package for scientific computing\n",
        "print(\"NumPy version: {}\". format(np.__version__))\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))\n",
        "\n",
        "import keras\n",
        "print(\"keras version: {}\".format(keras.__version__))\n",
        "\n",
        "import os\n",
        "#import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55XLlqJ1gSCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6aa30dbd-8ae6-4ae4-918e-7a6de416995c"
      },
      "source": [
        "#데이터 전처리 관련 라이브러리 로드\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "# Deep Learning Model 로드\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation \n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#HyperParameter Tuning을 위한 라이브러리 로드\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#모델 평가를 위한 라이브러리 로드\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn import model_selection\n",
        "\n",
        "#수학 & 통계 관련 라이브러리 로드\n",
        "import scipy.stats as st\n",
        "from collections import Counter\n",
        "\n",
        "#Configure Visualization Defaults\n",
        "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
        "%matplotlib inline\n",
        "mpl.style.use('ggplot')\n",
        "sns.set_style('white')\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCOcsXzdRMsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "3c91c950-94d0-4d00-bf46-a1050903b634"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNrkrsgURSBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/gdrive/My Drive/CustomClasses')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHjsksE0RSEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "71c001af-c449-44a3-c952-2557db1c5715"
      },
      "source": [
        "!ls /"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t\ttmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t\ttools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0a0\tusr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZAmJPbARSJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bfa54870-70fb-456e-cdd6-8b587e53254b"
      },
      "source": [
        "!ls /"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin  games  grte  include  lib\tlib32  local  sbin  share  src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCI-PkadRlmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "\n",
        "sc = SparkContext('local')\n",
        "spark = SparkSession(sc)\n",
        "df = spark.createDataFrame([(0, [1, 2, 5]),(1, [1, 2, 3, 5]),(2, [1, 2])], [id, items])\n",
        "\n",
        "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
        "model = fpGrowth.fit(df)\n",
        "\n",
        "# Display frequent itemsets.\t\n",
        "model.freqItemsets.show()\n",
        "\n",
        "# Display generated association rules.\t\n",
        "model.associationRules.show()\n",
        "\n",
        "# transform examines the input items against all the association rules and summarize the\t\n",
        "# consequents as prediction\n",
        "model.transform(df).show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}