{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Media_Project #3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fd533a0eeb741f283ce1f30622d9cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b1f50fb04e049d3bad0f7f5e34c85f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80bd6424f42b4762b72bb5b580ba9a82",
              "IPY_MODEL_6489f258c57b45b68cd9b63bba0877a3"
            ]
          }
        },
        "9b1f50fb04e049d3bad0f7f5e34c85f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80bd6424f42b4762b72bb5b580ba9a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6375282dca564cc3beb915ecf4c21fde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05824682484d4371a87ce6fea68fb807"
          }
        },
        "6489f258c57b45b68cd9b63bba0877a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62c70c8c7e794d35bef9cf0bf285dd02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 28/28 [00:07&lt;00:00,  4.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4821026a6924f46af19cee74160b548"
          }
        },
        "6375282dca564cc3beb915ecf4c21fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05824682484d4371a87ce6fea68fb807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62c70c8c7e794d35bef9cf0bf285dd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4821026a6924f46af19cee74160b548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57bdb97a578f4419b5a2d73760dcc6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a15623d32634046ac9776fe27f2ebc6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1fbb00951a414805aab9bf20f0b1f4c7",
              "IPY_MODEL_4258e24d90a64148ba86ce0af5f44cac"
            ]
          }
        },
        "0a15623d32634046ac9776fe27f2ebc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fbb00951a414805aab9bf20f0b1f4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6fc2d00151d4a398d4890cb863edfb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 40801,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40801,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38e93eb9597d4a82987c42a920912dd1"
          }
        },
        "4258e24d90a64148ba86ce0af5f44cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5220e9aa17354267a486c1b6b3d44604",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 40801/40801 [00:08&lt;00:00, 4986.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5283823855ef42aa825a480c19befb34"
          }
        },
        "a6fc2d00151d4a398d4890cb863edfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38e93eb9597d4a82987c42a920912dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5220e9aa17354267a486c1b6b3d44604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5283823855ef42aa825a480c19befb34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62f28daa9319473cac1f34c9b91fde15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44af62fce2734367b0bcae1a05048850",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36e9005a35dd4b8b87dc164ff566ff92",
              "IPY_MODEL_a32d8498bb2442fca48e5176199c769b"
            ]
          }
        },
        "44af62fce2734367b0bcae1a05048850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36e9005a35dd4b8b87dc164ff566ff92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e7a03e6a63a4ff4bc6b75fec3175d56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca17113a25b7467da606385bb47585b3"
          }
        },
        "a32d8498bb2442fca48e5176199c769b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f13a507d8d14b2a94ca3a409674a24d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 4/4 [26:18&lt;00:00, 394.70s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8bacad6ab1642b9aa1ed9a3e5a7219c"
          }
        },
        "2e7a03e6a63a4ff4bc6b75fec3175d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca17113a25b7467da606385bb47585b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f13a507d8d14b2a94ca3a409674a24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8bacad6ab1642b9aa1ed9a3e5a7219c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f3f530daa84484da53e6472a19fe996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_726426b98f8f45f59a2da6a2e9f0fa69",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b58bf3c8eae421ca7aaa81930c4586e",
              "IPY_MODEL_d60038be41fd49b3ae35c92c62b7c705"
            ]
          }
        },
        "726426b98f8f45f59a2da6a2e9f0fa69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b58bf3c8eae421ca7aaa81930c4586e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_852db1dbf077467fb0af494847db9edc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 922,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 922,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_681e4167e84c45fc9063eb7ae4b5e41e"
          }
        },
        "d60038be41fd49b3ae35c92c62b7c705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44fb4003718d4151840a5c67fcdbf1d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 922/922 [06:34&lt;00:00,  2.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dcc084806d44e20acefe590777280b9"
          }
        },
        "852db1dbf077467fb0af494847db9edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "681e4167e84c45fc9063eb7ae4b5e41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44fb4003718d4151840a5c67fcdbf1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dcc084806d44e20acefe590777280b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e100166320ec4376b7cf66ec1ea69ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_774dbf0005c84dba938b959e0e6693ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b85e08c7b6f74f9da742bd7633b1b6c4",
              "IPY_MODEL_767f436b4a004d6997aaeda7f258ed2c"
            ]
          }
        },
        "774dbf0005c84dba938b959e0e6693ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b85e08c7b6f74f9da742bd7633b1b6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2aaa21f7aa04a1d80264bf044671c9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 922,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 922,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_875b150a21b8490f9fdbebb620509607"
          }
        },
        "767f436b4a004d6997aaeda7f258ed2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8aa8432432154630a1e603d08d5cb4d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 922/922 [06:34&lt;00:00,  2.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed9efde6b53943f884b520594f528eae"
          }
        },
        "d2aaa21f7aa04a1d80264bf044671c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "875b150a21b8490f9fdbebb620509607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8aa8432432154630a1e603d08d5cb4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed9efde6b53943f884b520594f528eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4828f4bf8bdb435ca9b6c9ea504770ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0945aefe9f764c439417f276b6ba5544",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7b149a2f36c437e8585ee151a6c5d18",
              "IPY_MODEL_4a4b392b668044a09f6305d97143c81a"
            ]
          }
        },
        "0945aefe9f764c439417f276b6ba5544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7b149a2f36c437e8585ee151a6c5d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6dda77a1df048de9bdcaacdc891ef5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 922,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 922,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28f2e5524bcd4925b306d2d090f3f53e"
          }
        },
        "4a4b392b668044a09f6305d97143c81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca806537c9bc4995a9a2195e98269636",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 922/922 [06:34&lt;00:00,  2.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0639ecb3edd428ba7993e2c0bf7616f"
          }
        },
        "e6dda77a1df048de9bdcaacdc891ef5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28f2e5524bcd4925b306d2d090f3f53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca806537c9bc4995a9a2195e98269636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0639ecb3edd428ba7993e2c0bf7616f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8f86f52245c40edbe43cab0959aa58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc8af4035d4b46158a96638dafef099f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf58e127835a43b28a5ab101a315dda1",
              "IPY_MODEL_41993ca9902042e19aa694ff97d05418"
            ]
          }
        },
        "dc8af4035d4b46158a96638dafef099f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf58e127835a43b28a5ab101a315dda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_919d0f5ed2cb4fa5911bcd517eb1690a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 922,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 922,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebb3bf0375224df1bf25bfa65d79ad82"
          }
        },
        "41993ca9902042e19aa694ff97d05418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27bf2e6c303c4188bafb1d9382c375cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 922/922 [06:34&lt;00:00,  2.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3075f088423447ebb169e01549ba6178"
          }
        },
        "919d0f5ed2cb4fa5911bcd517eb1690a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebb3bf0375224df1bf25bfa65d79ad82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27bf2e6c303c4188bafb1d9382c375cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3075f088423447ebb169e01549ba6178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun0220/Colab/blob/master/Media_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmdavC_fLDrU",
        "colab_type": "text"
      },
      "source": [
        "#10조. 네이버 댓글 분석을 통한 상위, 하위 클립 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnLbyZflC1R1",
        "colab_type": "code",
        "outputId": "f2a70da4-bf12-430d-808e-3084c8475217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Auth 인증 및 Google Drive 활용 Data load\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5oQGfjLC-Jb",
        "colab_type": "code",
        "outputId": "fb4df752-3f3c-4794-9381-9bae1731dca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!ls ../gdrive/My\\ Drive/output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_ep10.csv\t file_ep16.csv\tfile_ep22.csv  file_ep4.csv\n",
            "file_ep11.csv\t file_ep17.csv\tfile_ep23.csv  file_ep5.csv\n",
            "file_ep12.csv\t file_ep18.csv\tfile_ep24.csv  file_ep6.csv\n",
            "file_ep13.csv\t file_ep19.csv\tfile_ep25.csv  file_ep7.csv\n",
            "file_ep14_1.csv  file_ep1.csv\tfile_ep26.csv  file_ep8.csv\n",
            "file_ep14.csv\t file_ep20.csv\tfile_ep2.csv   file_ep9.csv\n",
            "file_ep15.csv\t file_ep21.csv\tfile_ep3.csv   TheLastEmpress.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bdQCRGv7AX6",
        "colab_type": "code",
        "outputId": "aaf3032a-852b-4d86-c71b-331417b34bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip install regex"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: regex\n",
            "Successfully installed regex-2019.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEGh8u0qDI6h",
        "colab_type": "code",
        "outputId": "d3c2954a-dae4-4c8d-ee61-4d25c5ae4a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "# 기본 라이브러리 로드\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import regex as re\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터 전처리 관련 라이브러리 로드\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "#모델 알고리즘 로드\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "\n",
        "# Deep Learning Model 로드\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#차원축소 알고리즘 로드\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#HyperParameter Tuning을 위한 라이브러리 로드\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#모델 평가를 위한 라이브러리 로드\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\n",
        "\n",
        "#데이터 분리를 위한 라이브러리 로드\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#수학 & 통계 관련 라이브러리 로드\n",
        "import scipy.stats as st\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl  # 기본 설정 만지는 용도\n",
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도\n",
        "\n",
        "\n",
        "#Configure Visualization Defaults\n",
        "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
        "%matplotlib inline\n",
        "mpl.style.use('ggplot')\n",
        "sns.set_style('white')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpUzHCYqMYp1",
        "colab_type": "code",
        "outputId": "8b2236e2-18c4-426f-c322-40736723e918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "filelist = os.listdir('../gdrive/My Drive/output')\n",
        "filelist"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['file_ep1.csv',\n",
              " 'file_ep16.csv',\n",
              " 'file_ep17.csv',\n",
              " 'file_ep10.csv',\n",
              " 'file_ep14.csv',\n",
              " 'file_ep12.csv',\n",
              " 'file_ep11.csv',\n",
              " 'file_ep14_1.csv',\n",
              " 'file_ep15.csv',\n",
              " 'file_ep13.csv',\n",
              " 'file_ep18.csv',\n",
              " 'file_ep19.csv',\n",
              " 'file_ep21.csv',\n",
              " 'file_ep20.csv',\n",
              " 'file_ep2.csv',\n",
              " 'file_ep22.csv',\n",
              " 'file_ep23.csv',\n",
              " 'file_ep25.csv',\n",
              " 'file_ep24.csv',\n",
              " 'file_ep26.csv',\n",
              " 'file_ep3.csv',\n",
              " 'file_ep4.csv',\n",
              " 'file_ep5.csv',\n",
              " 'file_ep6.csv',\n",
              " 'file_ep9.csv',\n",
              " 'file_ep7.csv',\n",
              " 'TheLastEmpress.csv',\n",
              " 'file_ep8.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Ink4z2DVoG",
        "colab_type": "code",
        "outputId": "7bbef3d4-7b60-4443-9aba-1cd0ac2182b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469,
          "referenced_widgets": [
            "2fd533a0eeb741f283ce1f30622d9cff",
            "9b1f50fb04e049d3bad0f7f5e34c85f5",
            "80bd6424f42b4762b72bb5b580ba9a82",
            "6489f258c57b45b68cd9b63bba0877a3",
            "6375282dca564cc3beb915ecf4c21fde",
            "05824682484d4371a87ce6fea68fb807",
            "62c70c8c7e794d35bef9cf0bf285dd02",
            "e4821026a6924f46af19cee74160b548"
          ]
        }
      },
      "source": [
        "# 총 26회차 491개 하이라이트 클립 존재 (전체 재생수 = 107,221,654 / 클립 당 평균 재생수 = 218,374), \n",
        "# 이 중에서 예고편, 미공개, 인터뷰 등 클립 제외하고 총 422회 클립 대상\n",
        "df_title = pd.read_csv('../gdrive/My Drive/output/TheLastEmpress.csv', encoding = 'euc-kr')\n",
        "df_title.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "\n",
        "# 조회수 분포를 고려하여 각 회차별로 조회수 상위 4개, 하위 4개 클립을 샘플링 - 총 208개 클립\n",
        "# 좋아요수, 댓글 수, 댓글 내용, 댓글 작성자 정보 (웹크롤링 통한 추출)\n",
        "\n",
        "df_ep_tot = pd.DataFrame()\n",
        "for i in tqdm_notebook(filelist):\n",
        "  if (i[:4] == 'file'):\n",
        "    df_ep_temp = pd.read_csv('../gdrive/My Drive/output/'+i)\n",
        "    df_ep_temp['play'] = df_ep_temp['play'].apply(lambda x: int(re.sub(',','', x[4:])))\n",
        "    df_ep_temp['rank'] = df_ep_temp['play'].rank(method='dense', ascending=False)\n",
        "    df_ep_tot = df_ep_tot.append(df_ep_temp)\n",
        "\n",
        "df_ep_tot.drop(columns='Unnamed: 0', inplace=True)\n",
        "df_ep_tot['target'] = np.where(df_ep_tot['rank']<=4,1,0)\n",
        "df_ep_tot"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fd533a0eeb741f283ce1f30622d9cff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nick</th>\n",
              "      <th>contents</th>\n",
              "      <th>recomm</th>\n",
              "      <th>unrecomm</th>\n",
              "      <th>title</th>\n",
              "      <th>play</th>\n",
              "      <th>like</th>\n",
              "      <th>reple_count</th>\n",
              "      <th>episode</th>\n",
              "      <th>rank</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rosi****</td>\n",
              "      <td>ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>핑크에메랄드</td>\n",
              "      <td>왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>서지안</td>\n",
              "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>경</td>\n",
              "      <td>ㅏ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홍홍</td>\n",
              "      <td>이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>Major</td>\n",
              "      <td>와 ㅅㅂ...피지컬봐....</td>\n",
              "      <td>550</td>\n",
              "      <td>1</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842</th>\n",
              "      <td>스폰지밥</td>\n",
              "      <td>이쁘십니다 할때 나만설렜냐,,,,,,,</td>\n",
              "      <td>691</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1843</th>\n",
              "      <td>박한별</td>\n",
              "      <td>반했네</td>\n",
              "      <td>372</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1844</th>\n",
              "      <td>김민정</td>\n",
              "      <td>죄송하지만 이 분 이용합시다 ! 어쨌든 좋은게 좋은거죠 ..</td>\n",
              "      <td>593</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>블링블링</td>\n",
              "      <td>우빈이한테 전부 들이대는군</td>\n",
              "      <td>338</td>\n",
              "      <td>3</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40935 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          nick                                           contents  ...  rank  target\n",
              "0     rosi****  ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...  ...   1.0       1\n",
              "1       핑크에메랄드  왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...  ...   1.0       1\n",
              "2          서지안                                           ㅋㅋㅋㅋㅋㅋㅋㅋ  ...   1.0       1\n",
              "3            경                                                  ㅏ  ...   1.0       1\n",
              "4           홍홍            이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발  ...   1.0       1\n",
              "...        ...                                                ...  ...   ...     ...\n",
              "1841     Major                                    와 ㅅㅂ...피지컬봐....  ...   8.0       0\n",
              "1842      스폰지밥                              이쁘십니다 할때 나만설렜냐,,,,,,,  ...   8.0       0\n",
              "1843       박한별                                                반했네  ...   8.0       0\n",
              "1844       김민정                  죄송하지만 이 분 이용합시다 ! 어쨌든 좋은게 좋은거죠 ..  ...   8.0       0\n",
              "1845      블링블링                                     우빈이한테 전부 들이대는군  ...   8.0       0\n",
              "\n",
              "[40935 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-6DDOI-DyW_",
        "colab_type": "code",
        "outputId": "ba810e84-d933-415d-e686-355cb6b2178d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "display(df_title.head())\n",
        "display(df_title.info())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>title</th>\n",
              "      <th>play</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>[숨멎 엔딩] 신성록, 설렘 폭발하는 반전 섹시미!</td>\n",
              "      <td>892539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>장나라, 악녀 이엘리야 때려잡는 카리스마 “얻다대고 반말”</td>\n",
              "      <td>852569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>신은경 완벽 빙의한 ‘오아린 더빙 연기’</td>\n",
              "      <td>811897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>“사랑해요 폐하” 장나라, 신성록 계획 박살 내며 ‘흑화 스위치 ON’</td>\n",
              "      <td>757992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>뛰는 이엘리야 위 나는 오아린, 혼신의 눈물 연기(Feat. 윤소이 불꽃 따귀)</td>\n",
              "      <td>725808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   episode                                         title    play\n",
              "0       14                  [숨멎 엔딩] 신성록, 설렘 폭발하는 반전 섹시미!  892539\n",
              "1        8              장나라, 악녀 이엘리야 때려잡는 카리스마 “얻다대고 반말”  852569\n",
              "2       19                        신은경 완벽 빙의한 ‘오아린 더빙 연기’  811897\n",
              "3       10       “사랑해요 폐하” 장나라, 신성록 계획 박살 내며 ‘흑화 스위치 ON’  757992\n",
              "4       10  뛰는 이엘리야 위 나는 오아린, 혼신의 눈물 연기(Feat. 윤소이 불꽃 따귀)  725808"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 422 entries, 0 to 421\n",
            "Data columns (total 3 columns):\n",
            "episode    422 non-null int64\n",
            "title      422 non-null object\n",
            "play       422 non-null int64\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 10.0+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCdCQjW8D5xZ",
        "colab_type": "code",
        "outputId": "77a7c5a7-6758-4ea0-e7e0-3e7b52b0e1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "display(df_ep_tot.head())\n",
        "display(df_ep_tot.info())\n",
        "# df_ep_tot[df_ep_tot['episode'] == 1].sample(10).sort_values(by='play', ascending = False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nick</th>\n",
              "      <th>contents</th>\n",
              "      <th>recomm</th>\n",
              "      <th>unrecomm</th>\n",
              "      <th>title</th>\n",
              "      <th>play</th>\n",
              "      <th>like</th>\n",
              "      <th>reple_count</th>\n",
              "      <th>episode</th>\n",
              "      <th>rank</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rosi****</td>\n",
              "      <td>ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>핑크에메랄드</td>\n",
              "      <td>왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>서지안</td>\n",
              "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>경</td>\n",
              "      <td>ㅏ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홍홍</td>\n",
              "      <td>이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       nick                                           contents  ...  rank  target\n",
              "0  rosi****  ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...  ...   1.0       1\n",
              "1    핑크에메랄드  왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...  ...   1.0       1\n",
              "2       서지안                                           ㅋㅋㅋㅋㅋㅋㅋㅋ  ...   1.0       1\n",
              "3         경                                                  ㅏ  ...   1.0       1\n",
              "4        홍홍            이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발  ...   1.0       1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 40935 entries, 0 to 1845\n",
            "Data columns (total 11 columns):\n",
            "nick           40935 non-null object\n",
            "contents       40801 non-null object\n",
            "recomm         40935 non-null int64\n",
            "unrecomm       40935 non-null int64\n",
            "title          40935 non-null object\n",
            "play           40935 non-null int64\n",
            "like           40935 non-null object\n",
            "reple_count    40935 non-null object\n",
            "episode        40935 non-null int64\n",
            "rank           40935 non-null float64\n",
            "target         40935 non-null int64\n",
            "dtypes: float64(1), int64(5), object(5)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MxLLtPX7gN",
        "colab_type": "text"
      },
      "source": [
        "### 1화 댓글 대상 sample set test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cA7gB0gV3HF",
        "colab_type": "code",
        "outputId": "728ddc22-45c5-41be-d85b-394aa3e80c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# df_ep_sample = df_ep_tot[df_ep_tot['episode'] == 1].copy()\n",
        "df_ep_sample = df_ep_tot.copy()\n",
        "df_ep_sample.dropna(how='any', inplace=True)\n",
        "df_ep_sample.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 40801 entries, 0 to 1845\n",
            "Data columns (total 11 columns):\n",
            "nick           40801 non-null object\n",
            "contents       40801 non-null object\n",
            "recomm         40801 non-null int64\n",
            "unrecomm       40801 non-null int64\n",
            "title          40801 non-null object\n",
            "play           40801 non-null int64\n",
            "like           40801 non-null object\n",
            "reple_count    40801 non-null object\n",
            "episode        40801 non-null int64\n",
            "rank           40801 non-null float64\n",
            "target         40801 non-null int64\n",
            "dtypes: float64(1), int64(5), object(5)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52VbARCKYxHd",
        "colab_type": "code",
        "outputId": "6c976ce6-7893-4894-ca35-4f0ea73fe480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "!pip3 install konlpy"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.4MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.9MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, tweepy, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-0.7.0 beautifulsoup4-4.6.0 colorama-0.4.1 konlpy-0.5.2 tweepy-3.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qHvTttUYJQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Kkma, Okt\n",
        "from konlpy.utils import pprint\n",
        "\n",
        "okt =Okt()\n",
        "kkma = Kkma()\n",
        "# mecab = Mecab()\n",
        "# pprint(kkma.sentences(u'네, 안녕하세요. 반갑습니다.'))\n",
        "\n",
        "# sentence = u'만 6세 이하의 초등학교 취학 전 자녀를 양육하기 위해서는'\n",
        "# words = konlpy.tag.Twitter().pos(sentence)\n",
        "# print(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LzY1qM44bVrA",
        "colab": {}
      },
      "source": [
        "def morphs_okt(x):\n",
        "  res = okt.morphs(x)\n",
        "  if len(res) >= 1:\n",
        "    res = [re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) for i in range(len(res)) if re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) != '' and len(res[i]) >= 1]\n",
        "  else:\n",
        "    res = ''\n",
        "  res = '' if not res else res\n",
        "  return res\n",
        "\n",
        "def morphs_kkma(x):\n",
        "  res = kkma.morphs(x)\n",
        "  if len(res) >= 1:\n",
        "    res = [re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) for i in range(len(res)) if re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) != '' and len(res[i]) >= 1]\n",
        "  else:\n",
        "    res = ''\n",
        "  res = '' if not res else res\n",
        "  return res\n",
        "\n",
        "# def morphs_mecab(x):\n",
        "#   res = kkma.morphs(x)\n",
        "#   if len(res) > 1:\n",
        "#     res = [re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》ㅋㅡ ]', '', res[i]) for i in range(len(res)) if len(res[i]) > 1]\n",
        "#   else:\n",
        "#     res = ''\n",
        "#   return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyG91a40YN8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ep_sample['contents'] = df_ep_sample['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "# df_ep_sample['okt_token'] = df_ep_sample['contents'].apply(lambda x: morphs_okt(x))\n",
        "# df_ep_sample['kkma_token'] = df_ep_sample['contents'].apply(lambda x: morphs_kkma(x))\n",
        "# df_ep_sample['kkma_token_str'] = df_ep_sample['kkma_token'].apply(lambda x: ' '.join(x))\n",
        "# df_ep_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nYNT1D03sVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ep_sample.dropna(how='any',inplace=True)\n",
        "# df_ep_sample['okt_token_str'] = df_ep_sample['okt_token'].apply(lambda x: ' '.join(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfBFr_hYoSQ9",
        "colab_type": "code",
        "outputId": "adf36207-4b2e-426f-c8c4-f7961db0def4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "source": [
        "# df_ep_sample = df_ep_sample[df_ep_sample['okt_token'].str.len()>0]\n",
        "df_ep_sample.info()\n",
        "df_ep_sample.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 40801 entries, 0 to 1845\n",
            "Data columns (total 11 columns):\n",
            "nick           40801 non-null object\n",
            "contents       40801 non-null object\n",
            "recomm         40801 non-null int64\n",
            "unrecomm       40801 non-null int64\n",
            "title          40801 non-null object\n",
            "play           40801 non-null int64\n",
            "like           40801 non-null object\n",
            "reple_count    40801 non-null object\n",
            "episode        40801 non-null int64\n",
            "rank           40801 non-null float64\n",
            "target         40801 non-null int64\n",
            "dtypes: float64(1), int64(5), object(5)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nick</th>\n",
              "      <th>contents</th>\n",
              "      <th>recomm</th>\n",
              "      <th>unrecomm</th>\n",
              "      <th>title</th>\n",
              "      <th>play</th>\n",
              "      <th>like</th>\n",
              "      <th>reple_count</th>\n",
              "      <th>episode</th>\n",
              "      <th>rank</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rosi****</td>\n",
              "      <td>ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>핑크에메랄드</td>\n",
              "      <td>왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>서지안</td>\n",
              "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>경</td>\n",
              "      <td>ㅏ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홍홍</td>\n",
              "      <td>이게 나라냐 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       nick                                           contents  ...  rank  target\n",
              "0  rosi****  ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...  ...   1.0       1\n",
              "1    핑크에메랄드  왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...  ...   1.0       1\n",
              "2       서지안                                           ㅋㅋㅋㅋㅋㅋㅋㅋ  ...   1.0       1\n",
              "3         경                                                  ㅏ  ...   1.0       1\n",
              "4        홍홍             이게 나라냐 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발  ...   1.0       1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyS88sBUT_Tk",
        "colab_type": "text"
      },
      "source": [
        "## 공통 영역: Word Embedding을 위한 Hyper parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT_z_0uNV8fp",
        "colab_type": "code",
        "outputId": "fcc72b2f-8a4f-4672-a040-b7ce094f0e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Hyper Param setting\n",
        "\n",
        "# token의 Histogram 분포를 바탕으로 대부분의 단어 길이 cover 가능한 단어 개수 찾기\n",
        "# # 신경망 학습을 위한 input 벡터 길이로 사용 - 적정 길이는 tokenizng 이후 분포를 보고 결정(코드 하단)\n",
        "# totalLenSent = [len(x) for x in df_ep_sample['okt_token']] # 각 document의 단어 길이를 check\n",
        "# plt.hist(totalLenSent,bins = np.arange(0,max(totalLenSent),max(totalLenSent)/20))\n",
        "\n",
        "# print(np.percentile(totalLenSent, 95)) # 95%를 커버하는 수치는 41\n",
        "\n",
        "# MAX_LEN = int(np.percentile(totalLenSent, 95)) but bert는 128 embedding 사용\n",
        "MAX_LEN = 128\n",
        "print(MAX_LEN)\n",
        "\n",
        "# pre-trained Embedding을 몇 개 사용할 지 결정\n",
        "NUM_MODELS = 1\n",
        "\n",
        "# # input data 원문에서 보존할 최대 단어 개수 \n",
        "# # 전체 데이터셋에서 나타나는 unique 한 단어 수(넉넉하게 백단위 올림하여 setting)\n",
        "# from itertools import chain\n",
        "\n",
        "# sum_lists = list(chain.from_iterable(df_ep_sample['okt_token']))\n",
        "# totalCntWords = int(math.ceil(len(set(sum_lists))/100)*100)\n",
        "\n",
        "MAX_FEATURES = 37000\n",
        "# MAX_FEATURES = totalCntWords\n",
        "# print(len(set(sum_lists)), MAX_FEATURES)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwIUNatxUKw0",
        "colab_type": "text"
      },
      "source": [
        "## Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEZkCMh37IwK",
        "colab_type": "code",
        "outputId": "bb02d168-0ab9-4fdd-ff50-2bee64a43fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!pip install sacremoses sentencepiece "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 5.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 56.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.28.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=08bdc43b1390b9756395449fe1dcdac27a726f0a0cf7bebb3b6e4a87ac904741\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece\n",
            "Successfully installed sacremoses-0.0.35 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46mrhFm373Ag",
        "colab_type": "code",
        "outputId": "0488212e-6558-46de-f437-93d856ae5afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# !ls ../gdrive/My\\ Drive/data/transformers\n",
        "!ls ../gdrive/My\\ Drive/data/bert/bert-base-multilingual-cased"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert-base-multilingual-cased-vocab.txt\tbert_config.json  pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7LqtYkGG3YZ",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch 환경 내에서 BERT를 사용하기 위한 BERT 관련 Library Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW3fUFWuZoBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_PRETRAINED = \"../gdrive/My Drive/data/bert/bert-base-multilingual-cased\"\n",
        "PATH_VOCAB = \"../gdrive/My Drive/data/bert/bert-base-multilingual-cased\"\n",
        "PATH_BERT = \"../gdrive/My Drive/data/bert\"\n",
        "sys.path.append(PATH_PRETRAINED)\n",
        "sys.path.append(PATH_BERT)\n",
        "\n",
        "import sacremoses\n",
        "import sentencepiece\n",
        "\n",
        "import pickle\n",
        "import shutil\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn # for neural net\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # jupyter에서 마지막 값만 출력하는게 아니라 모든 출력값을 매번 연속적으로 출력\n",
        "InteractiveShell.ast_node_interactivity = \"all\" # all, last, last_expr, none (기본값은 'last_expr')\n",
        "\n",
        "# from transformers import convert_tf_checkpoint_to_pytorch\n",
        "from transformers import convert_bert_original_tf_checkpoint_to_pytorch\n",
        "\n",
        "# from transformers import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from transformers import BertTokenizer, AdamW, BertModel, BertPreTrainedModel, BertConfig\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "\n",
        "from transformers import BertConfig # This is the Bert configuration file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QScZ6eLIHP6m",
        "colab_type": "text"
      },
      "source": [
        "### BERT 사용 관련 Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FI7QIBsBbMX",
        "colab_type": "code",
        "outputId": "e0c60cef-b057-4c01-9599-52cabc964be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seed = 42\n",
        "MAX_SEQ_LEN = MAX_LEN # token분포 바탕으로 128 선정 (대부분의 단어 길이 cover)\n",
        "\n",
        "NUM_LABELS = len(df_ep_sample['target'].unique()) #2 If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy)\n",
        "training_epochs = 4\n",
        "lr = 2e-5\n",
        "warmup = 0.05\n",
        "batch_size = 32\n",
        "\n",
        "bert_model_config = PATH_PRETRAINED+'/bert_config.json'\n",
        "\n",
        "bert_model = 'bert-base-multilingual-cased'\n",
        "do_lower_case = 'uncased' in bert_model\n",
        "device = torch.device('cuda') # GPU 사용 setting\n",
        "\n",
        "output_model_file = 'bert_pytorch.bin'\n",
        "output_optimizer_file = 'bert_pytorch_optimizer.bin'\n",
        "# output_amp_file = 'bert_pytorch_amp.bin'\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7839849cf0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5dISpkhc1sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class BertForSequenceClassification(BertPreTrainedModel):\n",
        "#     r\"\"\"\n",
        "#         **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n",
        "#             Labels for computing the sequence classification/regression loss.\n",
        "#             Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "#             If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n",
        "#             If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n",
        "#     Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "#         **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "#             Classification (or regression if config.num_labels==1) loss.\n",
        "#         **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n",
        "#             Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
        "#         **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "#             list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "#             of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "#             Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "#         **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
        "#             list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
        "#             Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "#     Examples::\n",
        "#         tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#         model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "#         input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n",
        "#         labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
        "#         outputs = model(input_ids, labels=labels)\n",
        "#         loss, logits = outputs[:2]\n",
        "#     \"\"\"\n",
        "#     def __init__(self, config):\n",
        "#         super(BertForSequenceClassification, self).__init__(config)\n",
        "#         self.num_labels = config.num_labels\n",
        "\n",
        "#         self.bert = BertModel(config)\n",
        "#         self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "#         self.classifier = nn.Linear(config.hidden_size, self.config.num_labels-1)\n",
        "#         self.init_weights()\n",
        "\n",
        "#     def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
        "#                 position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
        "\n",
        "#         outputs = self.bert(input_ids,\n",
        "#                             attention_mask=attention_mask,\n",
        "#                             token_type_ids=token_type_ids,\n",
        "#                             position_ids=position_ids,\n",
        "#                             head_mask=head_mask,\n",
        "#                             inputs_embeds=inputs_embeds)\n",
        "\n",
        "#         pooled_output = outputs[1]\n",
        "\n",
        "#         pooled_output = self.dropout(pooled_output)\n",
        "#         logits = self.classifier(pooled_output)\n",
        "\n",
        "#         return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM54ZY3SYMGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification(BertPreTrainedModel):\n",
        "    r\"\"\"\n",
        "        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n",
        "            Labels for computing the sequence classification/regression loss.\n",
        "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "            If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n",
        "            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n",
        "    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "            Classification (or regression if config.num_labels==1) loss.\n",
        "        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n",
        "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
        "        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "            of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
        "            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "    Examples::\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
        "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
        "                position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
        "\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids,\n",
        "                            position_ids=position_ids,\n",
        "                            head_mask=head_mask,\n",
        "                            inputs_embeds=inputs_embeds)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSKjJZl_IzLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the lines to BERT format # do token-convert-to-ids\n",
        "# Thanks to https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming\n",
        "def convert_bert_token(example, max_seq_length,tokenizer):\n",
        "    max_seq_length -=2\n",
        "    all_tokens = []\n",
        "    longer = 0\n",
        "    for text in tqdm_notebook(example):\n",
        "        # print(\"text :\", text)\n",
        "        tokens_a = tokenizer.tokenize(text)\n",
        "        # print(\"tokens_a : \", tokens_a)\n",
        "        if len(tokens_a)>max_seq_length:  #token의 길이가 max_seq_length보다 길면 max_seq_length 뒤로는 잘라내고, longer 변수를 1증가 시킴\n",
        "            tokens_a = tokens_a[:max_seq_length]\n",
        "            longer += 1\n",
        "        # token의 앞 뒤에 [CLS]와 [SEP]을 추가 시키고 남는자리는 zero padding\n",
        "        # print(\"max_seq_length: \", max_seq_length, \"len(tokens_a): \", len(tokens_a), \"max_seq_length - len(tokens_a) : \", max_seq_length - len(tokens_a))\n",
        "\n",
        "        # \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+ [0] * int(max_seq_length - len(tokens_a)) # token을 vocab을 이용하여 id로 convert\n",
        "        all_tokens.append(one_token) # all_tokens에 추가\n",
        "    # print(longer)\n",
        "    return np.array(all_tokens)\n",
        "\n",
        "def create_attention_masks(sequence):\n",
        "# Create attention masks\n",
        "  attention_masks = []\n",
        "\n",
        "  # Create a mask of 1s for each token followed by 0s for padding\n",
        "  for seq in sequence:\n",
        "    # print(\"seq is \", seq)\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "  # print(attention_masks)\n",
        "  return attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yRZn7DeLoqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef3f4770-d0e3-4323-a146-b730570d309a"
      },
      "source": [
        "!ls ../gdrive/My\\ Drive/data/bert/bert-base-multilingual-cased/"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert-base-multilingual-cased-vocab.txt\tbert_config.json  pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGQSs3C29ki",
        "colab_type": "code",
        "outputId": "6957e149-a26c-4463-a83d-cd6f51eba426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231,
          "referenced_widgets": [
            "57bdb97a578f4419b5a2d73760dcc6a2",
            "0a15623d32634046ac9776fe27f2ebc6",
            "1fbb00951a414805aab9bf20f0b1f4c7",
            "4258e24d90a64148ba86ce0af5f44cac",
            "a6fc2d00151d4a398d4890cb863edfb4",
            "38e93eb9597d4a82987c42a920912dd1",
            "5220e9aa17354267a486c1b6b3d44604",
            "5283823855ef42aa825a480c19befb34"
          ]
        }
      },
      "source": [
        "# OKT로 Tokenize 한 데이터를 string으로 붙인 뒤 이를 다시 bert 형태로 tokenizing\n",
        "\n",
        "%%time\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=do_lower_case)\n",
        "# tokens_a :  ['[UNK]', '목', '##욕', '##탕', '들어', '##가는', '##거', '[UNK]', '명', '##품', '##일', '[UNK]']\n",
        "# tokens_a :  ['[UNK]', '선', '##황', '##제가', '바', '##람', '##은', '[UNK]', '같다', '##는', '생', '##각', '##이', '든', '##다', '태', '##후', '##가', '황', '##후', '##로', '있는', '##한', '감', '##히', '생', '##각', '##도', '못', '##했', '##을', '##듯']\n",
        "# tokens_a :  ['[UNK]']\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(PATH_VOCAB+'/bert-base-multilingual-cased-vocab.txt', do_lower_case=do_lower_case)\n",
        "# tokens_a :  ['옷', '입', '##고', '목', '##욕', '##탕', '들어', '##가는', '##거', '웃', '##기', '[UNK]', '저', '거', '명', '##품', '일', '텐', '##데']\n",
        "# tokens_a :  ['[UNK]', '선', '황', '##제', '가', '바', '##람', '은', '못', '[UNK]', '같다', '##는', '생', '##각', '이', '든', '##다', '태', '##후', '가', '황', '##후', '로', '있는', '##한', '감', '##히', '생', '##각', '도', '못', '했', '##을', '##듯']\n",
        "\n",
        "# train_df의 \"comment_text\"에서 na를 \"DUMMY_VALUE\"로 채우고, 최대 MAX_SEQUENCE_LENGTH 만큼 잘라냄\n",
        "# sequences = convert_bert_token(df_ep_sample[\"okt_token_str\"].fillna(\"DUMMY_VALUE\"),MAX_SEQ_LEN, tokenizer)\n",
        "sequences = convert_bert_token(df_ep_sample[\"contents\"].fillna(\"DUMMY_VALUE\"),MAX_SEQ_LEN, tokenizer)\n",
        "attention_masks = np.asarray(create_attention_masks(sequences))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpvc2uud56\n",
            "100%|██████████| 995526/995526 [00:00<00:00, 2625253.18B/s]\n",
            "INFO:transformers.file_utils:copying /tmp/tmpvc2uud56 to cache at /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "INFO:transformers.file_utils:removing temp file /tmp/tmpvc2uud56\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57bdb97a578f4419b5a2d73760dcc6a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=40801), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 11.9 s, sys: 175 ms, total: 12 s\n",
            "Wall time: 13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uaF3knUfY_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BertTokenization 한 Embedding + Target 변수 (Series를 numpy로 변환하면 (x,) 형태의 출력이기 때문에 열 추가를 위해 reshape 해줌)\n",
        "# all_lines = np.hstack((sequences, df_ep_sample['target'].to_numpy().reshape(-1,1)))\n",
        "# all_lines.shape\n",
        "\n",
        "X = sequences\n",
        "Y = df_ep_sample['target'].to_numpy()\n",
        "# Y = df_ep_sample['target'].to_numpy().reshape(-1,1)\n",
        "\n",
        "# Train & Test Set 분리\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.15, random_state=seed)\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.15, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DZFwNyQ1Q0I",
        "colab_type": "code",
        "outputId": "50b8a5b5-2a27-4987-f7ed-3f55b9f9737e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Dataset을 상속한 TensorDataset은 train data x와 레이블 y를 묶어놓은 컨테이너로 tensor만 전달 가능함\n",
        "# X는 torch.long 형태의 텐서로, y는 torch.float 타입의 텐서로 입력하여 pytorch에서 연산할 수 있는 기본 구조로 변경하여 train_dataset으로 할당\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_x,dtype=torch.long), torch.tensor(train_y,dtype=torch.long))\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_x,dtype=torch.long), torch.tensor(test_y,dtype=torch.long))\n",
        "# train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_x), torch.tensor(train_y))\n",
        "# test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_x), torch.tensor(test_y))\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29478, 128)\n",
            "(29478,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7_FsJ-CF_lA",
        "colab_type": "code",
        "outputId": "304c6bbc-c75f-4731-b15b-039a0d71b31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dataset.tensors[1].shape\n",
        "train_dataset.tensors[1].unsqueeze(1).shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([29478])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([29478, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2tlEqUDDehg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# m = nn.Sigmoid()\n",
        "# input = torch.randn(2)\n",
        "# print(input, input.shape)\n",
        "# output = m(input)\n",
        "# print(output, output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2--Gr8kLFyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "\n",
        "# Train 함수\n",
        "def bert_train_net(net, train_loader, optimizer, device=\"cuda\"):\n",
        "  tq = tqdm_notebook(range(training_epochs))\n",
        "\n",
        "  for epoch in tq:\n",
        "    tr_loss = 0.\n",
        "    nb_tr_examples, nb_tr_steps = 0,0\n",
        "\n",
        "    # 신경망을 훈련 모드로 설정\n",
        "    net.train()\n",
        "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
        "    \n",
        "    # iteration 1회에 train_loader의 batch_size (여기서는 64)만큼씩 읽어와 한꺼번에 batch처리 batch_size * i (여기서는 i = ) 가 전체 train data set의 크기가 될때까지 loop\n",
        "    for i,(x, y) in tk0:\n",
        "      x=x.to(device) # len(x)는 batch_size\n",
        "      y=y.to(device)\n",
        "\n",
        "      # y_pred = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=None)  # forward\n",
        "      # loss = F.binary_cross_entropy_with_logits(y_pred.view_as(y),y)\n",
        "      # loss = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=y) \n",
        "      # print(loss)\n",
        "      optimizer.zero_grad() # step과 zero_grad는 쌍을 이루는 것이라고 생각하면 됨 # optimizer의 gradient를 0으로 초기화\n",
        "      loss, logit = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=y)  # forward\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "      # print(\"loss ... \", loss, type(loss))\n",
        "      loss.backward() # backpropagation\n",
        "      optimizer.step() # update gradients\n",
        "\n",
        "      # update tracking variables\n",
        "      tr_loss += loss.item()\n",
        "      nb_tr_examples += x.size(0)\n",
        "      nb_tr_steps += 1\n",
        "      # running_loss += loss.item() # loss calculate\n",
        "\n",
        "      train_losses.append(tr_loss/nb_tr_steps))\n",
        "\n",
        "    print(\"epoch: {}/{} | train_loss: {:.4f} \".format(epoch, training_epochs, tr_loss/nb_tr_steps))\n",
        "    # train_losses.append(running_loss/len(train_loader))\n",
        "    # torch.save(model.state_dict(), output_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMkB5nm7GoA9",
        "colab_type": "code",
        "outputId": "1656d9f0-214b-45c2-c90d-6cc8d2b447e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# BertForSequenceClassification is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. \n",
        "# As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
        "\n",
        "bert_config = BertConfig.from_json_file(bert_model_config)\n",
        "bert_config.num_labels = NUM_LABELS\n",
        "\n",
        "# load pre-trained BERT model's weight in ../\n",
        "model = BertForSequenceClassification.from_pretrained(PATH_PRETRAINED, config=bert_config)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "\n",
        "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "### In Transformers, optimizer and schedules are splitted and instantiated like this:\n",
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:loading weights file ../gdrive/My Drive/data/bert/bert-base-multilingual-cased/pytorch_model.bin\n",
            "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twe-4xUHvIwk",
        "colab_type": "code",
        "outputId": "2b9a73f2-c575-477f-8435-ab20e39b4627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "62f28daa9319473cac1f34c9b91fde15",
            "44af62fce2734367b0bcae1a05048850",
            "36e9005a35dd4b8b87dc164ff566ff92",
            "a32d8498bb2442fca48e5176199c769b",
            "2e7a03e6a63a4ff4bc6b75fec3175d56",
            "ca17113a25b7467da606385bb47585b3",
            "9f13a507d8d14b2a94ca3a409674a24d",
            "b8bacad6ab1642b9aa1ed9a3e5a7219c",
            "5f3f530daa84484da53e6472a19fe996",
            "726426b98f8f45f59a2da6a2e9f0fa69",
            "2b58bf3c8eae421ca7aaa81930c4586e",
            "d60038be41fd49b3ae35c92c62b7c705",
            "852db1dbf077467fb0af494847db9edc",
            "681e4167e84c45fc9063eb7ae4b5e41e",
            "44fb4003718d4151840a5c67fcdbf1d0",
            "5dcc084806d44e20acefe590777280b9",
            "e100166320ec4376b7cf66ec1ea69ce8",
            "774dbf0005c84dba938b959e0e6693ff",
            "b85e08c7b6f74f9da742bd7633b1b6c4",
            "767f436b4a004d6997aaeda7f258ed2c",
            "d2aaa21f7aa04a1d80264bf044671c9a",
            "875b150a21b8490f9fdbebb620509607",
            "8aa8432432154630a1e603d08d5cb4d8",
            "ed9efde6b53943f884b520594f528eae",
            "4828f4bf8bdb435ca9b6c9ea504770ee",
            "0945aefe9f764c439417f276b6ba5544",
            "b7b149a2f36c437e8585ee151a6c5d18",
            "4a4b392b668044a09f6305d97143c81a",
            "e6dda77a1df048de9bdcaacdc891ef5c",
            "28f2e5524bcd4925b306d2d090f3f53e",
            "ca806537c9bc4995a9a2195e98269636",
            "f0639ecb3edd428ba7993e2c0bf7616f",
            "a8f86f52245c40edbe43cab0959aa58b",
            "dc8af4035d4b46158a96638dafef099f",
            "cf58e127835a43b28a5ab101a315dda1",
            "41993ca9902042e19aa694ff97d05418",
            "919d0f5ed2cb4fa5911bcd517eb1690a",
            "ebb3bf0375224df1bf25bfa65d79ad82",
            "27bf2e6c303c4188bafb1d9382c375cc",
            "3075f088423447ebb169e01549ba6178"
          ]
        }
      },
      "source": [
        "model.to(device) # GPU 연산을 위해 cuda로 전송\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "bert_train_net(model, train_loader, optimizer, device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62f28daa9319473cac1f34c9b91fde15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f3f530daa84484da53e6472a19fe996",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=922), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0/4 | train_loss: 0.5435 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e100166320ec4376b7cf66ec1ea69ce8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=922), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1/4 | train_loss: 0.5016 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4828f4bf8bdb435ca9b6c9ea504770ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=922), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 2/4 | train_loss: 0.4564 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8f86f52245c40edbe43cab0959aa58b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=922), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 3/4 | train_loss: 0.3991 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr6ddOojQOy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "ab7bac9a-1478-40d8-ad4c-2c5009c67ee1"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_losses)\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Batch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7837d63780>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAH0CAYAAABvg4/EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+uP/B3gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKU6jC1k9fLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(y_preds, real_ys):\n",
        "    print(type(y_preds))\n",
        "    pred_flat = np.argmax(y_preds, axis=1).flatten()\n",
        "    labels_flat = real_ys.flatten()\n",
        "    print(\"pred_flat : \", pred_flat)\n",
        "    print(\"labels_flat :\", labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzJUqt5G9HEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 평가 헬퍼 함수\n",
        "def bert_eval_net(net, data_loader, device=\"cuda\"):\n",
        "  # Dropout 및 BatchNorm 무효화\n",
        "  net.eval()\n",
        "\n",
        "  eval_acc = 0\n",
        "  nb_eval_examples, nb_eval_steps = 0,0\n",
        "\n",
        "  for x, y in data_loader:\n",
        "    x=x.to(device)\n",
        "    y=y.to(device)\n",
        "    with torch.no_grad():\n",
        "      y_preds = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=None)  # forward\n",
        "\n",
        "    #Move logits and labels to CPU\n",
        "    y_preds = y_preds[0].detach().cpu().numpy()\n",
        "    real_ys = y.to('cpu').numpy()\n",
        "\n",
        "    # print(\"y_preds in eval is \", y_preds, \"type is \", type(y_preds), y_preds[0],\"type is \", type(y_preds[0]))\n",
        "    # print(\"real_ys in eval is \", real_ys)\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(y_preds, real_ys)\n",
        "    print(\"tmp_eval_accuracy : \", tmp_eval_accuracy)\n",
        "\n",
        "    eval_acc += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_acc/nb_eval_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmmhDse9IMn",
        "colab_type": "code",
        "outputId": "d5a8a716-9a18-45c2-c69b-db9556e45fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "bert_eval_net(model, test_loader, device)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1]\n",
            "labels_flat : [1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1]\n",
            "labels_flat : [1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1]\n",
            "labels_flat : [1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0]\n",
            "labels_flat : [1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0]\n",
            "labels_flat : [1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0]\n",
            "labels_flat : [1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.96875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1]\n",
            "labels_flat : [1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0]\n",
            "labels_flat : [0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0]\n",
            "labels_flat : [0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0]\n",
            "labels_flat : [1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.9375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0]\n",
            "labels_flat : [1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0]\n",
            "labels_flat : [1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
            "labels_flat : [1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.65625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n",
            "labels_flat : [1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0]\n",
            "labels_flat : [0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0]\n",
            "labels_flat : [1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1]\n",
            "labels_flat : [0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1]\n",
            "labels_flat : [1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1]\n",
            "labels_flat : [0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
            "labels_flat : [0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1]\n",
            "labels_flat : [1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.96875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1]\n",
            "labels_flat : [0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1]\n",
            "labels_flat : [0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1]\n",
            "labels_flat : [0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n",
            "labels_flat : [1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1]\n",
            "labels_flat : [1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0]\n",
            "labels_flat : [0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1]\n",
            "labels_flat : [1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1]\n",
            "labels_flat : [0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.65625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1]\n",
            "labels_flat : [1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1]\n",
            "labels_flat : [1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0]\n",
            "labels_flat : [0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0]\n",
            "labels_flat : [0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1]\n",
            "labels_flat : [0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
            "labels_flat : [1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1]\n",
            "labels_flat : [1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.65625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.65625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0]\n",
            "labels_flat : [1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "labels_flat : [1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1]\n",
            "labels_flat : [1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1]\n",
            "labels_flat : [1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1]\n",
            "labels_flat : [1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "labels_flat : [0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1]\n",
            "labels_flat : [1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.65625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1]\n",
            "labels_flat : [0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0]\n",
            "labels_flat : [0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.9375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
            "labels_flat : [0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0]\n",
            "labels_flat : [1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0]\n",
            "tmp_eval_accuracy :  0.5625\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
            "labels_flat : [0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0]\n",
            "labels_flat : [1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0]\n",
            "labels_flat : [0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat : [0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.875\n",
            "<class 'numpy.ndarray'>\n",
            "pred_flat :  [1 1 1 1 0 1 1 1 1]\n",
            "labels_flat : [1 0 1 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.7777777777777778\n",
            "Validation Accuracy: 17.051697530864196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QMVH-Ei_Yl0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}