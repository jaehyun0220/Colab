{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "SDS_FeatureEngineering_Sampling_Template#4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun0220/Colab/blob/master/SDS_FeatureEngineering_Sampling_Template_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTl6Kc03-QOM",
        "colab_type": "text"
      },
      "source": [
        "# 3조. 건강검진 데이터를 활용한 치아우식증 발생 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzRKjmfr-aLz",
        "colab_type": "text"
      },
      "source": [
        "## - Version 4. 외부 변수 결합 후 scoring 모델 전환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-PqtwTI-L37",
        "colab_type": "text"
      },
      "source": [
        "## 1. 작업 환경 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMGiKfg4-IcZ",
        "colab_type": "text"
      },
      "source": [
        "### 1-1. 구글 드라이브 인증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oERZHfZ04v3N",
        "colab_type": "code",
        "outputId": "d495f112-7d51-442d-8a0e-780a14f72472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Auth 인증 및 Google Drive 활용 Data load\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "# 학교 g guite 사용 시: 학교 g suite 구글 드라이브에 연결해 놓았으니, 성대 킹고 로그인해서 구글 드라이브 켜놓고 아래 결과창에 나오는 url 클릭해서 성대 gmail로 로그인하면 됨\n",
        "# 데이터 경로는 본인 drive 내의 /sds/data 경로로 fixdm\n",
        "\n",
        "# Google Drive 내 Custom Class 경로 지정\n",
        "# import sys\n",
        "# sys.path.insert(0, '/gdrive/My Drive/CustomClasses')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cif7nSCH57W0",
        "colab_type": "code",
        "outputId": "f0e27c7a-0f5b-4aab-c044-b9bc8c5bcdb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /gdrive/My\\ Drive/sds/data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/gdrive/My Drive/sds/data': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ZxjlWD-tIJ",
        "colab_type": "text"
      },
      "source": [
        "### 1-2. 라이브러리 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSbAKlmw4kEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "d36312e5-2d00-4dc8-ee8a-26cb56407d79"
      },
      "source": [
        "# 기본 라이브러리 로드\n",
        "import pandas as pd\n",
        "\n",
        "# pd.set_option('display.float_format', '{:.6f}'.format) # 항상 float 형식으로\n",
        "# pd.set_option('display.float_format', '{:.2e}'.format) # 항상 사이언티픽\n",
        "# pd.set_option('display.float_format', '{:.2g}'.format)  # 적당히 알아서\n",
        "# pd.set_option('display.float_format', None) # option 삭제\n",
        "\n",
        "import numpy as np\n",
        "import os, sys\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터 전처리 관련 라이브러리 로드\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "#모델 알고리즘 로드\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "\n",
        "# Deep Learning Model 로드\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation \n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#HyperParameter Tuning을 위한 라이브러리 로드\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#모델 평가를 위한 라이브러리 로드\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\n",
        "\n",
        "#수학 & 통계 관련 라이브러리 로드\n",
        "import scipy.stats as st\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Visualization\n",
        "import matplotlib as mpl  # 기본 설정 만지는 용도\n",
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도\n",
        "import seaborn as sns\n",
        "\n",
        "#Configure Visualization Defaults\n",
        "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
        "%matplotlib inline\n",
        "mpl.style.use('ggplot')\n",
        "sns.set_style('white')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-BIhlYxPs-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # # matplotlib의 폰트 캐시 위치 출력\n",
        "# print(mpl.get_cachedir())\n",
        "# # # matplotlib의 폰트 캐시를 삭제\n",
        "# !rm -rf /root/.cache/matplotlib\n",
        "# !ls -ll /root/.cache/matplotlib/\n",
        "\n",
        "# !sudo fc-cache -fv\n",
        "\n",
        "# # 나눔 글꼴을 matplotlib 에 복사하고, matplotlib의 폰트 캐시를 삭제\n",
        "# !apt-get install fonts-nanum*\n",
        "# !sudo cp /usr/share/fonts/truetype/nanum/Nanum* /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/\n",
        "\n",
        "# font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "# font_list[:5]\n",
        "\n",
        "# # 폰트 직접 설정 \n",
        "# path_gothic = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "# fontprop1 = fm.FontProperties(fname=path_gothic, size=20)\n",
        "\n",
        "# path_pen = '/usr/share/fonts/truetype/nanum/NanumPen.ttf'\n",
        "# fontprop2 = fm.FontProperties(fname=path_pen, size=34)\n",
        "\n",
        "# data = np.random.randint(-100, 100, 50).cumsum()\n",
        "\n",
        "# plt.plot(range(50), data, 'r')\n",
        "# plt.title('가격변동 추이', fontproperties=fontprop1)\n",
        "# plt.ylabel('가격', fontproperties=fontprop2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_zJxWAY0ZYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.font_manager as fm\n",
        "\n",
        "# !apt-get install fonts-nanum*\n",
        "# !apt-get install fonts-woowa-hanna\n",
        "\n",
        "# BM_HANNA = fm.FontProperties(fname='/usr/share/fonts/truetype/woowa/BM-HANNA.ttf')\n",
        "# NANUM_GOTHIC = fm.FontProperties(fname='/usr/share/fonts/truetype/nanum/NanumGothic.ttf')\n",
        "# NANUM_GOTHIC_CODING = fm.FontProperties(fname='/usr/share/fonts/truetype/nanum/NanumGothicCoding.ttf')\n",
        "\n",
        "# # \n",
        "# \"\"\"\n",
        "# - font의 위치를 가져와서 font properties로 사용할 때는 해당 폰트파일이 어디에 있든 문제가 없지만, \n",
        "# - font_family(font의 이름과 동일한 의미)를 사용해서 세팅할 때는 matplotlib 내에서 해당 폰트 파일을 가지고 있어야 함. \n",
        "# - 따라서 아래처럼 빌드 해주는 것이 필요함. \n",
        "# \"\"\"\n",
        "# fm._rebuild()\n",
        "\n",
        "# plt.rc('font', family=NANUM_GOTHIC.get_name() )\n",
        "# mpl.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# # all_fonts_I_can_use = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "# data = np.random.randint(-100, 100, 50).cumsum()\n",
        "# plt.plot(range(50), data, 'r')\n",
        "# plt.title('가격변동 추이')\n",
        "# plt.ylabel('가격')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbVgUIo5nNxq",
        "colab_type": "text"
      },
      "source": [
        "## 2. 파일 Read 및 기초 탐색"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5eXV_Q6AUZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set_random_seed = 1024\n",
        "set_cv = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF7GDYjb4kEi",
        "colab_type": "code",
        "outputId": "524d2d50-0589-4cce-8103-51d9bcfa297c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "# DataFrame Load --------- 2개년도 기준 데이터 추출 및 병합\n",
        "\n",
        "df_raw_2012 = pd.read_csv('../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2012.csv', encoding = 'euc-kr')\n",
        "df_raw_2013 = pd.read_csv('../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2013.csv', encoding = 'euc-kr')\n",
        "\n",
        "# 컬럼명 내 불필요한 공백 및 특수문자 제거\n",
        "df_raw_2012.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "df_raw_2013.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "\n",
        "# 데이터 구조 확인\n",
        "display(df_raw_2012.head(2))\n",
        "display(df_raw_2013.head(2))\n",
        "\n",
        "# 데이터 결합 및 구강검진검수여부\n",
        "df_raw = pd.concat([df_raw_2012, df_raw_2013])\n",
        "df_raw = df_raw[df_raw['구강검진수검여부']==1]\n",
        "\n",
        "# len(df_raw)\n",
        "\n",
        "#### 2013년 기준 #########################################################################################################################################\n",
        "# # 참고 - 데이터 concat시 index 문제로 병합이 안되면 아래 코드 수행 후 다시 concat\n",
        "# # df_raw.drop_duplicates() #df_raw.reset_index() # df_raw.info()\n",
        "\n",
        "# df_raw_2013 = pd.read_csv('../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2013.csv', encoding = 'euc-kr')\n",
        "\n",
        "# # 컬럼명 내 불필요한 공백 및 특수문자 제거\n",
        "# df_raw_2013.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "# df_raw = df_raw_2013[df_raw_2013['구강검진수검여부']==1]\n",
        "# display(df_raw.sample(5))\n",
        "\n",
        "# # 참고 - 데이터 concat시 index 문제로 병합이 안되면 아래 코드 수행 후 다시 concat\n",
        "# # df_raw.drop_duplicates() #df_raw.reset_index() # df_raw.info()\n",
        "\n",
        "####  2015년 기준 #########################################################################################################################################\n",
        "# df_raw_2015 = pd.read_csv('../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2015.csv', encoding = 'euc-kr')\n",
        "\n",
        "# # 컬럼명 내 불필요한 공백 및 특수문자 제거\n",
        "# df_raw_2015.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "# df_raw = df_raw_2015[df_raw_2015['구강검진수검여부']==1]\n",
        "# display(df_raw.sample(5))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2bcbb6089157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_raw_2012\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2012.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euc-kr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_raw_2013\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2013.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euc-kr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 컬럼명 내 불필요한 공백 및 특수문자 제거\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2012.csv' does not exist: b'../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2012.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_MDmptRnZ6L",
        "colab_type": "text"
      },
      "source": [
        "### 2-1. 컬럼명 정제 및 기초 탐색"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p53XCNPg4kEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del_cols = ['기준년도', '가입자일련번호', '치아우식증유무', '결손치유무' ,'치아마모증유무','제3대구치사랑니이상','데이터공개일자', '구강검진수검여부','음주여부']\n",
        "# 2014 & 2015년도 데이터 기준\n",
        "# del_cols = ['기준년도', '가입자일련번호', '치아우식증유무', '데이터기준일자', '구강검진수검여부']\n",
        "# df_raw.drop(columns=del_cols, axis=1, inplace=True)\n",
        "# df_raw.rename(columns={'치석유무': '치석'}, inplace=True)\n",
        "\n",
        "# 2012 & 2013년도 데이터 기준\n",
        "del_cols = ['기준년도', '가입자일련번호', '데이터공개일자','구강검진수검여부']\n",
        "df_raw.drop(columns=del_cols, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# #### 2013년 기준 #########################################################################################################################################\n",
        "# del_cols = ['기준년도', '가입자일련번호', '데이터공개일자','구강검진수검여부']\n",
        "# df_raw.drop(columns=del_cols, axis=1, inplace=True)\n",
        "\n",
        "# display(df_raw.head(3))\n",
        "# df_raw.info()\n",
        "\n",
        "#### 2014년 기준 #########################################################################################################################################\n",
        "# del_cols = ['기준년도', '가입자일련번호', '데이터기준일자','구강검진수검여부']\n",
        "# df_raw.drop(columns=del_cols, axis=1, inplace=True)\n",
        "# df_raw.rename(columns={'치석유무': '치석'}, inplace=True)\n",
        "\n",
        "# display(df_raw.head(3))\n",
        "# df_raw.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOk5IWaKn87U",
        "colab_type": "text"
      },
      "source": [
        "### 2-2. 치석 데이터 분류 있으나 치석 분류가 2가 아닌 데이터만 df_data에 다시 할당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SegOjIWF54O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 타겟 변수 지정\n",
        "target_nm = '치아우식증유무'\n",
        "print(df_raw[target_nm].value_counts())\n",
        "\n",
        "# 타겟 변수 후보군 지정하여 분석시 제외\n",
        "remove_target_candidates = ['치아마모증유무', '치아우식증유무', '제3대구치사랑니이상', '치석', '결손치유무']\n",
        "\n",
        "# 모델에 따라 타겟 변수 후보군으로 제외하지 않고 입력으로 사용할 변수\n",
        "not_remove_in_tg = ['치석','결손치유무']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA2CR95G4kEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = df_raw[~(df_raw['치석'].isnull()) & (df_raw['치석'] != 2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JISl_zApNFi",
        "colab_type": "text"
      },
      "source": [
        "## 3. Simple EDA\n",
        "1. 데이터 임포트 후 메모리에 upload \n",
        "2. 데이터의 모양 확인\n",
        "3. 데이터의 타입 확인\n",
        "4. 데이터의 Null 값을 체크\n",
        "5. 종속변수의 분포 체크\n",
        "6. 독립변수 - 명목형 변수의 분포 체크\n",
        "7. 독립변수 - 수치형 변수의 분포 체크\n",
        "8. 수치형, 명목형 변수간의 관계 파악"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDqnWijUBr-x",
        "colab_type": "text"
      },
      "source": [
        "### 3-1. 데이터의 모양 및 타입 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38mpcw62dGqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EDA 진행 할 데이터 모양 확인 및 데이터 타입 확인\n",
        "display(df_data.sample(5))\n",
        "display(df_data.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHQQIYFRCVFD",
        "colab_type": "text"
      },
      "source": [
        "### 3-2. 데이터 NULL 값 체크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Rv5x9wpVwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Null Value Check\n",
        "print('# Null Value Check in Data \\n ---------------------------------------------------- ')\n",
        "print(df_data.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCTfk47DPQ6Z",
        "colab_type": "text"
      },
      "source": [
        "#### 3-2-1. 데이터 NULL 값의 비중이 크지 않으므로 일단 null 값을 모두 삭졔\n",
        " . 가장 많은 Null값을 갖고 있는 요단백의 경우 추후 분석 시, 모델에 끼치는 영향이 크다고 할 시, Imputation 고려"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTF8m28HGOeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (일단 임시로) null 포함 데이터 모두 삭제 \n",
        "df_data.dropna(how='any', inplace=True)\n",
        "display(df_data.info())\n",
        "print(len(df_data))\n",
        "\n",
        "print(df_data[target_nm].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCXjhcPCLKLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 샘플링을 통한 데이터 분석\n",
        "\n",
        "# # 1. 샘플링을 통해 10만건만 데이터분석\n",
        "# df_sample = df_data.sample(n=100000, random_state=42, replace = False ).copy()\n",
        "\n",
        "# 2. 0과 1을 1:1 비율로 5만건씩 추출하여 10만건 추출\n",
        "df_sample = df_data.groupby(target_nm).apply(lambda x: x.sample(n=150000, random_state=set_random_seed)).copy()\n",
        "\n",
        "# # 3. 0과 1을 특정 비율로 샘플링\n",
        "# n_target0 = 180000\n",
        "# n_target1 = 90000\n",
        "\n",
        "# df_sample = pd.DataFrame()\n",
        "# df_sample = df_data.groupby(target_nm, as_index=False).get_group(0.0).apply(lambda x: x.sample(n=180000,random_state = set_random_seed))\n",
        "# df_sample = df_sample.append(df_data.groupby(target_nm, as_index=False).get_group(1.0).apply(lambda x: x.sample(n=n_target1,random_state = set_random_seed)))\n",
        "\n",
        "# 4. 0과 1을 90% 비율로 추출하여 원본데이터 비율대로 추출\n",
        "# df_sample = df_data.groupby(target_nm).apply(lambda x: x.sample(frac=0.8)).copy()\n",
        "\n",
        "print(df_sample[target_nm].value_counts())\n",
        "print(df_sample[target_nm].value_counts()/len(df_sample[target_nm]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn41JMRLChd7",
        "colab_type": "text"
      },
      "source": [
        "### 3-3. 데이터 Unique 값 체크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RASZ0Re11zdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('## Unique Value Check')\n",
        "print(\"-\"*25)\n",
        "print('# Col Name: Unique Value / Total Size')\n",
        "print(\"-\"*25)\n",
        "\n",
        "for col in df_sample.columns:\n",
        "    print(col, ':', df_sample[col].unique().size, '/', len(df_sample[col]))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POnmMdC6Cr9m",
        "colab_type": "text"
      },
      "source": [
        "### 3-4. Data Wrangling\n",
        "#### - 데이터 의미에 맞게 연속형, 범주형으로 변형"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAudw27Cuy-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 범주형, 연속형 변수 type 지정\n",
        "# 명목형 변수는 obj로 연속형 변수는 int 또는 float로 변경\n",
        "\n",
        "# 2014, 2015년도 데이터 기준\n",
        "category_features = ['성별코드', '연령대코드5세단위', '신장5Cm단위', '체중5Kg단위','시도코드', '청력좌', '청력우', '흡연상태','음주여부', '요단백'] + not_remove_in_tg\n",
        "\n",
        "# 2013년도 데이터 기준\n",
        "# category_features = ['성별코드', '연령대코드5세단위', '신장5Cm단위', '체중5Kg단위','시도코드', '청력좌', '청력우', '흡연상태','음주여부', '요단백']\n",
        "\n",
        "for col in df_data.columns:\n",
        "  if col in category_features:\n",
        "    df_sample[col] = df_sample[col].astype(object)\n",
        "\n",
        "print(df_sample.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJvSxH4lC5yc",
        "colab_type": "text"
      },
      "source": [
        "### 3-5. Target 종속변수 속성 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXDFfiN54kEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Count : \\n\", df_sample[target_nm].value_counts(), \"\\n------------------------------\\nPortion : \\n\", df_sample[target_nm].value_counts()/len(df_sample[target_nm]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kshpVxc_pVml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample[target_nm].value_counts().plot(kind='bar') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCq2y8kjEvsK",
        "colab_type": "text"
      },
      "source": [
        "### 3-6. 명목형 변수 EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9tDDRhhE0wR",
        "colab_type": "text"
      },
      "source": [
        "#### 3-6-1. 명목형 변수 항목 변환\n",
        " - A_성별 --- 성별코드를 '남', '여' 로 변경\n",
        " - A_연령대5세단위 --- 연령대코드를 5세 단위 수치로 변경(20~24세는 20으로 표기)\n",
        " - A_시도 --- 시도코드를 서울, 경기와 같이 변경\n",
        " - A_청력좌, A_청력우 - 청력코드를 정상, 비정상으로 변경\n",
        " - A_요단백 - 요단백코드를 정상, 비정상으로 변경\n",
        " - A_흡연상태 - 비흡연, 금연, 흡연으로 변경\n",
        " - A_음주여부 - 비음주, 음주로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVnNG9cNFI4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 성별코드 변환\n",
        "df_sample[\"A_성별\"] = df_sample[\"성별코드\"].apply(lambda x:  '남' if x == 1 else '여')\n",
        "\n",
        "# 연령대코드 5세 단위 변환\n",
        "min_age_code = df_sample[\"연령대코드5세단위\"].min()\n",
        "print(min_age_code)\n",
        "\n",
        "df_sample[\"A_연령대5세단위\"] = df_sample[\"연령대코드5세단위\"].apply(lambda x:  (x-1)*5 + 20 if min_age_code == 1 else (x-1)*5).astype(object)\n",
        "\n",
        "# 시도코드 변환\n",
        "df_sample[\"A_시도\"] = np.where(df_sample['시도코드'] == 11, '서울', \n",
        "                            np.where(df_sample['시도코드']== 26, '부산', \n",
        "                              np.where(df_sample['시도코드'] == 27, '대구', \n",
        "                                np.where(df_sample['시도코드'] == 28, '인천', \n",
        "                                  np.where(df_sample['시도코드'] == 29, '광주', \n",
        "                                    np.where(df_sample['시도코드'] == 30, '대전', \n",
        "                                      np.where(df_sample['시도코드'] == 31, '울산', \n",
        "                                        np.where(df_sample['시도코드'] == 36, '세종', \n",
        "                                          np.where(df_sample['시도코드'] == 41, '경기', \n",
        "                                            np.where(df_sample['시도코드'] == 42, '강원', \n",
        "                                              np.where(df_sample['시도코드'] == 43, '충북', \n",
        "                                                np.where(df_sample['시도코드'] == 44, '충남', \n",
        "                                                  np.where(df_sample['시도코드'] == 45, '전북', \n",
        "                                                    np.where(df_sample['시도코드'] == 46, '전남', \n",
        "                                                      np.where(df_sample['시도코드'] == 47, '경북', \n",
        "                                                        np.where(df_sample['시도코드'] == 48, '경남', \n",
        "                                                          np.where(df_sample['시도코드'] == 49, '제주', '오류')\n",
        "                                      ))))))))))))))))\n",
        "\n",
        "# 청력좌  변환\n",
        "df_sample[\"A_청력좌\"] = df_sample[\"청력좌\"].apply(lambda x:  '정상' if x == 1 else '비정상')\n",
        "\n",
        "# 청력우  변환\n",
        "df_sample[\"A_청력우\"] = df_sample[\"청력우\"].apply(lambda x:  '정상' if x == 1 else '비정상')\n",
        "\n",
        "# 요단백  변환\n",
        "df_sample[\"A_요단백\"] = df_sample[\"요단백\"].apply(lambda x:  '음성' if x == 1 else '양성')\n",
        "\n",
        "# 흡연상태  변환\n",
        "df_sample[\"A_흡연상태\"] = df_sample[\"흡연상태\"].apply(lambda x:  '비흡연' if x == 1 else ('금연' if x==2 else '흡연'))\n",
        "\n",
        "# 음주여부  변환\n",
        "df_sample[\"A_음주여부\"] = df_sample[\"음주여부\"].apply(lambda x:  '비음주' if x == 0 else '음주')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X3gVV0-Yi2z",
        "colab_type": "text"
      },
      "source": [
        "#### 3-6-1-1 변환 명목형 원 컬럼 삭제\n",
        "- 변환이전의 코드 형식의 명목형 변수는 필요없으므로 삭제\n",
        "- 변환이전 코드형식 컬럼 list\n",
        "- del_obj_trans_cols = ['성별코드', '연령대코드5세단위', '시도코드', '청력좌', '청력우', '요단백', '흡연상태', '음주여부']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ofR4vfFqSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 변환 명목형 원 컬럼 삭제\n",
        "del_obj_trans_cols = ['성별코드', '연령대코드5세단위', '시도코드', '청력좌', '청력우', '요단백', '흡연상태', '음주여부']\n",
        "df_sample.drop(columns=del_obj_trans_cols, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITa1FbtHlu0",
        "colab_type": "text"
      },
      "source": [
        "### 3-6-2. 명목형 변수 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doTF4GYdpVgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 앞에서 명목형 변수의 형을 object로 모두 변경했기 때문에 컬럼 중에서 object 타입을 가진 컬럼만 뽑아서 명목형 변수의 리스트를 만든다\n",
        "# 이 때, 데이터의 기본키(인덱스), 종속변수 등을 제외하고 분석하는 것이 좋음\n",
        "\n",
        "# 단변수 탐색\n",
        "category_features = [col for col in df_sample.columns if df_sample[col].dtypes == \"object\"]\n",
        "print(category_features)\n",
        "\n",
        "cat_cols = list(set(category_features) - set([target_nm]))\n",
        "print(cat_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN0EUWQzFJDE",
        "colab_type": "text"
      },
      "source": [
        "#### 3-6-3. 명목형 변수 count plot (단변량)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHjG0XGx-KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 그래프를 통해 명목형 변수의 분포를 체크\n",
        "fig, saxis = plt.subplots(math.ceil(len(category_features)/2), 2, figsize=(20,20))\n",
        "plt.figure()\n",
        "\n",
        "# 변수별로 for문을 돌면서 countplot을 그림\n",
        "for idx, col in enumerate(cat_cols):\n",
        "  row_loc = idx // 2\n",
        "  col_loc = idx % 2\n",
        "  sns.countplot(x=df_sample[col], data= df_sample, ax = saxis[row_loc,col_loc])\n",
        "#   df_data[col].value_counts().plot(kind='bar', ax = saxis[row_loc,col_loc])\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8htzg6UDI0lr"
      },
      "source": [
        "#### 3-6-2. 명목형 변수 bar plot(이변량 - 종속변수와의 관계)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnUhtPz61uHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, saxis = plt.subplots(math.ceil(len(category_features)/2), 2, figsize=(20,20))\n",
        "plt.figure()\n",
        "\n",
        "# 변수별로 for문을 돌면서 barplot 그림\n",
        "for idx, col in enumerate(cat_cols):\n",
        "  row_loc = idx // 2\n",
        "  col_loc = idx % 2\n",
        "  sns.barplot(x=col, y=target_nm, data= df_sample, ax = saxis[row_loc,col_loc])\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aODjgQIqLO0Y",
        "colab_type": "text"
      },
      "source": [
        "### 3-7. 수치형 변수 EDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuoHG47J0Vl",
        "colab_type": "text"
      },
      "source": [
        "#### 3-7-2. 수치형 변수 추출 및 확인\n",
        "- 구강검진으로 나타날 수 있는 타겟 변수들 중 타겟을 제외하고 삭제 필요\n",
        "- remove_target_candidates = ['치아마모증유무', '치아우식증유무', '제3대구치사랑니이상', '치석', '결손치유무']\n",
        "- num_cols = list(set(numeric_features) - set(remove_target_candidates))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBngXixW3_2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 앞에서 명목형 변수의 형을 object로 모두 변경했기 때문에 컬럼 중에서 object 타입을 가진 컬럼만 뽑아서 명목형 변수의 리스트를 만든다\n",
        "# 이 때, 데이터의 기본키(인덱스), 종속변수 등을 제외하고 분석하는 것이 좋음\n",
        "\n",
        "# 단변수 탐색\n",
        "numeric_features = [col for col in df_sample.columns if df_sample[col].dtypes != \"object\"]\n",
        "numeric_features = np.sort(numeric_features)\n",
        "\n",
        "# 구강검진으로 나타날 수 있는 타겟 변수들 : '치아마모증유무', '치아우식증유무', '제3대구치사랑니이상', '치석', '결손치유무'\n",
        "remove_target_candidates = ['치아마모증유무', '치아우식증유무', '제3대구치사랑니이상', '치석', '결손치유무']\n",
        "\n",
        "not_remove_in_tg = ['치석','결손치유무']\n",
        "\n",
        "num_cols = list(set(numeric_features) - set(remove_target_candidates))\n",
        "print(num_cols)\n",
        "\n",
        "print(len(num_cols)) # 총 15개"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7cuyLJMRvhd",
        "colab_type": "text"
      },
      "source": [
        "#### 3-7-3. 수치형 변수 count plot (단변량)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G3UtmCsLOKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단변수 탐색 - 단변수 탐색은 seaborn 패키지의 distplot 함수를 이용하면 편함\n",
        "# 수치형 변수만 골라냄\n",
        "fig, saxis = plt.subplots(math.ceil(len(num_cols)/3), 3, figsize=(20,28))\n",
        "plt.figure()\n",
        "\n",
        "# 변수별로 for문을 돌면서 distplot을 그림\n",
        "for idx, col in enumerate(num_cols):\n",
        "    row_loc = idx // 3\n",
        "    col_loc = idx % 3\n",
        "    sns.distplot(df_sample.loc[df_sample[col].notnull(), col], ax = saxis[row_loc,col_loc])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9CO6qHnSREB",
        "colab_type": "text"
      },
      "source": [
        "#### 3-7-4. 수치형 변수 Transformations \n",
        " - num_ln_target_features --- 로그를 취할 변수명 list(추후 최종 입력 전 삭제 필요)\n",
        "\n",
        " - num_ln_cols --- 로그를 취하고 난 뒤의 변수명 list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zIbvoZwLOC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 수치형 변수들에 log를 취한 값 산출\n",
        "# 로그 취할 대상 컬럼 선정 # 그리고 log를 취한 원 변수는 추후에 버릴 예정으로 따로 기록해 둔다\n",
        "num_ln_target_features = ['LDL콜레스테롤', 'HDL콜레스테롤', '시력좌', '시력우', '혈청크레아티닌', '혈청지오티AST','혈청지오티ALT', '감마지티피', '트리글리세라이드', '식전혈당공복혈당']\n",
        "\n",
        "# Feature Engineering의 일환으로 Log 값 취한 뒤 Normalization을 하여 변수명 + LN (lognorm)으로 열 추가 후 그래프 다시 그림\n",
        "num_ln_cols = list(map(lambda x: \"LN_\"+str(x), num_ln_target_features))\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('log_scaler', FunctionTransformer(np.log1p, validate=True)), # pipeline 내 log transformation을 위해 Function Transfomer 사용\n",
        "        ('normalizer', MinMaxScaler()),\n",
        "    ])\n",
        "\n",
        "piped_np = num_pipeline.fit_transform(df_sample[num_ln_target_features])\n",
        "piped_df = pd.DataFrame(piped_np, columns=num_ln_cols)\n",
        "\n",
        "print(len(piped_df))\n",
        "piped_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcMw2z2aTU8Y",
        "colab_type": "text"
      },
      "source": [
        "#### 3-7-6. 수치형 LN 변수 count plot (단변량)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhzW18Kd4kEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단변수 탐색 with log 변형 변수\n",
        "fig, saxis = plt.subplots(math.ceil(len(num_ln_cols)/2), 2, figsize=(20,25))\n",
        "plt.figure()\n",
        "\n",
        "# 변수별로 for문을 돌면서 distplot 그림\n",
        "for idx, col in enumerate(num_ln_cols):\n",
        "    row_loc = idx // 2\n",
        "    col_loc = idx % 2\n",
        "    # print(idx, row_loc, col_loc)\n",
        "    sns.distplot(piped_df.loc[piped_df[col].notnull(), col], ax = saxis[row_loc,col_loc])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A5ZoxupRsvY",
        "colab_type": "text"
      },
      "source": [
        "#### 3-7-5. 로그 취한 수치형 변수 Concat을 통한 새 Dataframe 생성 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EP2WNz-LN2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Before Re-indexing: Data count is \", len(df_sample))\n",
        "df_sample.drop_duplicates()\n",
        "df_sample.reset_index(inplace=True, drop=True)\n",
        "print(\"After Re-indexing: Data count is \", len(df_sample))\n",
        "\n",
        "df_fe = pd.concat([df_sample, piped_df], axis=1)\n",
        "df_fe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_EADuUCK_fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl-BajSCZ9PZ",
        "colab_type": "text"
      },
      "source": [
        "### 3-8. Information Value 계산을 위한 환경 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SydqUwY0aSVH",
        "colab_type": "text"
      },
      "source": [
        "### 3-8-1. woe library 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lt6QhOCkQS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# woe package install\n",
        "! pip install woe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW1q-CqNaiEr",
        "colab_type": "text"
      },
      "source": [
        "### 3-8-2. Library Load 및 환경 변수 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az8YC4T8j1QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate IV Setting\n",
        "import pandas.core.algorithms as algos\n",
        "from pandas import Series\n",
        "import scipy.stats.stats as stats\n",
        "import traceback\n",
        "import string\n",
        "import woe\n",
        "from woe.eval import plot_ks\n",
        "\n",
        "max_bin = 20\n",
        "force_bin = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJhLJTwbaqZP",
        "colab_type": "text"
      },
      "source": [
        "### 3-8-3. Information Value 산출 사용자 정의 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyAaUQ6Wixzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a binning function for continous independent variables\n",
        "def mono_bin(Y, X, n = max_bin):\n",
        "  df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
        "  justmiss = df1[['X','Y']][df1.X.isnull()]\n",
        "  notmiss = df1[['X','Y']][df1.X.notnull()]\n",
        "  r = 0\n",
        "  while np.abs(r) < 1:\n",
        "    try:\n",
        "      global d1\n",
        "      global d2\n",
        "      d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
        "      d2 = d1.groupby('Bucket', as_index=True)\n",
        "      r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
        "      n = n - 1 \n",
        "    except Exception as e:\n",
        "      n = n - 1\n",
        "      break\n",
        "      \n",
        "  if len(d2) == 1:\n",
        "    n = force_bin         \n",
        "    bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
        "    if len(np.unique(bins)) == 2:\n",
        "        bins = np.insert(bins, 0, 1)\n",
        "        bins[1] = bins[1]-(bins[1]/2)\n",
        "    d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
        "    d2 = d1.groupby('Bucket', as_index=True)\n",
        "\n",
        "  d3 = pd.DataFrame({},index=[])\n",
        "  d3[\"MIN_VALUE\"] = d2.min().X\n",
        "  d3[\"MAX_VALUE\"] = d2.max().X\n",
        "  d3[\"COUNT\"] = d2.count().Y\n",
        "  d3[\"EVENT\"] = d2.sum().Y\n",
        "  d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n",
        "  d3=d3.reset_index(drop=True)\n",
        "\n",
        "  if len(justmiss.index) > 0:\n",
        "      d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
        "      d4[\"MAX_VALUE\"] = np.nan\n",
        "      d4[\"COUNT\"] = justmiss.count().Y\n",
        "      d4[\"EVENT\"] = justmiss.sum().Y\n",
        "      d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
        "      d3 = d3.append(d4,ignore_index=True)\n",
        "\n",
        "  d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
        "  d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
        "  d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
        "  d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
        "  d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"VAR_NAME\"] = \"VAR\"\n",
        "  d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
        "  d3 = d3.replace([np.inf, -np.inf], 0)\n",
        "  d3.IV = d3.IV.sum()\n",
        "\n",
        "  return(d3)\n",
        "  \n",
        "# Define a binning function for categorical independent variables\n",
        "def char_bin(Y, X):\n",
        "  df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
        "  justmiss = df1[['X','Y']][df1.X.isnull()]\n",
        "  notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
        "  df2 = notmiss.groupby('X',as_index=True)\n",
        "\n",
        "  d3 = pd.DataFrame({},index=[])\n",
        "  d3[\"COUNT\"] = df2.count().Y\n",
        "  d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
        "  d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
        "  d3[\"EVENT\"] = df2.sum().Y\n",
        "  d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
        "\n",
        "  if len(justmiss.index) > 0:\n",
        "    d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
        "    d4[\"MAX_VALUE\"] = np.nan\n",
        "    d4[\"COUNT\"] = justmiss.count().Y\n",
        "    d4[\"EVENT\"] = justmiss.sum().Y\n",
        "    d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
        "    d3 = d3.append(d4,ignore_index=True)\n",
        "\n",
        "  d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
        "  d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
        "  d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
        "  d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
        "  d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"VAR_NAME\"] = \"VAR\"\n",
        "  d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
        "  d3 = d3.replace([np.inf, -np.inf], 0)\n",
        "  d3.IV = d3.IV.sum()\n",
        "  d3 = d3.reset_index(drop=True)\n",
        "\n",
        "  return(d3)\n",
        "\n",
        "# Calculate Information Values\n",
        "def calc_iv_all(df1, target):\n",
        "    \n",
        "  stack = traceback.extract_stack()\n",
        "  filename, lineno, function_name, code = stack[-2]\n",
        "  vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
        "  final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
        "\n",
        "  x = df1.dtypes.index\n",
        "  count = -1\n",
        "\n",
        "  for i in tqdm_notebook(x):\n",
        "    if i.upper() not in (final.upper()):\n",
        "      if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
        "        conv = mono_bin(target, df1[i])\n",
        "        conv[\"VAR_NAME\"] = i\n",
        "        count = count + 1\n",
        "      else:\n",
        "        conv = char_bin(target, df1[i])\n",
        "        conv[\"VAR_NAME\"] = i            \n",
        "        count = count + 1\n",
        "\n",
        "      if count == 0:\n",
        "        iv_df = conv\n",
        "      else:\n",
        "        iv_df = iv_df.append(conv,ignore_index=True)\n",
        "\n",
        "  iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n",
        "  iv = iv.reset_index()\n",
        "  return(iv_df,iv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye8byOKFa21n",
        "colab_type": "text"
      },
      "source": [
        "### 3-8-4. IV 산출을 위한 data sampling 및 IV 산출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "41xv2BPVSgcm",
        "colab": {}
      },
      "source": [
        "# Information Value Test를 위한 임시 Dataframe 생성\n",
        "need_cols = list(set(df_fe.columns) - (set(num_ln_target_features + remove_target_candidates) - set([target_nm] + not_remove_in_tg)))\n",
        "\n",
        "df_iv_test = df_fe[need_cols].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAihdepJQAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IV 산출\n",
        "first_iv_df, IV_first = calc_iv_all(df_iv_test,df_iv_test[target_nm])\n",
        "# first_iv_df\n",
        "\n",
        "# IV 값 내림차순 정렬\n",
        "IV_first.sort_values('IV',ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McueKEuuZ4lO",
        "colab_type": "text"
      },
      "source": [
        "## 4. Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz-tC4mbRQvl",
        "colab_type": "text"
      },
      "source": [
        "### 4-1. Feature Engineering 내부 변수 추가\n",
        "- 데이터셋 내 내부 변수의 범주화를 통한 신규 변수 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDc5FTdbvs_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기존 수치형 변수들을 LN 변수들로 치환\n",
        "# df_fe.drop(columns=numeric_feature, axis=1, inplace=True)\n",
        "\n",
        "# BMI 변수 추가\n",
        "df_fe[\"A_BMI\"] = (df_fe[\"체중5Kg단위\"]/(df_fe[\"신장5Cm단위\"]*df_fe[\"신장5Cm단위\"])).astype(float)\n",
        "\n",
        "# 공복 혈당 \n",
        "# 100 이하는 정상/ 100 ~ 125는 '공복혈당장애 - 당뇨 전단계'/ 125 이상은 당뇨\n",
        "# 당뇨병의 중간인 100~125 mg/dL가 나오거나 \n",
        "\n",
        "df_fe[\"A_diabetes\"] = np.where(df_fe['식전혈당공복혈당'].between(0, 100, inclusive=True), '정상', \n",
        "                               np.where(df_fe['식전혈당공복혈당'].between(100, 124.9, inclusive=True), '당뇨전단계', \n",
        "                                        '당뇨')\n",
        "                              )\n",
        "\n",
        "# HDL 콜레스테롤\n",
        "# HDL 콜레스테롤 수치가 남자에서 40 mg/dL (1.0 mmol/L) 이하 또는 여자에서 50 mg/dL (1.3 mmol/L) 이하일 경우에는 다른 위험인자와 독립적으로 심장 질환의 위험도가 증가\n",
        "# HDL 콜레스테롤 수치가 남자에서 40-50 mg/dL (1.0-1.3 mmol/L) 그리고 여자에서 50-59 mg/dL (1.3-1.5 mmol/L)인 경우에는 심장 질환의 평균위험도와 연관\n",
        "# 보통 HDL 콜레스테롤 수치가 60 mg/dL (1.55 mmol/L) 또는 그 이상일 경우에는 심장 질환 평균 위험도보다 낮음\n",
        "# National Cholesterol Education Panel Adult Treatment Guidelines에 따르면 HDL 콜레스테롤 수치가 60 mg/dL 이상일 경우 심장 질환에서 보호되고 음성 위험 인자로서 치료되어야 함\n",
        "df_fe[\"A_HDL\"] = np.where(\n",
        "                    (df_fe['A_성별'] == \"여\") & (df_fe['HDL콜레스테롤']<= 50), '고위험', \n",
        "                       np.where(\n",
        "                         (df_fe['A_성별']== \"여\") & (df_fe['HDL콜레스테롤'].between(50, 59.9, inclusive=True)), '위험', \n",
        "                           np.where(\n",
        "                               (df_fe['A_성별']== \"남\") & (df_fe['HDL콜레스테롤']<= 40), '고위험', \n",
        "                                      np.where(\n",
        "                                          (df_fe['A_성별']== \"남\") & (df_fe['HDL콜레스테롤'].between(40, 49.9, inclusive=True)), '위험', '정상')\n",
        "                          )))\n",
        "# LDL 콜레스테롤(혈중 모든 콜레스테롤 중 LDL 콜레스테롤이 심장질환에 대한 위험도를 확인하는데 가장 중요한 지표)\n",
        "# 대부분의 치료 결정이 LDL 수치를 토대로 이루어지기 때문에 이 검사를 통해 식이요법 또는 운동처방의 효과를 감시하거나 지질감소 약물을 처방하는 것이 유용한지에 대한 평가\n",
        "# 100 mg/dL (2.59mmol/L) 미만 – 최적\n",
        "# 100-129 mg/dL (2.59-3.34 mmol/L) – 최적에 인접\n",
        "# 130-159 mg/dL (3.37-4.12 mmol/L) – 상한 경계성\n",
        "# 160-189 mg/dL (4.15-4.90 mmol/L) – 높음\n",
        "# 190 mg/dL (4.90 mmol) 이상 – 매우 높음\n",
        "df_fe[\"A_LDL\"] = np.where(df_fe['LDL콜레스테롤']<100, '최적', \n",
        "                    np.where(df_fe['LDL콜레스테롤'].between(100, 122.9, inclusive=True), '최적인접', \n",
        "                             np.where(df_fe['LDL콜레스테롤'].between(130, 159.9, inclusive=True), '상한경계', \n",
        "                                      np.where(df_fe['LDL콜레스테롤'].between(160, 189.9, inclusive=True), '높음', '매우높음')\n",
        "                              )))\n",
        "\n",
        "# 트리글리세라이드\n",
        "# 지방의 한 형태로서 몸의 주요 에너지원, 트리글리세라이드가 증가하는 것은, 이유가 분명하지 않으나 심혈관 질환으로 진행될 위험의 증가와 관련\n",
        "# 일부 인자들 즉, 운동 부족, 과체중, 흡연, 과음 및 당뇨와 신질환 등의 질병 상태가 고트리글리세라이드혈증 및 심혈관 질환 위험도 증가에 기여할 수 있음\n",
        "# 성인에서는 트리글리세라이드 결과가 아래와 같이 나뉘어진다.\n",
        "# 150 mg/dL (1.7 mmol/L) 미만: 바람직\n",
        "# 150-199 mg/dL (1.7-2.2 mmol/L): 경계성증가\n",
        "# 200-499 mg/dL (2.3-5.6 mmol/L): 증가: \n",
        "# 500 mg/dL (5.6 mmol/L) 이상: 매우 증가\n",
        "# 이 수치는 공복시 트리글리세라이드 수치에 기준합니다.\n",
        "df_fe[\"A_TRI\"] = np.where(df_fe['트리글리세라이드']<150, '바람직', \n",
        "                    np.where(df_fe['트리글리세라이드'].between(150, 199.9, inclusive=True), '경계성증가', \n",
        "                             np.where(df_fe['트리글리세라이드'].between(200, 499.9, inclusive=True), '증가', '매우증가')\n",
        "                              ))\n",
        "\n",
        "# 혈색소\n",
        "# 성인의 데시리터(100밀리리터) 당 12그램에서 18그램 정도: 정상치\n",
        "# 18그램 이상: 폐질환 등 기타 이상\n",
        "# 12그램 미만: 빈혈\n",
        "df_fe[\"A_HEMO\"] = np.where(df_fe['혈색소'].between(12, 17.9, inclusive=True), '정상', \n",
        "                    np.where(df_fe['혈색소']>=18, '이상', '빈혈'))\n",
        "\n",
        "# 요단백: 소변으로 빠져나가는 잉여의 단백질을 검출하기 위해, 신장 기증을 평가하고 모니터하는 것을 돕기 위해,  그리고 신장 손상을 검출하기 위해 검사\n",
        "# 요단백은 보통 소변에서 검출 되지 않음\n",
        "\n",
        "# 혈중 크레아티닌 농도의 \n",
        "# 정상범위는 0.50~1.4 mg/dL 입니다\n",
        "# 근육량에 비례하는 검사결과이므로 여성보다는 남성에게서 약간 높은 수치가 나타나고, 식사나 운동이 결과에 영향이 거의 미치지 않습니다. 지속적으로 많은 양의 육식을 섭취한 경우에는 크레아티닌 농도가 높게 측정됩니다.\n",
        "df_fe[\"A_CRE\"] = np.where(df_fe['혈청크레아티닌'].between(0.5, 1.4, inclusive=True), '정상', '이상')\n",
        "\n",
        "# 혈청지오티AST:\n",
        "#  간기능을 평가하는 기초검사항목으로서 알코올성 간장애나 만성 간질환에서 주로 증가한다.\n",
        " \n",
        "\n",
        "# 혈청지오티ALT:\n",
        "# 간기능을 평가하는 기초검사항목으로서 급성 간염 시 주로 증가한다.\n",
        "# 증가: 간질환, 심근경색, 지방간, 비만\n",
        "\n",
        "\n",
        "# 감마지티피\n",
        "# 간장세포나 담낭세포가 파괴되면 감마지티피가 혈액속으로 누출되어 수치가 높아짐\n",
        "# 남자는 50IU 이하, 여자는 32IU이하가 정상\n",
        "# 100이하면 음주 조절을 통해 조정 가능하나 100 이상이면 지방간이 진행되고 있을 가능성이 높음\n",
        "# 200 이상이면 담석이나 담도암등으로 담도가 막혀있을 가능성이 높음\n",
        "# 500 이상이면 황달\n",
        "df_fe[\"A_GTP\"] = np.where((df_fe['감마지티피'] >= 500), '황달', \n",
        "                       np.where(df_fe['감마지티피']>=200, '담도이상', \n",
        "                           np.where(df_fe['감마지티피']>= 100, '이상가능', \n",
        "                             np.where((df_fe['A_성별']== \"남\") & (df_fe['감마지티피']<=50), '정상',\n",
        "                              np.where((df_fe['A_성별']== \"여\") & (df_fe['감마지티피']<=32), '정상', '체크')\n",
        "                          ))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGWiCYhrbp91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fe.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZiUEtxudbzX",
        "colab_type": "text"
      },
      "source": [
        "### 4-2. Feature Engineering 외부 변수 추가\n",
        "- 외부 데이터 및 변수를 통한 신규 변수 추출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFs-UMZC3qJQ",
        "colab_type": "text"
      },
      "source": [
        "### 4-2-1. 데이터셋 외부 변수 load 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxzAtm8Z7Jv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /gdrive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhWQtJW8hxnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_add1 = pd.read_csv('../gdrive/My Drive/sds/data/완료_구강검진결과_14년도_교육이후개별비.csv', encoding = 'euc-kr')\n",
        "# # df_add1[\"성별\"] = df_add1[\"성별\"].str[:1]\n",
        "# # df_add1.drop(columns=['n_기타_결과'], axis=1, inplace=True)\n",
        "df_add1 = pd.read_csv('../gdrive/My Drive/sds/data/완료_구강검진결과_14년도_총수검인원기준비.csv', encoding = 'euc-kr')\n",
        "df_add2 = pd.read_csv('../gdrive/My Drive/sds/data/완료_KOSIS 연령별 성별 치과 평균 수진횟수 2012.csv', encoding = 'euc-kr')\n",
        "df_add3 = pd.read_csv('../gdrive/My Drive/sds/data/완료_KOSIS 치주질환 유병률 추이_2012.csv', encoding = 'euc-kr')\n",
        "\n",
        "display(df_add1.info())\n",
        "display(df_add2.info())\n",
        "display(df_add3.info())\n",
        "display(df_add1.head())\n",
        "display(df_add2.head())\n",
        "display(df_add3.head())\n",
        "\n",
        "# KOSIS 연령별 성별 치과 평균 수진횟수 2014"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hEFRTYU4NEU",
        "colab_type": "text"
      },
      "source": [
        "### 4-2-2. 데이터셋 외부 변수 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5t8PFgj4Ry_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multiple Key를 사용하여 Join\n",
        "# left_on=['column_name1','column_name2'], right_on = ['column_name3','column_name4']\n",
        "print(len(df_fe))\n",
        "\n",
        "df_new = pd.merge(left=df_fe, right=df_add1, how='outer', left_on=['A_시도','A_성별'], right_on = ['시도','성별'], sort=False)\n",
        "df_new.drop(columns=['시도','성별'], axis=1, inplace=True)\n",
        "display(df_new.head())\n",
        "print(len(df_new))\n",
        "\n",
        "df_new = pd.merge(left=df_new, right=df_add2, how='outer', left_on=['A_연령대5세단위','A_성별'], right_on = ['연령','성별'], sort=False)\n",
        "df_new.drop(columns=['연령','성별'], axis=1, inplace=True)\n",
        "display(df_new.head())\n",
        "print(len(df_new))\n",
        "\n",
        "df_new = pd.merge(left=df_new, right=df_add3, how='outer', left_on=['A_연령대5세단위','A_성별'], right_on = ['연령','성별'], sort=False)\n",
        "df_new.drop(columns=['연령','성별'], axis=1, inplace=True)\n",
        "display(df_new.head())\n",
        "print(len(df_new))\n",
        "\n",
        "display(df_new.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCtTc9K2d9fB",
        "colab_type": "text"
      },
      "source": [
        "#### 4-1-4. 데이터셋 내 내부 변수 신규 변수 검증(To-Do)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVWF88axeQEW",
        "colab_type": "text"
      },
      "source": [
        "### 4-2. FE 추가변수 IV값 산출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4_4oqlC9ASH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Information Value Test를 위한 임시 Dataframe 생성\n",
        "need_cols = list(set(df_new.columns) - (set(num_ln_target_features + remove_target_candidates) - set([target_nm] + not_remove_in_tg)))\n",
        "df_iv_final = df_new[need_cols].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9RJhBnfQk6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fe_iv_df, IV_fe = calc_iv_all(df_iv_final,df_iv_final[target_nm])\n",
        "# fe_iv_df\n",
        "\n",
        "# IV 값 내림차순 정렬\n",
        "IV_fe.sort_values('IV',ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GXVLszYoHVl",
        "colab_type": "text"
      },
      "source": [
        "### 4-3. Feature Engineering 이전과 Feature Engineering 이후의 IV 값 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7ZZRWf7oHtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IV_compare = pd.merge(IV_fe, IV_first, how='outer', on=\"VAR_NAME\")\n",
        "IV_compare = IV_compare.reset_index(drop=True)\n",
        "IV_compare.sort_values(['IV_x'], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Uqmh5TGj49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IV_input_col = list(IV_compare[IV_compare['IV_x']>=0.002]['VAR_NAME'])\n",
        "IV_input_col = list(IV_compare[IV_compare['IV_x']>=0.008]['VAR_NAME'])\n",
        "IV_input_col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3HXjRmLJyFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_iv_top = df_iv_final[IV_input_col+[target_nm]].copy()\n",
        "df_iv_top"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9b-9cMtH5gF",
        "colab_type": "text"
      },
      "source": [
        "### 4-4. 수치형 변수 기준 상관계수 체크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvVpdD0yvYHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 상관계수 검증을 위한 연속형 변수 탐색\n",
        "num_features_after_fe = [col for col in df_iv_top.columns if df_iv_top[col].dtypes != \"object\"]\n",
        "num_features_after_fe = np.sort(num_features_after_fe)\n",
        "\n",
        "num_input = list(set(num_features_after_fe) - set(remove_target_candidates))\n",
        "print(num_input)\n",
        "\n",
        "print(len(num_input)) # 총 18개"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxBZzygA4kEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint as pp\n",
        "\n",
        "corr_dict = {}\n",
        "\n",
        "for i in num_input:\n",
        "    corr_dict[i] = df_iv_top[target_nm].astype('float64').corr(df_iv_top[i])\n",
        "\n",
        "pp(corr_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AuPhJVRK4kE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 간의 상관관계 체크\n",
        "# 수치형변수들과 Survived 변수의 상관관계 Matrix 시각화\n",
        "plt.figure(figsize=(15, 15))\n",
        "g = sns.heatmap(df_iv_top.corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE3jPMLcWv7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del_corr_inputs = ['n_정밀검진_권고', 'n_관리_권고','n_치료필요_결과','n_정상A_결과','n_주의_결과','n_영양_교육','n_정상B_결과','n_불소_교육','n_위생_교육','n_우식필요_권고']\n",
        "# del_corr_inputs = ['n_정밀검진_권고', 'n_관리_권고','n_정상B_결과','n_불소_교육'] # iv >= 0.002\n",
        "# del_corr_inputs = ['n_영양_교육', 'n_정상A_결과', 'n_주의_결과', 'n_치료필요_결과'] # iv >= 0.015\n",
        "del_corr_inputs = ['n_관리_권고','n_정상B_결과','n_불소_교육','n_우식필요_권고'] # iv >= 0.008\n",
        "df_iv_result = df_iv_top.drop(columns=del_corr_inputs, axis=1).copy()\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "g = sns.heatmap(df_iv_result.corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AERAs1ZbVPxj",
        "colab_type": "text"
      },
      "source": [
        "### 4-5. 최종 모델 입력 변수 선정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSI-NTSUQfMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Engineering 이후 불필요컬럼 Drop\n",
        "\n",
        "# 치석, 결손치 유무와 같은 치아관련 변수 없이 모델 돌릴 시 # test set accuracy 수준: 56%\n",
        "\n",
        "# 1. 상관관계 기준 최소 변수 선정 # test set accuracy 수준: 60.4%\n",
        "# need_cols = ['치석'] + [target_nm] \n",
        "\n",
        "# 2. 치아검사 기준 최소 변수 선정 # test set accuracy 수준: 60.5%\n",
        "# need_cols = ['치석','결손치유무'] + [target_nm] \n",
        "\n",
        "# 3. 외부변수 제외 모델링 # test set accuracy 수준: 62.9%\n",
        "# need_cols = ['A_BMI', 'A_CRE', 'A_GTP', 'A_HDL', 'A_HEMO', 'A_LDL', 'A_TRI', 'A_diabetes', 'A_성별', 'A_시도', 'A_연령대5세단위', 'A_요단백', 'A_음주여부',\n",
        "#        'A_청력우', 'A_청력좌', 'A_흡연상태', 'LN_HDL콜레스테롤', 'LN_LDL콜레스테롤','LN_감마지티피', 'LN_시력우', 'LN_시력좌', 'LN_식전혈당공복혈당', 'LN_트리글리세라이드',\n",
        "#        'LN_혈청지오티ALT', 'LN_혈청지오티AST', 'LN_혈청크레아티닌', 'n_관리_권고', 'n_불소_교육',\n",
        "#        '결손치유무', '수축기혈압', '신장5Cm단위', '이완기혈압','체중5Kg단위', '총콜레스테롤', '치석', '치아우식증유무', '허리둘레', '혈색소']\n",
        "\n",
        "# 4. Information Value 기준 변수 선정(외부변수 추가) # test set accuracy 수준: 62.9%\n",
        "need_cols = df_iv_result.columns\n",
        "\n",
        "# # 5. 최종 모델에 입력 될 변수 선정(수치형 LN 기준 입력) # test set accuracy 수준: 63%\n",
        "# # need_cols = list(set(df_new.columns) - (set(num_ln_target_features + remove_target_candidates) - set([target_nm])))\n",
        "# need_cols = list(set(df_new.columns) - (set(num_ln_target_features + remove_target_candidates) - set([target_nm] + not_remove_in_tg))) \n",
        "\n",
        "df_final = df_new[need_cols].copy()\n",
        "df_final.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZb3q97XEsEY",
        "colab_type": "text"
      },
      "source": [
        "## 5. 모델 입력 전 최종 모델 입력에 맞게 입력 데이터 변형"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tg5YQO8CN8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_x = df_final[df_final.columns.difference([target_nm])]\n",
        "data_y = df_final[target_nm].astype('float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Dk9bmeErpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_attribs = [col for col in data_x.columns if data_x[col].dtype in ['int64','float64']]\n",
        "cat_attribs = [col for col in data_x.columns if data_x[col].dtype not in ['int64','float64']]\n",
        "\n",
        "num_attribs = list(set(num_attribs) - set([target_nm]))\n",
        "\n",
        "print(\"num_attribs: \", num_attribs)\n",
        "print(\"cat_attribs: \", cat_attribs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8IeJKMM-Lpi",
        "colab_type": "text"
      },
      "source": [
        "### 5-1. 수치형 변수 정규화 및 Pipeline 연결\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1LArIWT-pCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Engineering의 일환으로 Log 값 취한 뒤 Normalization을 하여 변수명 + LN (lognorm)으로 열 추가 후 그래프 다시 그림\n",
        "num_pipeline = Pipeline([\n",
        "        ('min_max_scaler', MinMaxScaler()),\n",
        "    ])\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num_pipeline\", num_pipeline, num_attribs),\n",
        "        (\"cat_encoder\", OneHotEncoder(sparse=False), cat_attribs),\n",
        "    ])\n",
        "\n",
        "data_x_piped = full_pipeline.fit_transform(data_x)\n",
        "\n",
        "data_y_piped = data_y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIUuuKv1U-1M",
        "colab_type": "text"
      },
      "source": [
        "### 5-2. Train & Test 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5XgxjU74kFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x, train_y, test_y = train_test_split(data_x_piped, data_y_piped, test_size = 0.2, random_state = set_random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKjGKTPv4kFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(train_x.shape)\n",
        "display(test_x.shape)\n",
        "display(train_y.shape)\n",
        "display(test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REz1lPlhVqLQ",
        "colab_type": "text"
      },
      "source": [
        "### 5-3. 모델 선정 및 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFtwec16DKii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Machine Learning Algorithm (MLA) 선택 및 초기화\n",
        "\n",
        "# 1차 Test 후 좋은 성능을 보인 모델 \n",
        "# ['LogisticRegressionCV', 'RidgeClassifierCV', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'LinearDiscriminantAnalysis', 'XGBClassifier']\n",
        "MLA = [ \n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "    # linear_model.PassiveAggressiveClassifier(),\n",
        "    linear_model.RidgeClassifierCV(),\n",
        "    # linear_model.SGDClassifier(),\n",
        "    # linear_model.Perceptron(),\n",
        "    \n",
        "    #Navies Bayes\n",
        "    naive_bayes.BernoulliNB(),\n",
        "    # naive_bayes.GaussianNB(),\n",
        "    \n",
        "    #Nearest Neighbor\n",
        "    # neighbors.KNeighborsClassifier(),\n",
        "\n",
        "    #Gaussian Processes\n",
        "    # gaussian_process.GaussianProcessClassifier(),\n",
        "\n",
        "    #Trees    \n",
        "    # tree.DecisionTreeClassifier(),\n",
        "    # tree.ExtraTreeClassifier(),\n",
        "\n",
        "    #Ensemble Methods\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    # ensemble.BaggingClassifier(),\n",
        "    # ensemble.ExtraTreesClassifier(),\n",
        "    # ensemble.GradientBoostingClassifier(),\n",
        "    # ensemble.RandomForestClassifier(),\n",
        "       \n",
        "    #Discriminant Analysis\n",
        "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "    # discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "    \n",
        "    #SVM\n",
        "    # svm.SVC(probability=True),\n",
        "    # svm.NuSVC(probability=True),\n",
        "    # svm.LinearSVC(),   \n",
        "\n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    XGBClassifier()\n",
        "    ]\n",
        "\n",
        "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "#note: this is an alternative to train_test_split\n",
        "cv_split = model_selection.ShuffleSplit(n_splits=3, test_size=.3, train_size =.6, random_state=42) # run model 10x with 60/30 split intentionally leaving out 10%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqjlW2Y9DKXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델평가를 위한 변수 세팅\n",
        "score_pram = ['accuracy', 'precision','recall','f1']\n",
        "\n",
        "#Create Table to Compare Canonical Models\n",
        "MLA_Result_columns = ['ModelName','Dataset','Accuracy','Precision','Recall','F1']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_Result_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = pd.DataFrame(train_y)\n",
        "print(MLA_predict.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm-yVCQEVxXG",
        "colab_type": "text"
      },
      "source": [
        "### 5-4. Model 실행 with Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKRXSn47D_2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# index through MLA and save performance to table\n",
        "row_index = 0\n",
        "cv = set_cv\n",
        "# 알고리즘을 하나씩 꺼내면서 loop\n",
        "for alg in tqdm_notebook(MLA):\n",
        "    print(alg, \"algorithm modeling starts ... \")\n",
        "    #알고리즘의 이름은 할당하고, [row_index, MLA Name]에 이름을 넣고, [row_index, MLA Parameters]에 알고리즘의 파라미터들을 할당\n",
        "    Model_Name = alg.__class__.__name__\n",
        "    \n",
        "    cv_results = cross_validate(alg, train_x, train_y, cv=cv, scoring=score_pram, return_train_score=True, n_jobs=-1, verbose=1)\n",
        "    \n",
        "    train_cnt = 0\n",
        "    test_cnt = 0\n",
        "    \n",
        "    for i in cv_results.keys():\n",
        "      if(\"train\" in i and train_cnt == 0):\n",
        "        MLA_compare.loc[row_index, 'ModelName'] = Model_Name\n",
        "        MLA_compare.loc[row_index, 'Dataset'] = \"TrainSet\"\n",
        "        MLA_compare.loc[row_index, 'Accuracy'] = format(cv_results['train_accuracy'].mean(), \"10.4f\")\n",
        "        MLA_compare.loc[row_index, 'Precision'] = format(cv_results['train_precision'].mean(), \"10.4f\")\n",
        "        MLA_compare.loc[row_index, 'Recall'] = format(cv_results['train_recall'].mean(), \"10.4f\")\n",
        "        MLA_compare.loc[row_index, 'F1'] = format(cv_results['train_f1'].mean(), \"10.4f\")\n",
        "        row_index+=1\n",
        "        train_cnt+=1\n",
        "      elif(\"test\" in i and test_cnt ==0):\n",
        "        MLA_compare.loc[row_index, 'ModelName'] = Model_Name\n",
        "        MLA_compare.loc[row_index, 'Dataset'] = \"TestSet\"\n",
        "        MLA_compare.loc[row_index, 'Accuracy'] = format(cv_results['test_accuracy'].mean(), \"10.4f\")\n",
        "        MLA_compare.loc[row_index, 'Precision'] = format(cv_results['test_precision'].mean(), \"10.4f\")\n",
        "        MLA_compare.loc[row_index, 'Recall'] = format(cv_results['test_recall'].mean(), \"10.4f\")\n",
        "        MLA_compare.loc[row_index, 'F1'] = format(cv_results['test_f1'].mean(), \"10.4f\")\n",
        "        row_index+=1\n",
        "        test_cnt+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUcXt7gNG82r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MLA_compare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adPerJQfUQBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_xg_model = XGBClassifier().fit(train_x, train_y)\n",
        "pred_y_xg = model_xg_model.predict_proba(test_x)\n",
        "pred_y_xg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBHfS7ReWYmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(pred_y_xg)\n",
        "# score_df_xg['proba_y'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lXPGLBxWEzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_df_xg = pd.DataFrame(columns=['proba_y', 'real_y'])\n",
        "# print(len(pred_y_xg[:,1]), len(test_y))\n",
        "\n",
        "score_df_xg['proba_y'] = pred_y_xg[:,1]\n",
        "score_df_xg['real_y'] = test_y\n",
        "\n",
        "score_df_xg = score_df_xg.sort_values(by=\"proba_y\", ascending=False)\n",
        "\n",
        "score_df_xg[\"prob_bin\"] = score_df_xg['proba_y'].apply(lambda x: str(x)[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSTgUjZaeE89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f={'proba_y':['count'], 'real_y':['sum']}\n",
        "score_final = score_df_xg.groupby([\"prob_bin\"]).agg(f)\n",
        "display(score_final)\n",
        "score_final['accuracy'] = score_final['real_y'].values/score_final['proba_y'].values\n",
        "score_final['portion'] = score_final['real_y'].values/len(score_final)\n",
        "score_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc4xxJHwDUw6",
        "colab_type": "text"
      },
      "source": [
        "### AUC Graph 그리는 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8fBYYVDT3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auc_graph(roc_auc, fpr, tpr):\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTJ3mIWfppm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep Learning 평가를 위한 평가 함수 정의\n",
        "from keras import backend as K\n",
        "\n",
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "    \n",
        "    # return a single tensor value\n",
        "    return _f1score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcsnrbgSpk20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def creat_dl_model(activation = 'relu', optimizer = 'rmsprop', epochs= 5, batch_size=64, init='glorot_uniform'):\n",
        "  input_dim = train_x.shape[1]\n",
        "  # batch_size = 64\n",
        "#   epochs = 50\n",
        "  print(\"activation is  \", activation, \", optimizer is  \", optimizer, \", epochs are \", epochs , \", batch_size is \", batch_size, \", init is \", init)\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # 첫 번째 Layer (Input layer)\n",
        "  model.add(Dense(input_dim=input_dim, init=init, activation=activation, output_dim=128))\n",
        "  # model.add(Dropout(0.2)) # 30% 정도를 Drop \n",
        "\n",
        "  # 두 번째 Layer (Hidden layer 1)\n",
        "  model.add(Dense(output_dim=128, init=init, activation=activation))\n",
        "  # model.add(Dropout(0.2)) # 30% 정도를 Drop \n",
        "\n",
        "  # 세 번째 Layer (Hidden layer 2)\n",
        "  model.add(Dense(output_dim=256, init=init, activation=activation))\n",
        "  # model.add(Dropout(0.2)) # 30% 정도를 Drop \n",
        "\n",
        "  # 네 번째 Layer (Hidden layer 3)\n",
        "  model.add(Dense(output_dim=512, init=init, activation=activation))\n",
        "  # model.add(Dropout(0.2)) # 30% 정도를 Drop \n",
        "\n",
        "  # # 다섯 번째 Layer (Hidden layer 4)\n",
        "  model.add(Dense(output_dim=512, init=init, activation=activation))\n",
        "  model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
        "\n",
        "  # 여섯 번째 Layer (Output layer)\n",
        "  model.add(Dense(output_dim=1))\n",
        "  model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "  # Cost function 및 Optimizer 설정 # binary class 분류이므로 binary_crossentropy 사용 # Adam optimizer 사용\n",
        "  # ffn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', precision, recall, f1score])\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', precision, recall, f1score])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TRqL6kzfvWx",
        "colab_type": "code",
        "outputId": "4a746a30-5b21-47a0-b17b-691a9187efab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_dl = KerasClassifier(build_fn=creat_dl_model, verbose=2)\n",
        "\n",
        "# grid search epochs, batch size and optimizer\n",
        "# optimizers = ['rmsprop', 'adam']\n",
        "# optimizers = ['adam', 'Nadam', 'Adadelta']\n",
        "optimizers = ['adam']\n",
        "\n",
        "# lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.1)\n",
        "# activations = [lrelu, 'relu', 'tanh']\n",
        "# activations = ['elu', 'tanh']\n",
        "activations = ['tanh']\n",
        "\n",
        "# init = ['glorot_uniform', 'normal', 'uniform']\n",
        "init = ['glorot_uniform']\n",
        "\n",
        "epochs = [10,15]\n",
        "\n",
        "# batches = [10, 50, 100]\n",
        "# batches = [64,128]\n",
        "batches = [64]\n",
        "\n",
        "print(\"Total iteration will be \", len(optimizers) * len(activations) * len(init) * len(epochs) * len(batches))\n",
        "\n",
        "param_grid = dict(optimizer=optimizers, activation = activations, epochs=epochs, batch_size=batches, init=init)\n",
        "\n",
        "cv = set_cv\n",
        "grid = GridSearchCV(estimator=model_dl, param_grid=param_grid, cv=cv)\n",
        "grid_result = grid.fit(train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total iteration will be  2\n",
            "activation is   tanh , optimizer is   adam , epochs are  10 , batch_size is  64 , init is  glorot_uniform\n",
            "Epoch 1/10\n",
            " - 15s - loss: 0.6567 - acc: 0.6145 - precision: 0.6165 - recall: 0.6085 - f1score: 0.6059\n",
            "Epoch 2/10\n",
            " - 14s - loss: 0.6520 - acc: 0.6192 - precision: 0.6209 - recall: 0.6136 - f1score: 0.6119\n",
            "Epoch 3/10\n",
            " - 14s - loss: 0.6520 - acc: 0.6209 - precision: 0.6229 - recall: 0.6156 - f1score: 0.6137\n",
            "Epoch 4/10\n",
            " - 14s - loss: 0.6518 - acc: 0.6206 - precision: 0.6220 - recall: 0.6162 - f1score: 0.6136\n",
            "Epoch 5/10\n",
            " - 14s - loss: 0.6516 - acc: 0.6207 - precision: 0.6217 - recall: 0.6214 - f1score: 0.6158\n",
            "Epoch 6/10\n",
            " - 14s - loss: 0.6509 - acc: 0.6213 - precision: 0.6227 - recall: 0.6183 - f1score: 0.6151\n",
            "Epoch 7/10\n",
            " - 14s - loss: 0.6506 - acc: 0.6217 - precision: 0.6231 - recall: 0.6193 - f1score: 0.6154\n",
            "Epoch 8/10\n",
            " - 14s - loss: 0.6498 - acc: 0.6228 - precision: 0.6244 - recall: 0.6194 - f1score: 0.6159\n",
            "Epoch 9/10\n",
            " - 14s - loss: 0.6497 - acc: 0.6220 - precision: 0.6225 - recall: 0.6221 - f1score: 0.6163\n",
            "Epoch 10/10\n",
            " - 14s - loss: 0.6489 - acc: 0.6213 - precision: 0.6217 - recall: 0.6256 - f1score: 0.6178\n",
            "activation is   tanh , optimizer is   adam , epochs are  10 , batch_size is  64 , init is  glorot_uniform\n",
            "Epoch 1/10\n",
            " - 16s - loss: 0.6581 - acc: 0.6129 - precision: 0.6169 - recall: 0.6104 - f1score: 0.6063\n",
            "Epoch 2/10\n",
            " - 14s - loss: 0.6539 - acc: 0.6188 - precision: 0.6230 - recall: 0.6145 - f1score: 0.6133\n",
            "Epoch 3/10\n",
            " - 14s - loss: 0.6536 - acc: 0.6202 - precision: 0.6254 - recall: 0.6123 - f1score: 0.6130\n",
            "Epoch 4/10\n",
            " - 14s - loss: 0.6534 - acc: 0.6193 - precision: 0.6243 - recall: 0.6134 - f1score: 0.6127\n",
            "Epoch 5/10\n",
            " - 14s - loss: 0.6527 - acc: 0.6186 - precision: 0.6225 - recall: 0.6130 - f1score: 0.6124\n",
            "Epoch 6/10\n",
            " - 14s - loss: 0.6525 - acc: 0.6203 - precision: 0.6253 - recall: 0.6143 - f1score: 0.6138\n",
            "Epoch 7/10\n",
            " - 14s - loss: 0.6512 - acc: 0.6210 - precision: 0.6257 - recall: 0.6146 - f1score: 0.6143\n",
            "Epoch 8/10\n",
            " - 14s - loss: 0.6512 - acc: 0.6206 - precision: 0.6243 - recall: 0.6192 - f1score: 0.6156\n",
            "Epoch 9/10\n",
            " - 14s - loss: 0.6507 - acc: 0.6199 - precision: 0.6242 - recall: 0.6200 - f1score: 0.6159\n",
            "Epoch 10/10\n",
            " - 14s - loss: 0.6500 - acc: 0.6204 - precision: 0.6228 - recall: 0.6258 - f1score: 0.6182\n",
            "activation is   tanh , optimizer is   adam , epochs are  15 , batch_size is  64 , init is  glorot_uniform\n",
            "Epoch 1/15\n",
            " - 16s - loss: 0.6568 - acc: 0.6144 - precision: 0.6164 - recall: 0.6127 - f1score: 0.6079\n",
            "Epoch 2/15\n",
            " - 14s - loss: 0.6528 - acc: 0.6195 - precision: 0.6212 - recall: 0.6160 - f1score: 0.6130\n",
            "Epoch 3/15\n",
            " - 14s - loss: 0.6528 - acc: 0.6198 - precision: 0.6213 - recall: 0.6175 - f1score: 0.6137\n",
            "Epoch 4/15\n",
            " - 14s - loss: 0.6522 - acc: 0.6206 - precision: 0.6234 - recall: 0.6136 - f1score: 0.6124\n",
            "Epoch 5/15\n",
            " - 14s - loss: 0.6514 - acc: 0.6210 - precision: 0.6229 - recall: 0.6156 - f1score: 0.6137\n",
            "Epoch 6/15\n",
            " - 14s - loss: 0.6512 - acc: 0.6217 - precision: 0.6227 - recall: 0.6180 - f1score: 0.6151\n",
            "Epoch 7/15\n",
            " - 13s - loss: 0.6508 - acc: 0.6216 - precision: 0.6237 - recall: 0.6175 - f1score: 0.6146\n",
            "Epoch 8/15\n",
            " - 14s - loss: 0.6500 - acc: 0.6217 - precision: 0.6234 - recall: 0.6198 - f1score: 0.6161\n",
            "Epoch 9/15\n",
            " - 14s - loss: 0.6494 - acc: 0.6230 - precision: 0.6233 - recall: 0.6258 - f1score: 0.6188\n",
            "Epoch 10/15\n",
            " - 14s - loss: 0.6492 - acc: 0.6227 - precision: 0.6231 - recall: 0.6232 - f1score: 0.6174\n",
            "Epoch 11/15\n",
            " - 14s - loss: 0.6487 - acc: 0.6232 - precision: 0.6229 - recall: 0.6266 - f1score: 0.6193\n",
            "Epoch 12/15\n",
            " - 14s - loss: 0.6480 - acc: 0.6231 - precision: 0.6225 - recall: 0.6277 - f1score: 0.6194\n",
            "Epoch 13/15\n",
            " - 14s - loss: 0.6477 - acc: 0.6226 - precision: 0.6223 - recall: 0.6253 - f1score: 0.6179\n",
            "Epoch 14/15\n",
            " - 14s - loss: 0.6477 - acc: 0.6229 - precision: 0.6225 - recall: 0.6259 - f1score: 0.6186\n",
            "Epoch 15/15\n",
            " - 13s - loss: 0.6474 - acc: 0.6243 - precision: 0.6248 - recall: 0.6242 - f1score: 0.6186\n",
            "activation is   tanh , optimizer is   adam , epochs are  15 , batch_size is  64 , init is  glorot_uniform\n",
            "Epoch 1/15\n",
            " - 17s - loss: 0.6580 - acc: 0.6122 - precision: 0.6166 - recall: 0.6102 - f1score: 0.6060\n",
            "Epoch 2/15\n",
            " - 14s - loss: 0.6536 - acc: 0.6191 - precision: 0.6227 - recall: 0.6166 - f1score: 0.6142\n",
            "Epoch 3/15\n",
            " - 15s - loss: 0.6536 - acc: 0.6201 - precision: 0.6246 - recall: 0.6157 - f1score: 0.6145\n",
            "Epoch 4/15\n",
            " - 14s - loss: 0.6533 - acc: 0.6189 - precision: 0.6231 - recall: 0.6134 - f1score: 0.6124\n",
            "Epoch 5/15\n",
            " - 14s - loss: 0.6525 - acc: 0.6190 - precision: 0.6224 - recall: 0.6140 - f1score: 0.6130\n",
            "Epoch 6/15\n",
            " - 14s - loss: 0.6525 - acc: 0.6203 - precision: 0.6255 - recall: 0.6136 - f1score: 0.6139\n",
            "Epoch 7/15\n",
            " - 14s - loss: 0.6516 - acc: 0.6216 - precision: 0.6254 - recall: 0.6190 - f1score: 0.6165\n",
            "Epoch 8/15\n",
            " - 14s - loss: 0.6516 - acc: 0.6211 - precision: 0.6246 - recall: 0.6165 - f1score: 0.6150\n",
            "Epoch 9/15\n",
            " - 14s - loss: 0.6506 - acc: 0.6218 - precision: 0.6262 - recall: 0.6189 - f1score: 0.6165\n",
            "Epoch 10/15\n",
            " - 14s - loss: 0.6502 - acc: 0.6230 - precision: 0.6263 - recall: 0.6226 - f1score: 0.6189\n",
            "Epoch 11/15\n",
            " - 15s - loss: 0.6501 - acc: 0.6209 - precision: 0.6230 - recall: 0.6248 - f1score: 0.6180\n",
            "Epoch 12/15\n",
            " - 14s - loss: 0.6495 - acc: 0.6223 - precision: 0.6255 - recall: 0.6215 - f1score: 0.6175\n",
            "Epoch 13/15\n",
            " - 14s - loss: 0.6488 - acc: 0.6227 - precision: 0.6256 - recall: 0.6227 - f1score: 0.6184\n",
            "Epoch 14/15\n",
            " - 14s - loss: 0.6490 - acc: 0.6228 - precision: 0.6266 - recall: 0.6219 - f1score: 0.6182\n",
            "Epoch 15/15\n",
            " - 14s - loss: 0.6485 - acc: 0.6239 - precision: 0.6270 - recall: 0.6227 - f1score: 0.6191\n",
            "activation is   tanh , optimizer is   adam , epochs are  10 , batch_size is  64 , init is  glorot_uniform\n",
            "Epoch 1/10\n",
            " - 31s - loss: 0.6554 - acc: 0.6166 - precision: 0.6191 - recall: 0.6134 - f1score: 0.6100\n",
            "Epoch 2/10\n",
            " - 28s - loss: 0.6528 - acc: 0.6205 - precision: 0.6244 - recall: 0.6119 - f1score: 0.6124\n",
            "Epoch 3/10\n",
            " - 28s - loss: 0.6519 - acc: 0.6211 - precision: 0.6248 - recall: 0.6141 - f1score: 0.6139\n",
            "Epoch 4/10\n",
            " - 28s - loss: 0.6514 - acc: 0.6209 - precision: 0.6232 - recall: 0.6185 - f1score: 0.6153\n",
            "Epoch 5/10\n",
            " - 28s - loss: 0.6509 - acc: 0.6214 - precision: 0.6232 - recall: 0.6213 - f1score: 0.6166\n",
            "Epoch 6/10\n",
            " - 28s - loss: 0.6502 - acc: 0.6217 - precision: 0.6240 - recall: 0.6200 - f1score: 0.6162\n",
            "Epoch 7/10\n",
            " - 28s - loss: 0.6493 - acc: 0.6215 - precision: 0.6221 - recall: 0.6263 - f1score: 0.6182\n",
            "Epoch 8/10\n",
            " - 28s - loss: 0.6491 - acc: 0.6218 - precision: 0.6229 - recall: 0.6239 - f1score: 0.6177\n",
            "Epoch 9/10\n",
            " - 29s - loss: 0.6487 - acc: 0.6223 - precision: 0.6231 - recall: 0.6266 - f1score: 0.6190\n",
            "Epoch 10/10\n",
            " - 28s - loss: 0.6486 - acc: 0.6219 - precision: 0.6225 - recall: 0.6270 - f1score: 0.6191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca8c2zoznBzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbyE16FVnCw_",
        "colab_type": "text"
      },
      "source": [
        "### 개별 모델 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrkz3x7fnCnE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3mbrtOZbnx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep Learning Single 모델 돌릴 때 사용\n",
        "\n",
        "# model training\n",
        "lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.1)\n",
        "activation = lrelu\n",
        "\n",
        "model_dl1 = KerasClassifier(build_fn = creat_dl_model, optimizer= 'adam', activation = 'tanh', epochs=5, batch_size=64, init='glorot_uniform')\n",
        "model_dl2 = KerasClassifier(build_fn = creat_dl_model, optimizer= 'adam', activation = 'elu', epochs=10, batch_size=64, init='glorot_uniform')\n",
        "model_dl3 = KerasClassifier(build_fn = creat_dl_model, optimizer= 'adam', activation = lrelu, epochs=10, batch_size=64, init='glorot_uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJaZbAdzpzxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dl1_run = model_dl1.fit(train_x, train_y)\n",
        "pred_y_dl1 = model_dl1.predict(test_x)\n",
        "pred_y_dl1 = (pred_y_dl1>0.5)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_dl1)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_dl1))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_dl1))\n",
        "\n",
        "roc_auc_dl1 = roc_auc_score(test_y, pred_y_dl1)\n",
        "print(\"roc_auc score is : \", roc_auc_dl1)\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_dl1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zdf4F4xWeplo",
        "colab": {}
      },
      "source": [
        "model_dl2_run = model_dl2.fit(train_x, train_y)\n",
        "\n",
        "pred_y_dl2 = model_dl2.predict(test_x)\n",
        "pred_y_dl2 = (pred_y_dl2>0.5)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_dl2)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_dl2))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_dl2))\n",
        "\n",
        "roc_auc_dl2 = roc_auc_score(test_y, pred_y_dl2)\n",
        "print(\"roc_auc score is : \", roc_auc_dl2)\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_dl2)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0KDJCTx9en8L",
        "colab": {}
      },
      "source": [
        "model_dl3_run = model_dl3.fit(train_x, train_y)\n",
        "\n",
        "pred_y_dl3 = model_dl3.predict(test_x)\n",
        "pred_y_dl3 = (pred_y_dl3>0.5)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_dl3)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_dl3))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_dl3))\n",
        "\n",
        "roc_auc_dl3 = roc_auc_score(test_y, pred_y_dl3)\n",
        "print(\"roc_auc score is : \", roc_auc_dl3)\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_dl3)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaJGjQEZhMXn",
        "colab_type": "text"
      },
      "source": [
        "### 성능이 좋은 모델들의 Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrGy91Em0bit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_split = ShuffleSplit(n_splits=3, test_size=.3, train_size =.6, random_state=set_random_seed) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "verboseNo = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVZ9P9Xm4kFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LogisticRegressionCV\n",
        "model_lr = linear_model.LogisticRegression()\n",
        "\n",
        "param_grid = {'C': np.logspace(-3,3,7), 'penalty': ['l1', 'l2']}\n",
        "\n",
        "grid_lr = GridSearchCV(model_lr,param_grid = param_grid, cv=cv_split, scoring=\"f1\", n_jobs= -1, verbose = verboseNo)\n",
        "grid_lr.fit(train_x, train_y)\n",
        "grid_lr_best = grid_lr.best_estimator_\n",
        "print(grid_lr_best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPxiUlkOU4AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y_lr = grid_lr_best.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_lr)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_lr))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_lr))\n",
        "\n",
        "roc_auc_lr = roc_auc_score(test_y, pred_y_lr)\n",
        "print(roc_auc_lr)\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_lr)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYnr5L0L2RoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RidgeClassifierCV\n",
        "model_rc = linear_model.RidgeClassifier()\n",
        "\n",
        "param_grid = {'alpha':[1e-3, 1e-2, 1e-1, 1]}\n",
        "\n",
        "grid_rc = GridSearchCV(model_rc,param_grid = param_grid, cv=cv_split, scoring=\"f1\", n_jobs= -1, verbose = verboseNo)\n",
        "grid_rc.fit(train_x, train_y)\n",
        "grid_rc_best = grid_rc.best_estimator_\n",
        "print(grid_rc_best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J-t_ofKVvO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y_rc = grid_rc_best.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_rc)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_rc))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_rc))\n",
        "\n",
        "roc_auc_rc = roc_auc_score(test_y, pred_y_rc)\n",
        "print(\"AUC Score : {:.5f}\".format(roc_auc_rc))\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_rc)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgXaGEB7LDqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AdaBoostClassifier\n",
        "model_ab = ensemble.AdaBoostClassifier()\n",
        "\n",
        "param_grid = {'n_estimators': [16, 32]}\n",
        "\n",
        "grid_ab = GridSearchCV(model_ab,param_grid = param_grid, cv=cv_split, scoring=\"f1\", n_jobs= -1, verbose = verboseNo)\n",
        "grid_ab.fit(train_x, train_y)\n",
        "grid_ab_best = grid_ab.best_estimator_\n",
        "print(grid_ab_best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSnmjadPV7FT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y_ab = grid_ab_best.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_ab)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_ab))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_ab))\n",
        "\n",
        "roc_auc_ab = roc_auc_score(test_y, pred_y_ab)\n",
        "print(\"AUC Score : {:.5f}\".format(roc_auc_ab))\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_ab)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdUDNhWpLDn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GradientBoostingClassifier\n",
        "model_gb = ensemble.GradientBoostingClassifier()\n",
        "\n",
        "param_grid = {'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0]}\n",
        "\n",
        "grid_gb = GridSearchCV(model_gb,param_grid = param_grid, cv=cv_split, scoring=\"f1\", n_jobs= -1, verbose = verboseNo)\n",
        "grid_gb.fit(train_x, train_y)\n",
        "grid_gb_best = grid_gb.best_estimator_\n",
        "print(grid_gb_best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTzvXKZGWG1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y_gb = grid_gb_best.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_gb)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_gb))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_gb))\n",
        "\n",
        "roc_auc_gb = roc_auc_score(test_y, pred_y_gb)\n",
        "print(\"AUC Score : {:.5f}\".format(roc_auc_gb))\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_gb)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6YeRb8QLDlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LinearDiscriminantAnalysis\n",
        "## LDA(선형판별분석(Linear Discriminant Analysis):데이터를 특정 한 축에 사영(projection)한 후에 두 범주를 잘 구분할 수 있는 직선을 찾는 걸 목표\n",
        "model_ld = discriminant_analysis.LinearDiscriminantAnalysis()\n",
        "\n",
        "param_grid = {'solver': ['svd', 'lsqr']}\n",
        "\n",
        "grid_ld = GridSearchCV(model_ld,param_grid = param_grid, cv=cv_split, scoring=\"f1\", n_jobs= -1, verbose = verboseNo)\n",
        "grid_ld.fit(train_x, train_y)\n",
        "grid_ld_best = grid_ld.best_estimator_\n",
        "print(grid_ld_best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK_HM3j8XO6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y_ld = grid_ld_best.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_ld)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_ld))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_ld))\n",
        "\n",
        "roc_auc_ld = roc_auc_score(test_y, pred_y_ld)\n",
        "print(\"AUC Score : {:.5f}\".format(roc_auc_ld))\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_ld)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFNoZqxNLDi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XGBClassifier\n",
        "model_xg = XGBClassifier()\n",
        "\n",
        "param_grid = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
        "              'objective':['binary:logistic'],\n",
        "              'learning_rate': [0.05], #so called `eta` value\n",
        "              'max_depth': [6],\n",
        "              'min_child_weight': [11],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.8],\n",
        "              'colsample_bytree': [0.7],\n",
        "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
        "              'missing':[-999],\n",
        "              'seed': [1337]}\n",
        "\n",
        "grid_xg = GridSearchCV(model_xg,param_grid = param_grid, cv=cv_split, scoring=\"f1\", n_jobs= -1, verbose = verboseNo)\n",
        "grid_xg.fit(train_x, train_y)\n",
        "grid_xg_best = grid_xg.best_estimator_\n",
        "print(grid_xg_best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaYaWb6rLDgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y_xg = grid_xg_best.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_xg)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_xg))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_xg))\n",
        "\n",
        "roc_auc_xg = roc_auc_score(test_y, pred_y_xg)\n",
        "print(\"AUC Score : {:.5f}\".format(roc_auc_xg))\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_xg)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmNWezMRhJZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # XGBoost Test\n",
        "# xgb_clf = XGBClassifier(nthreads=-1)\n",
        "\n",
        "# one_to_left = st.beta(100, 1)  \n",
        "# from_zero_positive = st.expon(0, 50)\n",
        "\n",
        "# params = {  \n",
        "#     \"n_estimators\": st.randint(3, 100),\n",
        "#     \"max_depth\": st.randint(3, 40),\n",
        "#     \"learning_rate\": st.uniform(0.05, 0.9),\n",
        "#     \"colsample_bytree\": one_to_left,\n",
        "#     \"subsample\": one_to_left,\n",
        "#     \"gamma\": st.uniform(0, 10),\n",
        "#     'reg_alpha': from_zero_positive,\n",
        "#     \"min_child_weight\": from_zero_positive,\n",
        "# }\n",
        "\n",
        "# rand_search = RandomizedSearchCV(xgb_clf, params, n_jobs=1, cv=100)  \n",
        "# rand_search.fit(x_train, y_train) \n",
        "# xgb_best = rand_search.best_estimator_\n",
        "# print(rand_search.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3dzERZNhTSO",
        "colab_type": "text"
      },
      "source": [
        "## 결과 앙상블로 모델 결과 최적화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpV_sYdchLgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "votingC = VotingClassifier(estimators=[('model_lr',grid_lr_best),('model_ab', grid_ab_best),\n",
        "                                       ('model_gb', grid_gb_best),('model_ld', grid_ld_best), ('model_xg',grid_xg_best)], \n",
        "                           voting='soft', n_jobs=-1)\n",
        "\n",
        "votingC = votingC.fit(train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cACSFDvVvwUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# soft voting을 통한 성능 향상\n",
        "pred_y_vc = votingC.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_vc)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_vc))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_vc))\n",
        "\n",
        "roc_auc_vc = roc_auc_score(test_y, pred_y_vc)\n",
        "print(\"AUC Score : {:.5f}\".format(roc_auc_vc))\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_vc)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei1RSRzZvuMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "votingC1 = VotingClassifier(estimators=[('model_lr',grid_lr_best),('model_ab', grid_ab_best),('model_gb', grid_gb_best)\n",
        "                                       ,('model_ld', grid_ld_best), ('model_xg',grid_xg_best), ('model_dl',model_dl)], \n",
        "                           voting='soft')\n",
        "\n",
        "votingC1 = votingC1.fit(train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyQ-B28E9DAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# soft voting을 통한 성능 향상\n",
        "pred_y_vc1 = votingC1.predict(test_x)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_vc1)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_vc1))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_vc1))\n",
        "\n",
        "roc_auc_vc1 = roc_auc_score(test_y, pred_y_vc1)\n",
        "print(\"AUC Score : {:.5f}\".format(roc_auc_vc1))\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_vc1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7L5UQgybyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}