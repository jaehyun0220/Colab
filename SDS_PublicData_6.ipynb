{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDS_PublicData#6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun0220/Colab/blob/master/SDS_PublicData_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFW4i1H_63WG",
        "colab_type": "text"
      },
      "source": [
        "## 3조. 건강검진 데이터를 활용한 치아우식증 발생 예측\n",
        "#### # Ver 6. Keras 활용 MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbUuUBLq6o5n",
        "colab_type": "code",
        "outputId": "0474e629-405c-4432-be94-10468d55ec93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Auth 인증 및 Google Drive 활용 Data load\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-RQ4wm563Cr",
        "colab_type": "text"
      },
      "source": [
        "#### #2. 작업환경 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjHIIUYEXh6n",
        "colab_type": "code",
        "outputId": "1509bfab-d79d-4c16-de14-218cf6efddaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# woe package install\n",
        "! pip install woe"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: woe in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from woe) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from woe) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from woe) (1.17.4)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from woe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->woe) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->woe) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->woe) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->woe) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->woe) (2.4.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.19.2->woe) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->woe) (41.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0KCYMzm7Iv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기본 라이브러리 로드\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터 전처리 관련 라이브러리 로드\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "#모델 알고리즘 로드\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "\n",
        "#차원축소 알고리즘 로드\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Calculate IV Setting\n",
        "import pandas.core.algorithms as algos\n",
        "from pandas import Series\n",
        "import scipy.stats.stats as stats\n",
        "import traceback\n",
        "import string\n",
        "import woe\n",
        "from woe.eval import plot_ks\n",
        "\n",
        "# Deep Learning Model 로드\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "# Pytorch 로드\n",
        "import torch\n",
        "import torch.nn as nn # for neural net # nn: Deep learning model에 필요한 모듈이 모아져 있는 패키지 ex) nn.Linear(128, 128), nn.ReLU()\n",
        "import torch.nn.functional as F # F: nn과 같은 모듈이 모아져 있지만 함수의 input으로 반드시 연산이 되어야 하는 값을 받습니다. ex) F.linear(X, 128, 128), R.relu(X)\n",
        "import torch.optim as optim # 학습에 관련된 optimizing method가 있는 패키지\n",
        "import torch.utils.data as data_utils # batch generator 등 학습 데이터에 관련된 패키지\n",
        "\n",
        "#HyperParameter Tuning을 위한 라이브러리 로드\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#모델 평가를 위한 라이브러리 로드\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\n",
        "\n",
        "#수학 & 통계 관련 라이브러리 로드\n",
        "import scipy.stats as st\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl  # 기본 설정 만지는 용도\n",
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도\n",
        "\n",
        "\n",
        "#Configure Visualization Defaults\n",
        "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
        "%matplotlib inline\n",
        "mpl.style.use('ggplot')\n",
        "sns.set_style('white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUDEfenP7Rdl",
        "colab_type": "text"
      },
      "source": [
        "#### #3.사용할 사용자 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igQsIjbj7ON5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auc_graph(roc_auc, fpr, tpr):\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()\n",
        "\n",
        "# Define a binning function for continous independent variables\n",
        "max_bin = 20\n",
        "force_bin = 3\n",
        "\n",
        "def mono_bin(Y, X, n = max_bin):\n",
        "  df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
        "  justmiss = df1[['X','Y']][df1.X.isnull()]\n",
        "  notmiss = df1[['X','Y']][df1.X.notnull()]\n",
        "  r = 0\n",
        "  while np.abs(r) < 1:\n",
        "    try:\n",
        "      global d1\n",
        "      global d2\n",
        "      d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
        "      d2 = d1.groupby('Bucket', as_index=True)\n",
        "      r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
        "      n = n - 1 \n",
        "    except Exception as e:\n",
        "      n = n - 1\n",
        "      break\n",
        "      \n",
        "  if len(d2) == 1:\n",
        "    n = force_bin         \n",
        "    bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
        "    if len(np.unique(bins)) == 2:\n",
        "        bins = np.insert(bins, 0, 1)\n",
        "        bins[1] = bins[1]-(bins[1]/2)\n",
        "    d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
        "    d2 = d1.groupby('Bucket', as_index=True)\n",
        "\n",
        "  d3 = pd.DataFrame({},index=[])\n",
        "  d3[\"MIN_VALUE\"] = d2.min().X\n",
        "  d3[\"MAX_VALUE\"] = d2.max().X\n",
        "  d3[\"COUNT\"] = d2.count().Y\n",
        "  d3[\"EVENT\"] = d2.sum().Y\n",
        "  d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n",
        "  d3=d3.reset_index(drop=True)\n",
        "\n",
        "  if len(justmiss.index) > 0:\n",
        "      d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
        "      d4[\"MAX_VALUE\"] = np.nan\n",
        "      d4[\"COUNT\"] = justmiss.count().Y\n",
        "      d4[\"EVENT\"] = justmiss.sum().Y\n",
        "      d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
        "      d3 = d3.append(d4,ignore_index=True)\n",
        "\n",
        "  d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
        "  d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
        "  d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
        "  d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
        "  d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"VAR_NAME\"] = \"VAR\"\n",
        "  d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
        "  d3 = d3.replace([np.inf, -np.inf], 0)\n",
        "  d3.IV = d3.IV.sum()\n",
        "\n",
        "  return(d3)\n",
        "  \n",
        "# Define a binning function for categorical independent variables\n",
        "def char_bin(Y, X):\n",
        "  df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
        "  justmiss = df1[['X','Y']][df1.X.isnull()]\n",
        "  notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
        "  df2 = notmiss.groupby('X',as_index=True)\n",
        "\n",
        "  d3 = pd.DataFrame({},index=[])\n",
        "  d3[\"COUNT\"] = df2.count().Y\n",
        "  d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
        "  d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
        "  d3[\"EVENT\"] = df2.sum().Y\n",
        "  d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
        "\n",
        "  if len(justmiss.index) > 0:\n",
        "    d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
        "    d4[\"MAX_VALUE\"] = np.nan\n",
        "    d4[\"COUNT\"] = justmiss.count().Y\n",
        "    d4[\"EVENT\"] = justmiss.sum().Y\n",
        "    d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
        "    d3 = d3.append(d4,ignore_index=True)\n",
        "\n",
        "  d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
        "  d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
        "  d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
        "  d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
        "  d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "  d3[\"VAR_NAME\"] = \"VAR\"\n",
        "  d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
        "  d3 = d3.replace([np.inf, -np.inf], 0)\n",
        "  d3.IV = d3.IV.sum()\n",
        "  d3 = d3.reset_index(drop=True)\n",
        "\n",
        "  return(d3)\n",
        "\n",
        "# Calculate Information Values\n",
        "def calc_iv_all(df1, target):\n",
        "    \n",
        "  stack = traceback.extract_stack()\n",
        "  filename, lineno, function_name, code = stack[-2]\n",
        "  vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
        "  final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
        "\n",
        "  x = df1.dtypes.index\n",
        "  count = -1\n",
        "\n",
        "  for i in tqdm_notebook(x):\n",
        "    if i.upper() not in (final.upper()):\n",
        "      if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
        "        conv = mono_bin(target, df1[i])\n",
        "        conv[\"VAR_NAME\"] = i\n",
        "        count = count + 1\n",
        "      else:\n",
        "        conv = char_bin(target, df1[i])\n",
        "        conv[\"VAR_NAME\"] = i            \n",
        "        count = count + 1\n",
        "\n",
        "      if count == 0:\n",
        "        iv_df = conv\n",
        "      else:\n",
        "        iv_df = iv_df.append(conv,ignore_index=True)\n",
        "\n",
        "  iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n",
        "  iv = iv.reset_index()\n",
        "  return(iv_df,iv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa1S7ugaqFtt",
        "colab_type": "text"
      },
      "source": [
        "##### #3-1. Keras를 위한 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN-h8mLoqEuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep Learning 평가를 위한 평가 함수 정의\n",
        "from keras import backend as K\n",
        "\n",
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "    \n",
        "    # return a single tensor value\n",
        "    return _f1score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kde9-tsZ7vhS",
        "colab_type": "text"
      },
      "source": [
        "#### #4.원천 데이터 load 및 seed 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69HLpZvl7v0v",
        "colab_type": "code",
        "outputId": "5118e7bd-7ca8-49ec-bb6a-dde1e4ba752d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "source": [
        "set_random_seed = 2580 # seed 지정\n",
        "target_nm = 'dental_carries' # 타겟 변수 지정\n",
        "\n",
        "#### 2013년 기준 #########################################################################################################################################\n",
        "df_raw_2013 = pd.read_csv('../gdrive/My Drive/sds/data/NHIS_OPEN_GJ_2013_eng.csv', encoding = 'euc-kr')\n",
        "\n",
        "# 컬럼명 내 불필요한 공백 및 특수문자 제거\n",
        "df_raw_2013.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "\n",
        "# 구강검진 결과가 있는 데이터셋만 load\n",
        "df_data = df_raw_2013[df_raw_2013['examine_mouth']==1]\n",
        "\n",
        "# 분석과 관련 없는 변수 제거\n",
        "del_cols = ['baseyear', 'id', 'data_open_date','examine_mouth']\n",
        "df_data.drop(columns=del_cols, axis=1, inplace=True)\n",
        "\n",
        "# 치아우식증 결과가 있는 데이터만 끌고 옴\n",
        "df_data = df_data[~(df_data['dental_carries'].isnull()) & (df_data['dental_carries'] != 2)]\n",
        "\n",
        "# null 포함 데이터 모두 삭제 \n",
        "df_data.dropna(how='any', inplace=True)\n",
        "display(df_data.info())\n",
        "print(len(df_data))\n",
        "\n",
        "print(df_data[target_nm].value_counts())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 380657 entries, 3 to 999998\n",
            "Data columns (total 30 columns):\n",
            "sex                      380657 non-null int64\n",
            "ageband                  380657 non-null int64\n",
            "province                 380657 non-null int64\n",
            "height                   380657 non-null int64\n",
            "weight                   380657 non-null int64\n",
            "waist                    380657 non-null int64\n",
            "sight_l                  380657 non-null float64\n",
            "sight_r                  380657 non-null float64\n",
            "hearing_l                380657 non-null float64\n",
            "hearing_r                380657 non-null float64\n",
            "bp_systolic              380657 non-null int64\n",
            "bp_diastolic             380657 non-null int64\n",
            "bs_before                380657 non-null int64\n",
            "tot_cholesterol          380657 non-null int64\n",
            "triglycerides            380657 non-null int64\n",
            "HDL_cholesterol          380657 non-null int64\n",
            "LDL_cholesterol          380657 non-null float64\n",
            "hemoglobin               380657 non-null float64\n",
            "piu                      380657 non-null float64\n",
            "serum_creatinine         380657 non-null float64\n",
            "AST                      380657 non-null int64\n",
            "ALT                      380657 non-null int64\n",
            "GammaGTP                 380657 non-null int64\n",
            "smoking                  380657 non-null float64\n",
            "drinking                 380657 non-null float64\n",
            "dental_carries           380657 non-null float64\n",
            "missing_tooth            380657 non-null float64\n",
            "dental_abrasion          380657 non-null float64\n",
            "wisdom_teeth_abnormal    380657 non-null float64\n",
            "plaque                   380657 non-null float64\n",
            "dtypes: float64(15), int64(15)\n",
            "memory usage: 90.0 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "380657\n",
            "0.0    288017\n",
            "1.0     92640\n",
            "Name: dental_carries, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH0vKa9Y-frQ",
        "colab_type": "text"
      },
      "source": [
        "#### #5. 데이터샘플링 및 Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvLVC4de8VL3",
        "colab_type": "code",
        "outputId": "44271e75-2d29-4033-a1f3-c1f0e2c9f167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 치아우식 0과 1의 값을 9만건씩 총 18만건 추출\n",
        "df_sample = df_data.groupby(target_nm).apply(lambda x: x.sample(n=50000, random_state=set_random_seed)).copy()\n",
        "df_sample.reset_index(drop=True, inplace=True)\n",
        "print(df_sample[target_nm].value_counts())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0    50000\n",
            "0.0    50000\n",
            "Name: dental_carries, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Uj02jC6EECx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 명목형 변수 변경\n",
        "category_features = ['sex', 'ageband', 'height', 'weight','province', 'hearing_l', 'hearing_r', 'smoking','drinking', 'piu']\n",
        "\n",
        "for col in df_data.columns:\n",
        "  if col in category_features:\n",
        "    df_sample[col] = df_sample[col].astype(object)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlz7eUbdETWb",
        "colab_type": "text"
      },
      "source": [
        "##### #5-1.내부 명목형 변수 묶기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzmle99OEYot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 명목형 변수의 범주화\n",
        "# 성별코드 변환\n",
        "df_sample[\"C_sex\"] = df_sample[\"sex\"].apply(lambda x:  'Male' if x == 1 else 'Female')\n",
        "\n",
        "# 연령대코드 5세 단위 변환\n",
        "min_age_code = df_sample[\"ageband\"].min()\n",
        "\n",
        "df_sample[\"C_ageband\"] = df_sample[\"ageband\"].apply(lambda x:  (x-1)*5 + 20 if min_age_code == 1 else (x-1)*5).astype(object)\n",
        "\n",
        "# 시도코드 변환\n",
        "df_sample[\"C_province\"] = np.where(df_sample['province'] == 11, 'Seoul', \n",
        "                            np.where(df_sample['province']== 26, 'Busan', \n",
        "                              np.where(df_sample['province'] == 27, 'Daegu', \n",
        "                                np.where(df_sample['province'] == 28, 'Incheon', \n",
        "                                  np.where(df_sample['province'] == 29, 'Kwangju', \n",
        "                                    np.where(df_sample['province'] == 30, 'Daejeon', \n",
        "                                      np.where(df_sample['province'] == 31, 'Ulsan', \n",
        "                                        np.where(df_sample['province'] == 36, 'Sejong', \n",
        "                                          np.where(df_sample['province'] == 41, 'Gyeonggi', \n",
        "                                            np.where(df_sample['province'] == 42, 'Gangwon', \n",
        "                                              np.where(df_sample['province'] == 43, 'Chungbuk', \n",
        "                                                np.where(df_sample['province'] == 44, 'Chungnam', \n",
        "                                                  np.where(df_sample['province'] == 45, 'Jeonbuk', \n",
        "                                                    np.where(df_sample['province'] == 46, 'Jeonnam', \n",
        "                                                      np.where(df_sample['province'] == 47, 'Gyungbuk', \n",
        "                                                        np.where(df_sample['province'] == 48, 'Gyungnam', \n",
        "                                                          np.where(df_sample['province'] == 49, 'Jeju', 'Err')\n",
        "                                      ))))))))))))))))\n",
        "\n",
        "# 청력좌  변환\n",
        "df_sample[\"C_hearing_l\"] = df_sample[\"hearing_l\"].apply(lambda x:  'Normal' if x == 1 else 'Abnormal')\n",
        "\n",
        "# 청력우  변환\n",
        "df_sample[\"C_hearing_r\"] = df_sample[\"hearing_r\"].apply(lambda x:  'Normal' if x == 1 else 'Abnormal')\n",
        "\n",
        "# 요단백  변환\n",
        "df_sample[\"C_piu\"] = df_sample[\"piu\"].apply(lambda x:  'Negative' if x == 1 else 'Positive')\n",
        "\n",
        "# 흡연상태  변환\n",
        "df_sample[\"C_smoking\"] = df_sample[\"smoking\"].apply(lambda x:  'NonSmoking' if x == 1 else ('StopSmoking' if x==2 else 'Smoking'))\n",
        "\n",
        "# 음주여부  변환\n",
        "df_sample[\"C_drinking\"] = df_sample[\"drinking\"].apply(lambda x:  'NonDrinking' if x == 0 else 'Drinking')\n",
        "\n",
        "# 변환 명목형 원 컬럼 삭제\n",
        "del_obj_trans_cols = ['sex', 'ageband', 'province', 'hearing_l', 'hearing_r', 'piu', 'smoking', 'drinking']\n",
        "df_sample.drop(columns=del_obj_trans_cols, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N3rwa_DE5Py",
        "colab_type": "text"
      },
      "source": [
        "##### #5-2. 내부 수치형 변수 구간화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox2naYoPE5mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 수치형 변수 명목화\n",
        "# BMI 변수 추가\n",
        "df_sample[\"N_BMI\"] = (df_sample[\"weight\"]/(df_sample[\"height\"]*df_sample[\"height\"])).astype(float)\n",
        "\n",
        "# 공복 혈당 \n",
        "# 100 이하는 정상/ 100 ~ 125는 '공복혈당장애 - 당뇨 전단계'/ 125 이상은 당뇨\n",
        "# 당뇨병의 중간인 100~125 mg/dL가 나오거나 \n",
        "\n",
        "df_sample[\"N_diabetes\"] = np.where(df_sample['bs_before'].between(0, 100, inclusive=True), 'Normal', \n",
        "                               np.where(df_sample['bs_before'].between(100, 124.9, inclusive=True), 'Prediabetes', \n",
        "                                        'Diabetes')\n",
        "                              )\n",
        "\n",
        "# HDL 콜레스테롤\n",
        "# HDL 콜레스테롤 수치가 남자에서 40 mg/dL (1.0 mmol/L) 이하 또는 여자에서 50 mg/dL (1.3 mmol/L) 이하일 경우에는 다른 위험인자와 독립적으로 심장 질환의 위험도가 증가\n",
        "# HDL 콜레스테롤 수치가 남자에서 40-50 mg/dL (1.0-1.3 mmol/L) 그리고 여자에서 50-59 mg/dL (1.3-1.5 mmol/L)인 경우에는 심장 질환의 평균위험도와 연관\n",
        "# 보통 HDL 콜레스테롤 수치가 60 mg/dL (1.55 mmol/L) 또는 그 이상일 경우에는 심장 질환 평균 위험도보다 낮음\n",
        "# National Cholesterol Education Panel Adult Treatment Guidelines에 따르면 HDL 콜레스테롤 수치가 60 mg/dL 이상일 경우 심장 질환에서 보호되고 음성 위험 인자로서 치료되어야 함\n",
        "df_sample[\"N_HDL\"] = np.where(\n",
        "                    (df_sample['C_sex'] == \"Female\") & (df_sample['HDL_cholesterol']<= 50), 'HighRisk', \n",
        "                       np.where(\n",
        "                         (df_sample['C_sex']== \"Female\") & (df_sample['HDL_cholesterol'].between(50, 59.9, inclusive=True)), 'MediumRisk', \n",
        "                           np.where(\n",
        "                               (df_sample['C_sex']== \"Male\") & (df_sample['HDL_cholesterol']<= 40), 'HighRisk', \n",
        "                                      np.where(\n",
        "                                          (df_sample['C_sex']== \"Male\") & (df_sample['HDL_cholesterol'].between(40, 49.9, inclusive=True)), 'MediumRisk', 'Normal')\n",
        "                          )))\n",
        "# LDL 콜레스테롤(혈중 모든 콜레스테롤 중 LDL 콜레스테롤이 심장질환에 대한 위험도를 확인하는데 가장 중요한 지표)\n",
        "# 대부분의 치료 결정이 LDL 수치를 토대로 이루어지기 때문에 이 검사를 통해 식이요법 또는 운동처방의 효과를 감시하거나 지질감소 약물을 처방하는 것이 유용한지에 대한 평가\n",
        "# 100 mg/dL (2.59mmol/L) 미만 – 최적\n",
        "# 100-129 mg/dL (2.59-3.34 mmol/L) – 최적에 인접\n",
        "# 130-159 mg/dL (3.37-4.12 mmol/L) – 상한 경계성\n",
        "# 160-189 mg/dL (4.15-4.90 mmol/L) – 높음\n",
        "# 190 mg/dL (4.90 mmol) 이상 – 매우 높음\n",
        "df_sample[\"N_LDL\"] = np.where(df_sample['LDL_cholesterol']<100, 'Good', \n",
        "                    np.where(df_sample['LDL_cholesterol'].between(100, 122.9, inclusive=True), 'NearGood', \n",
        "                             np.where(df_sample['LDL_cholesterol'].between(130, 159.9, inclusive=True), 'Upperbound', \n",
        "                                      np.where(df_sample['LDL_cholesterol'].between(160, 189.9, inclusive=True), 'High', 'VeryHigh')\n",
        "                              )))\n",
        "\n",
        "# 트리글리세라이드\n",
        "# 지방의 한 형태로서 몸의 주요 에너지원, 트리글리세라이드가 증가하는 것은, 이유가 분명하지 않으나 심혈관 질환으로 진행될 위험의 증가와 관련\n",
        "# 일부 인자들 즉, 운동 부족, 과체중, 흡연, 과음 및 당뇨와 신질환 등의 질병 상태가 고트리글리세라이드혈증 및 심혈관 질환 위험도 증가에 기여할 수 있음\n",
        "# 성인에서는 트리글리세라이드 결과가 아래와 같이 나뉘어진다.\n",
        "# 150 mg/dL (1.7 mmol/L) 미만: 바람직\n",
        "# 150-199 mg/dL (1.7-2.2 mmol/L): 경계성증가\n",
        "# 200-499 mg/dL (2.3-5.6 mmol/L): 증가: \n",
        "# 500 mg/dL (5.6 mmol/L) 이상: 매우 증가\n",
        "# 이 수치는 공복시 트리글리세라이드 수치에 기준합니다.\n",
        "df_sample[\"N_TRI\"] = np.where(df_sample['triglycerides']<150, 'Good', \n",
        "                    np.where(df_sample['triglycerides'].between(150, 199.9, inclusive=True), 'Check', \n",
        "                             np.where(df_sample['triglycerides'].between(200, 499.9, inclusive=True), 'Increased', 'VeryIncreased')\n",
        "                              ))\n",
        "\n",
        "# 혈색소\n",
        "# 성인의 데시리터(100밀리리터) 당 12그램에서 18그램 정도: 정상치\n",
        "# 18그램 이상: 폐질환 등 기타 이상\n",
        "# 12그램 미만: 빈혈\n",
        "df_sample[\"N_HEMO\"] = np.where(df_sample['hemoglobin'].between(12, 17.9, inclusive=True), 'Normal', \n",
        "                    np.where(df_sample['hemoglobin']>=18, 'Abnormal', 'Anemia'))\n",
        "\n",
        "# 요단백: 소변으로 빠져나가는 잉여의 단백질을 검출하기 위해, 신장 기증을 평가하고 모니터하는 것을 돕기 위해,  그리고 신장 손상을 검출하기 위해 검사\n",
        "# 요단백은 보통 소변에서 검출 되지 않음\n",
        "\n",
        "# 혈중 크레아티닌 농도의 \n",
        "# 정상범위는 0.50~1.4 mg/dL 입니다\n",
        "# 근육량에 비례하는 검사결과이므로 여성보다는 남성에게서 약간 높은 수치가 나타나고, 식사나 운동이 결과에 영향이 거의 미치지 않습니다. 지속적으로 많은 양의 육식을 섭취한 경우에는 크레아티닌 농도가 높게 측정됩니다.\n",
        "df_sample[\"N_CRE\"] = np.where(df_sample['serum_creatinine'].between(0.5, 1.4, inclusive=True), 'Normal', 'Abnormal')\n",
        "\n",
        "# 혈청지오티AST:\n",
        "#  간기능을 평가하는 기초검사항목으로서 알코올성 간장애나 만성 간질환에서 주로 증가한다.\n",
        " \n",
        "\n",
        "# 혈청지오티ALT:\n",
        "# 간기능을 평가하는 기초검사항목으로서 급성 간염 시 주로 증가한다.\n",
        "# 증가: 간질환, 심근경색, 지방간, 비만\n",
        "\n",
        "\n",
        "# 감마지티피\n",
        "# 간장세포나 담낭세포가 파괴되면 감마지티피가 혈액속으로 누출되어 수치가 높아짐\n",
        "# 남자는 50IU 이하, 여자는 32IU이하가 정상\n",
        "# 100이하면 음주 조절을 통해 조정 가능하나 100 이상이면 지방간이 진행되고 있을 가능성이 높음\n",
        "# 200 이상이면 담석이나 담도암등으로 담도가 막혀있을 가능성이 높음\n",
        "# 500 이상이면 황달\n",
        "df_sample[\"N_GTP\"] = np.where((df_sample['GammaGTP'] >= 500), 'Jaundice', \n",
        "                       np.where(df_sample['GammaGTP']>=200, 'Abnormal', \n",
        "                           np.where(df_sample['GammaGTP']>= 100, 'PossibleAbnormal', \n",
        "                             np.where((df_sample['C_sex']== \"Male\") & (df_sample['GammaGTP']<=50), 'Normal',\n",
        "                              np.where((df_sample['C_sex']== \"Female\") & (df_sample['GammaGTP']<=32), 'Normal', 'Check')\n",
        "                          ))))\n",
        "\n",
        "# 변환 수치형 원 컬럼 삭제\n",
        "del_num_trans_cols = ['bs_before', 'HDL_cholesterol', 'LDL_cholesterol', 'triglycerides', 'hemoglobin', 'serum_creatinine', 'GammaGTP']\n",
        "df_sample.drop(columns=del_num_trans_cols, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZjaLDYILxSx",
        "colab_type": "text"
      },
      "source": [
        "##### #5-3. 내부 수치형 변수 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwlAxb6ZKdgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 수치형 변수들 중 분포 이슈로 log 값을 취할 필요 있는 변수들 추출\n",
        "num_ln_target_features = ['sight_l', 'sight_r', 'AST','ALT']\n",
        "\n",
        "# Feature Engineering의 일환으로 Log 값 취한 뒤 Normalization을 하여 변수명 + LN (lognorm)으로 열 추가 후 그래프 다시 그림\n",
        "num_ln_cols = list(map(lambda x: \"LN_\"+str(x), num_ln_target_features))\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('log_scaler', FunctionTransformer(np.log1p, validate=True)), # pipeline 내 log transformation을 위해 Function Transfomer 사용\n",
        "        ('normalizer', MinMaxScaler()),\n",
        "    ])\n",
        "\n",
        "piped_np = num_pipeline.fit_transform(df_sample[num_ln_target_features])\n",
        "piped_df = pd.DataFrame(piped_np, columns=num_ln_cols)\n",
        "\n",
        "piped_df.head()\n",
        "\n",
        "df_sample.drop(columns=num_ln_target_features, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx43qNb6L9e3",
        "colab_type": "code",
        "outputId": "3c39caef-9c3f-44f7-fd05-d0b3ec2baf6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(\"Before Re-indexing: Data count is \", len(df_sample))\n",
        "df_sample.drop_duplicates()\n",
        "df_sample.reset_index(inplace=True, drop=True)\n",
        "print(\"After Re-indexing: Data count is \", len(df_sample))\n",
        "\n",
        "df_fe = pd.concat([df_sample, piped_df], axis=1)\n",
        "df_fe.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Re-indexing: Data count is  100000\n",
            "After Re-indexing: Data count is  100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waist</th>\n",
              "      <th>bp_systolic</th>\n",
              "      <th>bp_diastolic</th>\n",
              "      <th>tot_cholesterol</th>\n",
              "      <th>dental_carries</th>\n",
              "      <th>missing_tooth</th>\n",
              "      <th>dental_abrasion</th>\n",
              "      <th>wisdom_teeth_abnormal</th>\n",
              "      <th>plaque</th>\n",
              "      <th>C_sex</th>\n",
              "      <th>C_ageband</th>\n",
              "      <th>C_province</th>\n",
              "      <th>C_hearing_l</th>\n",
              "      <th>C_hearing_r</th>\n",
              "      <th>C_piu</th>\n",
              "      <th>C_smoking</th>\n",
              "      <th>C_drinking</th>\n",
              "      <th>N_BMI</th>\n",
              "      <th>N_diabetes</th>\n",
              "      <th>N_HDL</th>\n",
              "      <th>N_LDL</th>\n",
              "      <th>N_TRI</th>\n",
              "      <th>N_HEMO</th>\n",
              "      <th>N_CRE</th>\n",
              "      <th>N_GTP</th>\n",
              "      <th>LN_sight_l</th>\n",
              "      <th>LN_sight_r</th>\n",
              "      <th>LN_AST</th>\n",
              "      <th>LN_ALT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>74</td>\n",
              "      <td>170</td>\n",
              "      <td>110</td>\n",
              "      <td>208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.374972</td>\n",
              "      <td>0.318926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155</td>\n",
              "      <td>45</td>\n",
              "      <td>67</td>\n",
              "      <td>95</td>\n",
              "      <td>65</td>\n",
              "      <td>162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>20</td>\n",
              "      <td>Chungnam</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.001873</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.357967</td>\n",
              "      <td>0.357967</td>\n",
              "      <td>0.365967</td>\n",
              "      <td>0.279401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>165</td>\n",
              "      <td>70</td>\n",
              "      <td>91</td>\n",
              "      <td>155</td>\n",
              "      <td>105</td>\n",
              "      <td>215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>30</td>\n",
              "      <td>Incheon</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NearGood</td>\n",
              "      <td>Increased</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Abnormal</td>\n",
              "      <td>0.302229</td>\n",
              "      <td>0.238306</td>\n",
              "      <td>0.511011</td>\n",
              "      <td>0.340812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>160</td>\n",
              "      <td>60</td>\n",
              "      <td>77</td>\n",
              "      <td>110</td>\n",
              "      <td>70</td>\n",
              "      <td>223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>50</td>\n",
              "      <td>Gyeonggi</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Smoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002344</td>\n",
              "      <td>Normal</td>\n",
              "      <td>MediumRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Check</td>\n",
              "      <td>0.214731</td>\n",
              "      <td>0.214731</td>\n",
              "      <td>0.555008</td>\n",
              "      <td>0.600442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>160</td>\n",
              "      <td>55</td>\n",
              "      <td>69</td>\n",
              "      <td>129</td>\n",
              "      <td>71</td>\n",
              "      <td>140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Gyeonggi</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Positive</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>Drinking</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>HighRisk</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.238306</td>\n",
              "      <td>0.238306</td>\n",
              "      <td>0.383516</td>\n",
              "      <td>0.318926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  height weight  waist  bp_systolic  ...  LN_sight_l  LN_sight_r    LN_AST    LN_ALT\n",
              "0    155     55     74          170  ...    0.135235    0.260671  0.374972  0.318926\n",
              "1    155     45     67           95  ...    0.357967    0.357967  0.365967  0.279401\n",
              "2    165     70     91          155  ...    0.302229    0.238306  0.511011  0.340812\n",
              "3    160     60     77          110  ...    0.214731    0.214731  0.555008  0.600442\n",
              "4    160     55     69          129  ...    0.238306    0.238306  0.383516  0.318926\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caU-WGrLNtak",
        "colab_type": "text"
      },
      "source": [
        "#### #6. 외부변수 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl_X8cosNt9D",
        "colab_type": "code",
        "outputId": "78f723e7-8228-4114-facc-2cccd63a42da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_add1 = pd.read_csv('../gdrive/My Drive/sds/data/DentalExamineResult_2014_PortionbyTotInspector.csv', encoding = 'euc-kr')\n",
        "df_add2 = pd.read_csv('../gdrive/My Drive/sds/data/KOSIS_AgeSex_AverageDentalVisitCnt_2012.csv', encoding = 'euc-kr')\n",
        "df_add3 = pd.read_csv('../gdrive/My Drive/sds/data/KOSIS_DentalPrevalenceTrend_2012.csv', encoding = 'euc-kr')\n",
        "df_add4 = pd.read_csv('../gdrive/My Drive/sds/data/chs_12_final_from_python.csv', encoding = 'euc-kr')\n",
        "\n",
        "# Multiple Key를 사용하여 Join\n",
        "# left_on=['column_name1','column_name2'], right_on = ['column_name3','column_name4']\n",
        "print(len(df_fe))\n",
        "\n",
        "df_new = pd.merge(left=df_fe, right=df_add1, how='outer', left_on=['C_province','C_sex'], right_on = ['Province','Sex'], sort=False)\n",
        "df_new.drop(columns=['Province','Sex'], axis=1, inplace=True)\n",
        "display(df_new.head())\n",
        "print(len(df_new))\n",
        "\n",
        "df_new = pd.merge(left=df_new, right=df_add2, how='outer', left_on=['C_ageband','C_sex'], right_on = ['Ageband','Sex'], sort=False)\n",
        "df_new.drop(columns=['Ageband','Sex'], axis=1, inplace=True)\n",
        "display(df_new.head())\n",
        "print(len(df_new))\n",
        "\n",
        "df_new = pd.merge(left=df_new, right=df_add3, how='outer', left_on=['C_ageband','C_sex'], right_on = ['Ageband','Sex'], sort=False)\n",
        "df_new.drop(columns=['Ageband','Sex'], axis=1, inplace=True)\n",
        "display(df_new.head())\n",
        "print(len(df_new))\n",
        "\n",
        "df_new = pd.merge(left=df_new, right=df_add4, how='left', left_on=['C_ageband','C_sex','C_province', 'weight', 'height'], right_on = ['R_ageband','R_sex','R_province','R_weight','R_height'], sort=False)\n",
        "df_new.drop(columns=['R_ageband','R_sex','R_province','R_weight','R_height'], axis=1, inplace=True)\n",
        "display(df_new.head())\n",
        "print(len(df_new))\n",
        "\n",
        "display(df_new.info())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waist</th>\n",
              "      <th>bp_systolic</th>\n",
              "      <th>bp_diastolic</th>\n",
              "      <th>tot_cholesterol</th>\n",
              "      <th>dental_carries</th>\n",
              "      <th>missing_tooth</th>\n",
              "      <th>dental_abrasion</th>\n",
              "      <th>wisdom_teeth_abnormal</th>\n",
              "      <th>plaque</th>\n",
              "      <th>C_sex</th>\n",
              "      <th>C_ageband</th>\n",
              "      <th>C_province</th>\n",
              "      <th>C_hearing_l</th>\n",
              "      <th>C_hearing_r</th>\n",
              "      <th>C_piu</th>\n",
              "      <th>C_smoking</th>\n",
              "      <th>C_drinking</th>\n",
              "      <th>N_BMI</th>\n",
              "      <th>N_diabetes</th>\n",
              "      <th>N_HDL</th>\n",
              "      <th>N_LDL</th>\n",
              "      <th>N_TRI</th>\n",
              "      <th>N_HEMO</th>\n",
              "      <th>N_CRE</th>\n",
              "      <th>N_GTP</th>\n",
              "      <th>LN_sight_l</th>\n",
              "      <th>LN_sight_r</th>\n",
              "      <th>LN_AST</th>\n",
              "      <th>LN_ALT</th>\n",
              "      <th>A_NormalA_Result</th>\n",
              "      <th>A_NormalB_Result</th>\n",
              "      <th>A_Caution_Result</th>\n",
              "      <th>A_NeedCare_Result</th>\n",
              "      <th>A_Nutrition_Edu</th>\n",
              "      <th>A_Hygine_Edu</th>\n",
              "      <th>A_Fluoride_Edu</th>\n",
              "      <th>A_Examine_Rec</th>\n",
              "      <th>A_Care_Rec</th>\n",
              "      <th>A_Carries_Rec</th>\n",
              "      <th>A_Cure_Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>74</td>\n",
              "      <td>170</td>\n",
              "      <td>110</td>\n",
              "      <td>208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.374972</td>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>76</td>\n",
              "      <td>123</td>\n",
              "      <td>76</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>60</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Abnormal</td>\n",
              "      <td>Abnormal</td>\n",
              "      <td>Positive</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>Normal</td>\n",
              "      <td>HighRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.214731</td>\n",
              "      <td>0.189809</td>\n",
              "      <td>0.383516</td>\n",
              "      <td>0.279401</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>77</td>\n",
              "      <td>108</td>\n",
              "      <td>68</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>60</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NearGood</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.072840</td>\n",
              "      <td>0.072840</td>\n",
              "      <td>0.399390</td>\n",
              "      <td>0.385380</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150</td>\n",
              "      <td>60</td>\n",
              "      <td>88</td>\n",
              "      <td>110</td>\n",
              "      <td>70</td>\n",
              "      <td>270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>55</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002667</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>Normal</td>\n",
              "      <td>High</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.238306</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.383516</td>\n",
              "      <td>0.330234</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>165</td>\n",
              "      <td>60</td>\n",
              "      <td>74</td>\n",
              "      <td>110</td>\n",
              "      <td>70</td>\n",
              "      <td>225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>55</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002204</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.357967</td>\n",
              "      <td>0.357967</td>\n",
              "      <td>0.439558</td>\n",
              "      <td>0.400290</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  height weight  waist  ...  A_Care_Rec  A_Carries_Rec  A_Cure_Rec\n",
              "0    155     55     74  ...        8.17           2.68        0.57\n",
              "1    155     55     76  ...        8.17           2.68        0.57\n",
              "2    155     55     77  ...        8.17           2.68        0.57\n",
              "3    150     60     88  ...        8.17           2.68        0.57\n",
              "4    165     60     74  ...        8.17           2.68        0.57\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waist</th>\n",
              "      <th>bp_systolic</th>\n",
              "      <th>bp_diastolic</th>\n",
              "      <th>tot_cholesterol</th>\n",
              "      <th>dental_carries</th>\n",
              "      <th>missing_tooth</th>\n",
              "      <th>dental_abrasion</th>\n",
              "      <th>wisdom_teeth_abnormal</th>\n",
              "      <th>plaque</th>\n",
              "      <th>C_sex</th>\n",
              "      <th>C_ageband</th>\n",
              "      <th>C_province</th>\n",
              "      <th>C_hearing_l</th>\n",
              "      <th>C_hearing_r</th>\n",
              "      <th>C_piu</th>\n",
              "      <th>C_smoking</th>\n",
              "      <th>C_drinking</th>\n",
              "      <th>N_BMI</th>\n",
              "      <th>N_diabetes</th>\n",
              "      <th>N_HDL</th>\n",
              "      <th>N_LDL</th>\n",
              "      <th>N_TRI</th>\n",
              "      <th>N_HEMO</th>\n",
              "      <th>N_CRE</th>\n",
              "      <th>N_GTP</th>\n",
              "      <th>LN_sight_l</th>\n",
              "      <th>LN_sight_r</th>\n",
              "      <th>LN_AST</th>\n",
              "      <th>LN_ALT</th>\n",
              "      <th>A_NormalA_Result</th>\n",
              "      <th>A_NormalB_Result</th>\n",
              "      <th>A_Caution_Result</th>\n",
              "      <th>A_NeedCare_Result</th>\n",
              "      <th>A_Nutrition_Edu</th>\n",
              "      <th>A_Hygine_Edu</th>\n",
              "      <th>A_Fluoride_Edu</th>\n",
              "      <th>A_Examine_Rec</th>\n",
              "      <th>A_Care_Rec</th>\n",
              "      <th>A_Carries_Rec</th>\n",
              "      <th>A_Cure_Rec</th>\n",
              "      <th>A_AverageDentalHospitalVisitCnt</th>\n",
              "      <th>A_AverageDentalClinicVisitCnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>74</td>\n",
              "      <td>170</td>\n",
              "      <td>110</td>\n",
              "      <td>208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.374972</td>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>150</td>\n",
              "      <td>70</td>\n",
              "      <td>89</td>\n",
              "      <td>134</td>\n",
              "      <td>82</td>\n",
              "      <td>194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.003111</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>MediumRisk</td>\n",
              "      <td>VeryHigh</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.365967</td>\n",
              "      <td>0.368977</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155</td>\n",
              "      <td>50</td>\n",
              "      <td>73</td>\n",
              "      <td>129</td>\n",
              "      <td>81</td>\n",
              "      <td>196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>Drinking</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NearGood</td>\n",
              "      <td>Good</td>\n",
              "      <td>Anemia</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.238306</td>\n",
              "      <td>0.456511</td>\n",
              "      <td>0.368977</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>160</td>\n",
              "      <td>55</td>\n",
              "      <td>75</td>\n",
              "      <td>120</td>\n",
              "      <td>70</td>\n",
              "      <td>209</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>Drinking</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>MediumRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.105152</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.391642</td>\n",
              "      <td>0.330234</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>75</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002222</td>\n",
              "      <td>Normal</td>\n",
              "      <td>HighRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Anemia</td>\n",
              "      <td>Abnormal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.420682</td>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  height weight  ...  A_AverageDentalHospitalVisitCnt  A_AverageDentalClinicVisitCnt\n",
              "0    155     55  ...                             48.1                        1061.92\n",
              "1    150     70  ...                             48.1                        1061.92\n",
              "2    155     50  ...                             48.1                        1061.92\n",
              "3    160     55  ...                             48.1                        1061.92\n",
              "4    150     50  ...                             48.1                        1061.92\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waist</th>\n",
              "      <th>bp_systolic</th>\n",
              "      <th>bp_diastolic</th>\n",
              "      <th>tot_cholesterol</th>\n",
              "      <th>dental_carries</th>\n",
              "      <th>missing_tooth</th>\n",
              "      <th>dental_abrasion</th>\n",
              "      <th>wisdom_teeth_abnormal</th>\n",
              "      <th>plaque</th>\n",
              "      <th>C_sex</th>\n",
              "      <th>C_ageband</th>\n",
              "      <th>C_province</th>\n",
              "      <th>C_hearing_l</th>\n",
              "      <th>C_hearing_r</th>\n",
              "      <th>C_piu</th>\n",
              "      <th>C_smoking</th>\n",
              "      <th>C_drinking</th>\n",
              "      <th>N_BMI</th>\n",
              "      <th>N_diabetes</th>\n",
              "      <th>N_HDL</th>\n",
              "      <th>N_LDL</th>\n",
              "      <th>N_TRI</th>\n",
              "      <th>N_HEMO</th>\n",
              "      <th>N_CRE</th>\n",
              "      <th>N_GTP</th>\n",
              "      <th>LN_sight_l</th>\n",
              "      <th>LN_sight_r</th>\n",
              "      <th>LN_AST</th>\n",
              "      <th>LN_ALT</th>\n",
              "      <th>A_NormalA_Result</th>\n",
              "      <th>A_NormalB_Result</th>\n",
              "      <th>A_Caution_Result</th>\n",
              "      <th>A_NeedCare_Result</th>\n",
              "      <th>A_Nutrition_Edu</th>\n",
              "      <th>A_Hygine_Edu</th>\n",
              "      <th>A_Fluoride_Edu</th>\n",
              "      <th>A_Examine_Rec</th>\n",
              "      <th>A_Care_Rec</th>\n",
              "      <th>A_Carries_Rec</th>\n",
              "      <th>A_Cure_Rec</th>\n",
              "      <th>A_AverageDentalHospitalVisitCnt</th>\n",
              "      <th>A_AverageDentalClinicVisitCnt</th>\n",
              "      <th>A_DentalPrevalenceTrend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>74</td>\n",
              "      <td>170</td>\n",
              "      <td>110</td>\n",
              "      <td>208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.374972</td>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>150</td>\n",
              "      <td>70</td>\n",
              "      <td>89</td>\n",
              "      <td>134</td>\n",
              "      <td>82</td>\n",
              "      <td>194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.003111</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>MediumRisk</td>\n",
              "      <td>VeryHigh</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.365967</td>\n",
              "      <td>0.368977</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155</td>\n",
              "      <td>50</td>\n",
              "      <td>73</td>\n",
              "      <td>129</td>\n",
              "      <td>81</td>\n",
              "      <td>196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>Drinking</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NearGood</td>\n",
              "      <td>Good</td>\n",
              "      <td>Anemia</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.238306</td>\n",
              "      <td>0.456511</td>\n",
              "      <td>0.368977</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>160</td>\n",
              "      <td>55</td>\n",
              "      <td>75</td>\n",
              "      <td>120</td>\n",
              "      <td>70</td>\n",
              "      <td>209</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>Drinking</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>MediumRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.105152</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.391642</td>\n",
              "      <td>0.330234</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>75</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002222</td>\n",
              "      <td>Normal</td>\n",
              "      <td>HighRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Anemia</td>\n",
              "      <td>Abnormal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.420682</td>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.57</td>\n",
              "      <td>48.1</td>\n",
              "      <td>1061.92</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  height weight  ...  A_AverageDentalClinicVisitCnt  A_DentalPrevalenceTrend\n",
              "0    155     55  ...                        1061.92                      558\n",
              "1    150     70  ...                        1061.92                      558\n",
              "2    155     50  ...                        1061.92                      558\n",
              "3    160     55  ...                        1061.92                      558\n",
              "4    150     50  ...                        1061.92                      558\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waist</th>\n",
              "      <th>bp_systolic</th>\n",
              "      <th>bp_diastolic</th>\n",
              "      <th>tot_cholesterol</th>\n",
              "      <th>dental_carries</th>\n",
              "      <th>missing_tooth</th>\n",
              "      <th>dental_abrasion</th>\n",
              "      <th>wisdom_teeth_abnormal</th>\n",
              "      <th>plaque</th>\n",
              "      <th>C_sex</th>\n",
              "      <th>C_ageband</th>\n",
              "      <th>C_province</th>\n",
              "      <th>C_hearing_l</th>\n",
              "      <th>C_hearing_r</th>\n",
              "      <th>C_piu</th>\n",
              "      <th>C_smoking</th>\n",
              "      <th>C_drinking</th>\n",
              "      <th>N_BMI</th>\n",
              "      <th>N_diabetes</th>\n",
              "      <th>N_HDL</th>\n",
              "      <th>N_LDL</th>\n",
              "      <th>N_TRI</th>\n",
              "      <th>N_HEMO</th>\n",
              "      <th>N_CRE</th>\n",
              "      <th>N_GTP</th>\n",
              "      <th>LN_sight_l</th>\n",
              "      <th>LN_sight_r</th>\n",
              "      <th>LN_AST</th>\n",
              "      <th>LN_ALT</th>\n",
              "      <th>A_NormalA_Result</th>\n",
              "      <th>A_NormalB_Result</th>\n",
              "      <th>A_Caution_Result</th>\n",
              "      <th>A_NeedCare_Result</th>\n",
              "      <th>A_Nutrition_Edu</th>\n",
              "      <th>A_Hygine_Edu</th>\n",
              "      <th>A_Fluoride_Edu</th>\n",
              "      <th>A_Examine_Rec</th>\n",
              "      <th>A_Care_Rec</th>\n",
              "      <th>...</th>\n",
              "      <th>R_income</th>\n",
              "      <th>R_AnemiaDiag</th>\n",
              "      <th>R_AnginaPectorisDiag</th>\n",
              "      <th>R_ArthritisDiag</th>\n",
              "      <th>R_Asthma_Diag</th>\n",
              "      <th>R_MasticationLesion</th>\n",
              "      <th>R_BHepatitisDiag</th>\n",
              "      <th>R_CHepatitisDiag</th>\n",
              "      <th>R_HemorrhoidsDiag</th>\n",
              "      <th>R_HealthInstExp</th>\n",
              "      <th>R_HBP_Diag</th>\n",
              "      <th>R_PronounceLesion</th>\n",
              "      <th>R_DentureUse</th>\n",
              "      <th>R_SubjHealthLevel</th>\n",
              "      <th>R_EQVAS</th>\n",
              "      <th>R_FinEduGrade</th>\n",
              "      <th>R_DentDidNotExp</th>\n",
              "      <th>R_EQ5DNormLife</th>\n",
              "      <th>R_CPRRecognition</th>\n",
              "      <th>R_DrinkStartAge</th>\n",
              "      <th>R_FamilyCnt</th>\n",
              "      <th>R_AveSleepTime</th>\n",
              "      <th>R_AIDSRecognition</th>\n",
              "      <th>R_BPCheckinYear</th>\n",
              "      <th>R_WalkingDay</th>\n",
              "      <th>R_WalkingMinutes</th>\n",
              "      <th>R_SmokingStartAge</th>\n",
              "      <th>R_NutriChk</th>\n",
              "      <th>R_DrinkFreq</th>\n",
              "      <th>R_NearGYM</th>\n",
              "      <th>R_EQ5DPain</th>\n",
              "      <th>R_EQ5DAthleticAbility</th>\n",
              "      <th>R_BPCheckinYear.1</th>\n",
              "      <th>R_StressIndex</th>\n",
              "      <th>R_ExerciseMidHour</th>\n",
              "      <th>R_DrinkPerOnce</th>\n",
              "      <th>R_BreakfastperWeek</th>\n",
              "      <th>R_EQ5DSelfManage</th>\n",
              "      <th>R_ExerciseHighHour</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>74</td>\n",
              "      <td>170</td>\n",
              "      <td>110</td>\n",
              "      <td>208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.374972</td>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>...</td>\n",
              "      <td>4862.242991</td>\n",
              "      <td>0.102804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065421</td>\n",
              "      <td>0.009346</td>\n",
              "      <td>0.149533</td>\n",
              "      <td>0.037383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093458</td>\n",
              "      <td>0.196262</td>\n",
              "      <td>0.158879</td>\n",
              "      <td>0.018692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018692</td>\n",
              "      <td>74.700935</td>\n",
              "      <td>5.504673</td>\n",
              "      <td>0.364486</td>\n",
              "      <td>0.056075</td>\n",
              "      <td>0.869159</td>\n",
              "      <td>20.560748</td>\n",
              "      <td>3.551402</td>\n",
              "      <td>6.607477</td>\n",
              "      <td>0.934579</td>\n",
              "      <td>2.149533</td>\n",
              "      <td>4.906542</td>\n",
              "      <td>17.383178</td>\n",
              "      <td>1.177570</td>\n",
              "      <td>0.579439</td>\n",
              "      <td>0.261682</td>\n",
              "      <td>0.850467</td>\n",
              "      <td>0.327103</td>\n",
              "      <td>0.065421</td>\n",
              "      <td>0.915888</td>\n",
              "      <td>0.925234</td>\n",
              "      <td>0.523364</td>\n",
              "      <td>0.766355</td>\n",
              "      <td>5.514019</td>\n",
              "      <td>0.018692</td>\n",
              "      <td>0.495327</td>\n",
              "      <td>0.289720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>150</td>\n",
              "      <td>70</td>\n",
              "      <td>89</td>\n",
              "      <td>134</td>\n",
              "      <td>82</td>\n",
              "      <td>194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.003111</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>MediumRisk</td>\n",
              "      <td>VeryHigh</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.365967</td>\n",
              "      <td>0.368977</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>...</td>\n",
              "      <td>5100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155</td>\n",
              "      <td>50</td>\n",
              "      <td>73</td>\n",
              "      <td>129</td>\n",
              "      <td>81</td>\n",
              "      <td>196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>Drinking</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NearGood</td>\n",
              "      <td>Good</td>\n",
              "      <td>Anemia</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.238306</td>\n",
              "      <td>0.456511</td>\n",
              "      <td>0.368977</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>...</td>\n",
              "      <td>4910.857143</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.030075</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.150376</td>\n",
              "      <td>0.045113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112782</td>\n",
              "      <td>0.180451</td>\n",
              "      <td>0.067669</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>5.819549</td>\n",
              "      <td>0.270677</td>\n",
              "      <td>0.067669</td>\n",
              "      <td>0.887218</td>\n",
              "      <td>17.556391</td>\n",
              "      <td>3.518797</td>\n",
              "      <td>6.593985</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>1.744361</td>\n",
              "      <td>4.661654</td>\n",
              "      <td>17.827068</td>\n",
              "      <td>0.939850</td>\n",
              "      <td>0.586466</td>\n",
              "      <td>0.278195</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.203008</td>\n",
              "      <td>0.037594</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.827068</td>\n",
              "      <td>0.165414</td>\n",
              "      <td>0.691729</td>\n",
              "      <td>5.827068</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.270677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>160</td>\n",
              "      <td>55</td>\n",
              "      <td>75</td>\n",
              "      <td>120</td>\n",
              "      <td>70</td>\n",
              "      <td>209</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>Drinking</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>Prediabetes</td>\n",
              "      <td>MediumRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.105152</td>\n",
              "      <td>0.135235</td>\n",
              "      <td>0.391642</td>\n",
              "      <td>0.330234</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>...</td>\n",
              "      <td>5512.561983</td>\n",
              "      <td>0.123967</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066116</td>\n",
              "      <td>0.008264</td>\n",
              "      <td>0.082645</td>\n",
              "      <td>0.033058</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123967</td>\n",
              "      <td>0.148760</td>\n",
              "      <td>0.049587</td>\n",
              "      <td>0.008264</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033058</td>\n",
              "      <td>77.512397</td>\n",
              "      <td>5.851240</td>\n",
              "      <td>0.223140</td>\n",
              "      <td>0.033058</td>\n",
              "      <td>0.892562</td>\n",
              "      <td>18.487603</td>\n",
              "      <td>3.512397</td>\n",
              "      <td>6.553719</td>\n",
              "      <td>0.950413</td>\n",
              "      <td>1.867769</td>\n",
              "      <td>4.677686</td>\n",
              "      <td>16.528926</td>\n",
              "      <td>1.099174</td>\n",
              "      <td>0.553719</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.859504</td>\n",
              "      <td>0.280992</td>\n",
              "      <td>0.057851</td>\n",
              "      <td>0.710744</td>\n",
              "      <td>0.892562</td>\n",
              "      <td>0.314050</td>\n",
              "      <td>0.702479</td>\n",
              "      <td>5.942149</td>\n",
              "      <td>0.016529</td>\n",
              "      <td>0.859504</td>\n",
              "      <td>0.223140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>75</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NonSmoking</td>\n",
              "      <td>NonDrinking</td>\n",
              "      <td>0.002222</td>\n",
              "      <td>Normal</td>\n",
              "      <td>HighRisk</td>\n",
              "      <td>Upperbound</td>\n",
              "      <td>Good</td>\n",
              "      <td>Anemia</td>\n",
              "      <td>Abnormal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.260671</td>\n",
              "      <td>0.420682</td>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.21</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.17</td>\n",
              "      <td>...</td>\n",
              "      <td>5272.500000</td>\n",
              "      <td>0.140625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.140625</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>74.984375</td>\n",
              "      <td>5.406250</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>0.921875</td>\n",
              "      <td>21.406250</td>\n",
              "      <td>3.593750</td>\n",
              "      <td>6.437500</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>2.406250</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>17.500000</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>5.703125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.234375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  height weight  waist  ...  R_EQ5DSelfManage  R_ExerciseHighHour    target\n",
              "0    155     55     74  ...          0.018692            0.495327  0.289720\n",
              "1    150     70     89  ...          0.000000            0.000000  1.000000\n",
              "2    155     50     73  ...          0.015038            0.578947  0.270677\n",
              "3    160     55     75  ...          0.016529            0.859504  0.223140\n",
              "4    150     50     75  ...          0.000000            0.343750  0.234375\n",
              "\n",
              "[5 rows x 85 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 100000 entries, 0 to 99999\n",
            "Data columns (total 85 columns):\n",
            "height                             100000 non-null object\n",
            "weight                             100000 non-null object\n",
            "waist                              100000 non-null int64\n",
            "bp_systolic                        100000 non-null int64\n",
            "bp_diastolic                       100000 non-null int64\n",
            "tot_cholesterol                    100000 non-null int64\n",
            "dental_carries                     100000 non-null float64\n",
            "missing_tooth                      100000 non-null float64\n",
            "dental_abrasion                    100000 non-null float64\n",
            "wisdom_teeth_abnormal              100000 non-null float64\n",
            "plaque                             100000 non-null float64\n",
            "C_sex                              100000 non-null object\n",
            "C_ageband                          100000 non-null object\n",
            "C_province                         100000 non-null object\n",
            "C_hearing_l                        100000 non-null object\n",
            "C_hearing_r                        100000 non-null object\n",
            "C_piu                              100000 non-null object\n",
            "C_smoking                          100000 non-null object\n",
            "C_drinking                         100000 non-null object\n",
            "N_BMI                              100000 non-null float64\n",
            "N_diabetes                         100000 non-null object\n",
            "N_HDL                              100000 non-null object\n",
            "N_LDL                              100000 non-null object\n",
            "N_TRI                              100000 non-null object\n",
            "N_HEMO                             100000 non-null object\n",
            "N_CRE                              100000 non-null object\n",
            "N_GTP                              100000 non-null object\n",
            "LN_sight_l                         100000 non-null float64\n",
            "LN_sight_r                         100000 non-null float64\n",
            "LN_AST                             100000 non-null float64\n",
            "LN_ALT                             100000 non-null float64\n",
            "A_NormalA_Result                   100000 non-null float64\n",
            "A_NormalB_Result                   100000 non-null float64\n",
            "A_Caution_Result                   100000 non-null float64\n",
            "A_NeedCare_Result                  100000 non-null float64\n",
            "A_Nutrition_Edu                    100000 non-null float64\n",
            "A_Hygine_Edu                       100000 non-null float64\n",
            "A_Fluoride_Edu                     100000 non-null float64\n",
            "A_Examine_Rec                      100000 non-null float64\n",
            "A_Care_Rec                         100000 non-null float64\n",
            "A_Carries_Rec                      100000 non-null float64\n",
            "A_Cure_Rec                         100000 non-null float64\n",
            "A_AverageDentalHospitalVisitCnt    100000 non-null float64\n",
            "A_AverageDentalClinicVisitCnt      100000 non-null float64\n",
            "A_DentalPrevalenceTrend            100000 non-null int64\n",
            "R_income                           96559 non-null float64\n",
            "R_AnemiaDiag                       96559 non-null float64\n",
            "R_AnginaPectorisDiag               96559 non-null float64\n",
            "R_ArthritisDiag                    96559 non-null float64\n",
            "R_Asthma_Diag                      96559 non-null float64\n",
            "R_MasticationLesion                96559 non-null float64\n",
            "R_BHepatitisDiag                   96559 non-null float64\n",
            "R_CHepatitisDiag                   96559 non-null float64\n",
            "R_HemorrhoidsDiag                  96559 non-null float64\n",
            "R_HealthInstExp                    96559 non-null float64\n",
            "R_HBP_Diag                         96559 non-null float64\n",
            "R_PronounceLesion                  96559 non-null float64\n",
            "R_DentureUse                       96559 non-null float64\n",
            "R_SubjHealthLevel                  96559 non-null float64\n",
            "R_EQVAS                            96559 non-null float64\n",
            "R_FinEduGrade                      96559 non-null float64\n",
            "R_DentDidNotExp                    96559 non-null float64\n",
            "R_EQ5DNormLife                     96559 non-null float64\n",
            "R_CPRRecognition                   96559 non-null float64\n",
            "R_DrinkStartAge                    96559 non-null float64\n",
            "R_FamilyCnt                        96559 non-null float64\n",
            "R_AveSleepTime                     96559 non-null float64\n",
            "R_AIDSRecognition                  96559 non-null float64\n",
            "R_BPCheckinYear                    96559 non-null float64\n",
            "R_WalkingDay                       96559 non-null float64\n",
            "R_WalkingMinutes                   96559 non-null float64\n",
            "R_SmokingStartAge                  96559 non-null float64\n",
            "R_NutriChk                         96559 non-null float64\n",
            "R_DrinkFreq                        96559 non-null float64\n",
            "R_NearGYM                          96559 non-null float64\n",
            "R_EQ5DPain                         96559 non-null float64\n",
            "R_EQ5DAthleticAbility              96559 non-null float64\n",
            "R_BPCheckinYear.1                  96559 non-null float64\n",
            "R_StressIndex                      96559 non-null float64\n",
            "R_ExerciseMidHour                  96559 non-null float64\n",
            "R_DrinkPerOnce                     96559 non-null float64\n",
            "R_BreakfastperWeek                 96559 non-null float64\n",
            "R_EQ5DSelfManage                   96559 non-null float64\n",
            "R_ExerciseHighHour                 96559 non-null float64\n",
            "target                             96559 non-null float64\n",
            "dtypes: float64(63), int64(5), object(17)\n",
            "memory usage: 65.6+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya7dG_AROYbe",
        "colab_type": "code",
        "outputId": "07d2844c-cee2-4d86-a73d-c480e587cddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 외부변수와 매칭이 되지 않는 항목은 버림\n",
        "df_new.dropna(how='any', inplace=True)\n",
        "print(df_new[target_nm].value_counts())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0    48427\n",
            "1.0    48132\n",
            "Name: dental_carries, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRBtVWUWX6G9",
        "colab_type": "text"
      },
      "source": [
        "#### #7. IV 계산을 통한 변수 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rL7QbTXX2ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # IV 산출\n",
        "# iv_df, IV_first = calc_iv_all(df_new,df_new[target_nm])\n",
        "\n",
        "# # IV 값 내림차순 정렬\n",
        "# IV_first.sort_values('IV',ascending=False)\n",
        "\n",
        "# IV_select_col = list(IV_first[IV_first['IV']>=0.015]['VAR_NAME'])\n",
        "# IV_select_col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RwwMyDLED72",
        "colab_type": "code",
        "outputId": "237667e5-c975-430e-f486-885053bfe0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# 독립변수와 종속변수를 나눠 줌\n",
        "data_x = df_new[df_new.columns.difference([target_nm])]\n",
        "# data_x = df_new[IV_select_col]\n",
        "data_y = df_new[target_nm].astype('float64')\n",
        "\n",
        "# 데이터를 나눈 뒤 속성별로 컬럼을 분류\n",
        "num_attribs = [col for col in data_x.columns if data_x[col].dtype in ['int64','float64']]\n",
        "cat_attribs = [col for col in data_x.columns if data_x[col].dtype not in ['int64','float64']]\n",
        "\n",
        "num_attribs = list(set(num_attribs) - set([target_nm]))\n",
        "\n",
        "print(\"num_attribs: \", num_attribs)\n",
        "print(\"cat_attribs: \", cat_attribs)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_attribs:  ['waist', 'dental_abrasion', 'R_NearGYM', 'R_FamilyCnt', 'R_HealthInstExp', 'A_Nutrition_Edu', 'LN_sight_l', 'R_Asthma_Diag', 'A_Carries_Rec', 'R_ExerciseMidHour', 'R_DentureUse', 'R_HBP_Diag', 'R_SubjHealthLevel', 'R_income', 'R_BreakfastperWeek', 'R_EQ5DAthleticAbility', 'R_ExerciseHighHour', 'LN_AST', 'R_CHepatitisDiag', 'R_BPCheckinYear', 'R_DentDidNotExp', 'LN_ALT', 'A_Fluoride_Edu', 'R_SmokingStartAge', 'LN_sight_r', 'R_EQ5DNormLife', 'wisdom_teeth_abnormal', 'R_EQ5DPain', 'A_AverageDentalHospitalVisitCnt', 'R_AnginaPectorisDiag', 'A_AverageDentalClinicVisitCnt', 'A_NormalA_Result', 'A_NormalB_Result', 'A_Caution_Result', 'R_HemorrhoidsDiag', 'R_BPCheckinYear.1', 'tot_cholesterol', 'R_ArthritisDiag', 'R_MasticationLesion', 'R_NutriChk', 'target', 'N_BMI', 'bp_systolic', 'A_Cure_Rec', 'R_WalkingMinutes', 'A_NeedCare_Result', 'R_StressIndex', 'A_DentalPrevalenceTrend', 'plaque', 'R_CPRRecognition', 'R_DrinkFreq', 'R_AnemiaDiag', 'missing_tooth', 'A_Examine_Rec', 'R_EQ5DSelfManage', 'R_FinEduGrade', 'R_WalkingDay', 'R_AveSleepTime', 'R_PronounceLesion', 'bp_diastolic', 'R_AIDSRecognition', 'R_BHepatitisDiag', 'R_DrinkStartAge', 'A_Care_Rec', 'A_Hygine_Edu', 'R_DrinkPerOnce', 'R_EQVAS']\n",
            "cat_attribs:  ['C_ageband', 'C_drinking', 'C_hearing_l', 'C_hearing_r', 'C_piu', 'C_province', 'C_sex', 'C_smoking', 'N_CRE', 'N_GTP', 'N_HDL', 'N_HEMO', 'N_LDL', 'N_TRI', 'N_diabetes', 'height', 'weight']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT20XJ5SICI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label = LabelEncoder()\n",
        "# for col in data_x[cat_attribs].columns:   \n",
        "#   data_x[col] = label.fit_transform(data_x[col])\n",
        "#   data_x = pd.get_dummies(data_x, columns =[col], prefix=col+\"_lb\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZGJ5-n5rQUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 수치형 변수 정규화 \n",
        "num_pipeline = Pipeline([\n",
        "        ('min_max_scaler', MinMaxScaler()),\n",
        "    ])\n",
        "\n",
        "# numpy 형식으로 전체 변경\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num_pipeline\", num_pipeline, num_attribs),\n",
        "        (\"cat_encoder\", OneHotEncoder(sparse=False), cat_attribs),\n",
        "    ])\n",
        "\n",
        "data_x_piped = full_pipeline.fit_transform(data_x)\n",
        "\n",
        "data_y_piped = data_y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7JDk-RXvZO0",
        "colab_type": "code",
        "outputId": "e149f7d6-2370-4ea1-cdff-ac7d7ffd842b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_x_piped.shape[1]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpnjUNhR-xpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x, train_y, test_y = train_test_split(data_x_piped, data_y_piped, test_size = 0.2, random_state = set_random_seed)\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.2, random_state = set_random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCF6bpKmwcQK",
        "colab_type": "code",
        "outputId": "8d854f8c-f6d1-4b0a-9011-ea263d2f4897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# Tensorboard 사용준비\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-21 02:20:34--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.237.203.145, 52.4.11.55, 52.71.61.108, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.237.203.145|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  18.0MB/s    in 0.7s    \n",
            "\n",
            "2019-11-21 02:20:35 (18.0 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ngrok                   \n",
            "https://0c87c0ca.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RA9GCcWtIaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = \"softmax\"\n",
        "optimizer = keras.optimizers.SGD()\n",
        "input_dim = train_x.shape[1]\n",
        "batch_size = 128\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CThA-GFqtILK",
        "colab_type": "code",
        "outputId": "0e9e9583-9aee-4a24-e62e-7b4a6c4d12f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "K.clear_session() # Tensorboard Callback error 방지를 위해 tensorboard의 session을 clear 해줌\n",
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "  model = Sequential()\n",
        "  # 첫 번째 Layer (Input layer)\n",
        "  model.add(Dense(input_dim=input_dim, init='glorot_uniform', activation=activation, output_dim=256))\n",
        "  # # 두 번째 Layer (Hidden layer 1)\n",
        "  model.add(Dense(output_dim=256, activation=activation))\n",
        "  # Dense Layer (Output layer)\n",
        "  model.add(Dense(output_dim=1))\n",
        "  model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "  # Cost function 및 Optimizer 설정 # binary class 분류이므로 binary_crossentropy 사용 # Adam optimizer 사용\n",
        "  model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=True),  metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "  tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                          write_graph=True,\n",
        "                          write_grads=True,\n",
        "                          batch_size=batch_size,\n",
        "                          write_images=True)\n",
        "  hist = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(val_x, val_y), callbacks=[tbCallBack])\n",
        "  \n",
        "  # loss, accuracy, f1_score, precision, recall = model.evaluate(test_x, test_y, verbose=0)\n",
        "  score = model.evaluate(test_x, test_y, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 61797 samples, validate on 15450 samples\n",
            "Epoch 1/10\n",
            "61797/61797 [==============================] - 3s 45us/step - loss: 0.6931 - acc: 0.4995 - precision: 0.1653 - recall: 0.3332 - f1score: 0.2206 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 2/10\n",
            "61797/61797 [==============================] - 3s 49us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 3/10\n",
            "61797/61797 [==============================] - 3s 48us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 4/10\n",
            "61797/61797 [==============================] - 3s 42us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 5/10\n",
            "61797/61797 [==============================] - 3s 44us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 6/10\n",
            "61797/61797 [==============================] - 3s 41us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 7/10\n",
            "61797/61797 [==============================] - 3s 44us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 8/10\n",
            "61797/61797 [==============================] - 3s 45us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 9/10\n",
            "61797/61797 [==============================] - 3s 46us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Epoch 10/10\n",
            "61797/61797 [==============================] - 3s 45us/step - loss: 0.6931 - acc: 0.5023 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
            "Test loss: 0.6931771939711424\n",
            "Test accuracy: 0.4987572493786247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99sLXV448bBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = \"relu\"\n",
        "optimizer = keras.optimizers.Adam()\n",
        "input_dim = train_x.shape[1]\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkKzLLmgqBFc",
        "colab_type": "code",
        "outputId": "71497aa4-040f-48a1-a577-9784c5d5ef45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session() # Tensorboard Callback error 방지를 위해 tensorboard의 session을 clear 해줌\n",
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "  model = Sequential()\n",
        "  # 첫 번째 Layer (Input layer)\n",
        "  model.add(Dense(input_dim=input_dim, init='glorot_uniform', activation=activation, output_dim=256))\n",
        "  model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
        "\n",
        "  # # 두 번째 Layer (Hidden layer 1)\n",
        "  model.add(Dense(output_dim=256, activation=activation))\n",
        "  model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
        "\n",
        "  # # 세 번째 Layer (Hidden layer 2)\n",
        "  model.add(Dense(output_dim=256, activation=activation))\n",
        "  model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
        "\n",
        "  # Dense Layer (Output layer)\n",
        "  model.add(Dense(output_dim=1))\n",
        "  model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "  # Cost function 및 Optimizer 설정 # binary class 분류이므로 binary_crossentropy 사용 # Adam optimizer 사용\n",
        "  model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=True),  metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "  tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                          write_graph=True,\n",
        "                          write_grads=True,\n",
        "                          batch_size=batch_size,\n",
        "                          write_images=True)\n",
        "  hist = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(val_x, val_y), callbacks=[tbCallBack])\n",
        "  \n",
        "  score = model.evaluate(test_x, test_y, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 61797 samples, validate on 15450 samples\n",
            "Epoch 1/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6944 - acc: 0.5185 - precision: 0.5171 - recall: 0.5119 - f1score: 0.5112 - val_loss: 0.6837 - val_acc: 0.5669 - val_precision: 0.5497 - val_recall: 0.7158 - val_f1score: 0.6204\n",
            "Epoch 2/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6853 - acc: 0.5528 - precision: 0.5522 - recall: 0.5429 - f1score: 0.5449 - val_loss: 0.6743 - val_acc: 0.5974 - val_precision: 0.5890 - val_recall: 0.6313 - val_f1score: 0.6078\n",
            "Epoch 3/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6778 - acc: 0.5753 - precision: 0.5751 - recall: 0.5637 - f1score: 0.5667 - val_loss: 0.6640 - val_acc: 0.6118 - val_precision: 0.6030 - val_recall: 0.6438 - val_f1score: 0.6211\n",
            "Epoch 4/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6693 - acc: 0.5888 - precision: 0.5881 - recall: 0.5791 - f1score: 0.5813 - val_loss: 0.6543 - val_acc: 0.6213 - val_precision: 0.6061 - val_recall: 0.6837 - val_f1score: 0.6410\n",
            "Epoch 5/100\n",
            "61797/61797 [==============================] - 4s 70us/step - loss: 0.6634 - acc: 0.6005 - precision: 0.5993 - recall: 0.5961 - f1score: 0.5956 - val_loss: 0.6477 - val_acc: 0.6280 - val_precision: 0.6146 - val_recall: 0.6779 - val_f1score: 0.6431\n",
            "Epoch 6/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6584 - acc: 0.6103 - precision: 0.6090 - recall: 0.6071 - f1score: 0.6061 - val_loss: 0.6443 - val_acc: 0.6315 - val_precision: 0.6174 - val_recall: 0.6825 - val_f1score: 0.6468\n",
            "Epoch 7/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6536 - acc: 0.6162 - precision: 0.6146 - recall: 0.6130 - f1score: 0.6118 - val_loss: 0.6415 - val_acc: 0.6331 - val_precision: 0.6235 - val_recall: 0.6643 - val_f1score: 0.6416\n",
            "Epoch 8/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6512 - acc: 0.6211 - precision: 0.6197 - recall: 0.6171 - f1score: 0.6163 - val_loss: 0.6399 - val_acc: 0.6356 - val_precision: 0.6355 - val_recall: 0.6306 - val_f1score: 0.6312\n",
            "Epoch 9/100\n",
            "61797/61797 [==============================] - 5s 74us/step - loss: 0.6497 - acc: 0.6211 - precision: 0.6202 - recall: 0.6168 - f1score: 0.6167 - val_loss: 0.6392 - val_acc: 0.6337 - val_precision: 0.6380 - val_recall: 0.6118 - val_f1score: 0.6227\n",
            "Epoch 10/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6483 - acc: 0.6238 - precision: 0.6241 - recall: 0.6124 - f1score: 0.6165 - val_loss: 0.6385 - val_acc: 0.6361 - val_precision: 0.6354 - val_recall: 0.6316 - val_f1score: 0.6316\n",
            "Epoch 11/100\n",
            "61797/61797 [==============================] - 5s 73us/step - loss: 0.6458 - acc: 0.6282 - precision: 0.6285 - recall: 0.6176 - f1score: 0.6208 - val_loss: 0.6379 - val_acc: 0.6376 - val_precision: 0.6338 - val_recall: 0.6455 - val_f1score: 0.6377\n",
            "Epoch 12/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6461 - acc: 0.6272 - precision: 0.6281 - recall: 0.6162 - f1score: 0.6201 - val_loss: 0.6376 - val_acc: 0.6374 - val_precision: 0.6423 - val_recall: 0.6140 - val_f1score: 0.6259\n",
            "Epoch 13/100\n",
            "61797/61797 [==============================] - 4s 69us/step - loss: 0.6440 - acc: 0.6304 - precision: 0.6326 - recall: 0.6137 - f1score: 0.6210 - val_loss: 0.6371 - val_acc: 0.6379 - val_precision: 0.6395 - val_recall: 0.6270 - val_f1score: 0.6312\n",
            "Epoch 14/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6434 - acc: 0.6287 - precision: 0.6310 - recall: 0.6135 - f1score: 0.6201 - val_loss: 0.6369 - val_acc: 0.6374 - val_precision: 0.6428 - val_recall: 0.6129 - val_f1score: 0.6256\n",
            "Epoch 15/100\n",
            "61797/61797 [==============================] - 5s 74us/step - loss: 0.6430 - acc: 0.6315 - precision: 0.6338 - recall: 0.6157 - f1score: 0.6223 - val_loss: 0.6368 - val_acc: 0.6370 - val_precision: 0.6399 - val_recall: 0.6203 - val_f1score: 0.6281\n",
            "Epoch 16/100\n",
            "61797/61797 [==============================] - 5s 83us/step - loss: 0.6423 - acc: 0.6316 - precision: 0.6341 - recall: 0.6141 - f1score: 0.6220 - val_loss: 0.6366 - val_acc: 0.6364 - val_precision: 0.6385 - val_recall: 0.6225 - val_f1score: 0.6285\n",
            "Epoch 17/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6425 - acc: 0.6325 - precision: 0.6352 - recall: 0.6175 - f1score: 0.6239 - val_loss: 0.6364 - val_acc: 0.6366 - val_precision: 0.6393 - val_recall: 0.6204 - val_f1score: 0.6278\n",
            "Epoch 18/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6413 - acc: 0.6323 - precision: 0.6361 - recall: 0.6141 - f1score: 0.6227 - val_loss: 0.6364 - val_acc: 0.6365 - val_precision: 0.6436 - val_recall: 0.6055 - val_f1score: 0.6220\n",
            "Epoch 19/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6399 - acc: 0.6351 - precision: 0.6381 - recall: 0.6148 - f1score: 0.6244 - val_loss: 0.6362 - val_acc: 0.6363 - val_precision: 0.6394 - val_recall: 0.6183 - val_f1score: 0.6268\n",
            "Epoch 20/100\n",
            "61797/61797 [==============================] - 4s 72us/step - loss: 0.6399 - acc: 0.6340 - precision: 0.6373 - recall: 0.6136 - f1score: 0.6230 - val_loss: 0.6361 - val_acc: 0.6365 - val_precision: 0.6430 - val_recall: 0.6074 - val_f1score: 0.6227\n",
            "Epoch 21/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6405 - acc: 0.6331 - precision: 0.6367 - recall: 0.6132 - f1score: 0.6226 - val_loss: 0.6359 - val_acc: 0.6361 - val_precision: 0.6424 - val_recall: 0.6069 - val_f1score: 0.6222\n",
            "Epoch 22/100\n",
            "61797/61797 [==============================] - 4s 71us/step - loss: 0.6398 - acc: 0.6335 - precision: 0.6363 - recall: 0.6157 - f1score: 0.6238 - val_loss: 0.6359 - val_acc: 0.6358 - val_precision: 0.6430 - val_recall: 0.6030 - val_f1score: 0.6204\n",
            "Epoch 23/100\n",
            "61797/61797 [==============================] - 5s 82us/step - loss: 0.6393 - acc: 0.6347 - precision: 0.6379 - recall: 0.6150 - f1score: 0.6243 - val_loss: 0.6358 - val_acc: 0.6360 - val_precision: 0.6443 - val_recall: 0.6000 - val_f1score: 0.6193\n",
            "Epoch 24/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6393 - acc: 0.6350 - precision: 0.6393 - recall: 0.6117 - f1score: 0.6233 - val_loss: 0.6356 - val_acc: 0.6365 - val_precision: 0.6398 - val_recall: 0.6182 - val_f1score: 0.6268\n",
            "Epoch 25/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6386 - acc: 0.6340 - precision: 0.6376 - recall: 0.6143 - f1score: 0.6237 - val_loss: 0.6356 - val_acc: 0.6369 - val_precision: 0.6383 - val_recall: 0.6251 - val_f1score: 0.6297\n",
            "Epoch 26/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6376 - acc: 0.6373 - precision: 0.6411 - recall: 0.6153 - f1score: 0.6258 - val_loss: 0.6354 - val_acc: 0.6374 - val_precision: 0.6380 - val_recall: 0.6282 - val_f1score: 0.6312\n",
            "Epoch 27/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6378 - acc: 0.6362 - precision: 0.6391 - recall: 0.6176 - f1score: 0.6263 - val_loss: 0.6355 - val_acc: 0.6372 - val_precision: 0.6417 - val_recall: 0.6141 - val_f1score: 0.6257\n",
            "Epoch 28/100\n",
            "61797/61797 [==============================] - 5s 73us/step - loss: 0.6389 - acc: 0.6356 - precision: 0.6397 - recall: 0.6144 - f1score: 0.6247 - val_loss: 0.6353 - val_acc: 0.6375 - val_precision: 0.6426 - val_recall: 0.6121 - val_f1score: 0.6251\n",
            "Epoch 29/100\n",
            "61797/61797 [==============================] - 5s 83us/step - loss: 0.6373 - acc: 0.6360 - precision: 0.6387 - recall: 0.6170 - f1score: 0.6258 - val_loss: 0.6355 - val_acc: 0.6380 - val_precision: 0.6484 - val_recall: 0.5956 - val_f1score: 0.6189\n",
            "Epoch 30/100\n",
            "61797/61797 [==============================] - 4s 72us/step - loss: 0.6374 - acc: 0.6371 - precision: 0.6419 - recall: 0.6134 - f1score: 0.6253 - val_loss: 0.6352 - val_acc: 0.6375 - val_precision: 0.6412 - val_recall: 0.6174 - val_f1score: 0.6272\n",
            "Epoch 31/100\n",
            "61797/61797 [==============================] - 5s 80us/step - loss: 0.6374 - acc: 0.6377 - precision: 0.6414 - recall: 0.6164 - f1score: 0.6267 - val_loss: 0.6352 - val_acc: 0.6367 - val_precision: 0.6411 - val_recall: 0.6142 - val_f1score: 0.6254\n",
            "Epoch 32/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6363 - acc: 0.6389 - precision: 0.6424 - recall: 0.6168 - f1score: 0.6277 - val_loss: 0.6353 - val_acc: 0.6377 - val_precision: 0.6468 - val_recall: 0.5993 - val_f1score: 0.6201\n",
            "Epoch 33/100\n",
            "61797/61797 [==============================] - 5s 80us/step - loss: 0.6374 - acc: 0.6366 - precision: 0.6409 - recall: 0.6141 - f1score: 0.6249 - val_loss: 0.6352 - val_acc: 0.6381 - val_precision: 0.6400 - val_recall: 0.6243 - val_f1score: 0.6301\n",
            "Epoch 34/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6367 - acc: 0.6375 - precision: 0.6416 - recall: 0.6159 - f1score: 0.6265 - val_loss: 0.6351 - val_acc: 0.6379 - val_precision: 0.6429 - val_recall: 0.6122 - val_f1score: 0.6253\n",
            "Epoch 35/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6361 - acc: 0.6387 - precision: 0.6425 - recall: 0.6188 - f1score: 0.6285 - val_loss: 0.6350 - val_acc: 0.6380 - val_precision: 0.6435 - val_recall: 0.6109 - val_f1score: 0.6248\n",
            "Epoch 36/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6364 - acc: 0.6380 - precision: 0.6420 - recall: 0.6154 - f1score: 0.6265 - val_loss: 0.6349 - val_acc: 0.6386 - val_precision: 0.6406 - val_recall: 0.6244 - val_f1score: 0.6305\n",
            "Epoch 37/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6360 - acc: 0.6382 - precision: 0.6414 - recall: 0.6177 - f1score: 0.6272 - val_loss: 0.6350 - val_acc: 0.6379 - val_precision: 0.6457 - val_recall: 0.6037 - val_f1score: 0.6219\n",
            "Epoch 38/100\n",
            "61797/61797 [==============================] - 4s 73us/step - loss: 0.6355 - acc: 0.6385 - precision: 0.6425 - recall: 0.6165 - f1score: 0.6274 - val_loss: 0.6348 - val_acc: 0.6384 - val_precision: 0.6420 - val_recall: 0.6183 - val_f1score: 0.6279\n",
            "Epoch 39/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6359 - acc: 0.6404 - precision: 0.6444 - recall: 0.6191 - f1score: 0.6295 - val_loss: 0.6348 - val_acc: 0.6393 - val_precision: 0.6469 - val_recall: 0.6059 - val_f1score: 0.6237\n",
            "Epoch 40/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6353 - acc: 0.6377 - precision: 0.6417 - recall: 0.6153 - f1score: 0.6264 - val_loss: 0.6348 - val_acc: 0.6390 - val_precision: 0.6471 - val_recall: 0.6040 - val_f1score: 0.6227\n",
            "Epoch 41/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6348 - acc: 0.6378 - precision: 0.6422 - recall: 0.6155 - f1score: 0.6264 - val_loss: 0.6346 - val_acc: 0.6387 - val_precision: 0.6460 - val_recall: 0.6065 - val_f1score: 0.6236\n",
            "Epoch 42/100\n",
            "61797/61797 [==============================] - 5s 82us/step - loss: 0.6352 - acc: 0.6388 - precision: 0.6424 - recall: 0.6179 - f1score: 0.6280 - val_loss: 0.6346 - val_acc: 0.6393 - val_precision: 0.6429 - val_recall: 0.6189 - val_f1score: 0.6287\n",
            "Epoch 43/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6349 - acc: 0.6403 - precision: 0.6447 - recall: 0.6192 - f1score: 0.6298 - val_loss: 0.6347 - val_acc: 0.6389 - val_precision: 0.6477 - val_recall: 0.6023 - val_f1score: 0.6220\n",
            "Epoch 44/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6350 - acc: 0.6389 - precision: 0.6426 - recall: 0.6188 - f1score: 0.6285 - val_loss: 0.6345 - val_acc: 0.6381 - val_precision: 0.6426 - val_recall: 0.6151 - val_f1score: 0.6265\n",
            "Epoch 45/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6347 - acc: 0.6393 - precision: 0.6441 - recall: 0.6171 - f1score: 0.6285 - val_loss: 0.6345 - val_acc: 0.6399 - val_precision: 0.6400 - val_recall: 0.6329 - val_f1score: 0.6345\n",
            "Epoch 46/100\n",
            "61797/61797 [==============================] - 5s 83us/step - loss: 0.6346 - acc: 0.6382 - precision: 0.6412 - recall: 0.6207 - f1score: 0.6286 - val_loss: 0.6344 - val_acc: 0.6391 - val_precision: 0.6424 - val_recall: 0.6204 - val_f1score: 0.6292\n",
            "Epoch 47/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6338 - acc: 0.6395 - precision: 0.6435 - recall: 0.6186 - f1score: 0.6286 - val_loss: 0.6345 - val_acc: 0.6386 - val_precision: 0.6473 - val_recall: 0.6015 - val_f1score: 0.6215\n",
            "Epoch 48/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6339 - acc: 0.6388 - precision: 0.6429 - recall: 0.6195 - f1score: 0.6289 - val_loss: 0.6344 - val_acc: 0.6398 - val_precision: 0.6459 - val_recall: 0.6109 - val_f1score: 0.6259\n",
            "Epoch 49/100\n",
            "61797/61797 [==============================] - 5s 74us/step - loss: 0.6346 - acc: 0.6403 - precision: 0.6449 - recall: 0.6173 - f1score: 0.6288 - val_loss: 0.6343 - val_acc: 0.6403 - val_precision: 0.6409 - val_recall: 0.6316 - val_f1score: 0.6344\n",
            "Epoch 50/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6340 - acc: 0.6408 - precision: 0.6444 - recall: 0.6220 - f1score: 0.6310 - val_loss: 0.6343 - val_acc: 0.6392 - val_precision: 0.6468 - val_recall: 0.6056 - val_f1score: 0.6235\n",
            "Epoch 51/100\n",
            "61797/61797 [==============================] - 5s 80us/step - loss: 0.6335 - acc: 0.6412 - precision: 0.6442 - recall: 0.6227 - f1score: 0.6315 - val_loss: 0.6343 - val_acc: 0.6399 - val_precision: 0.6461 - val_recall: 0.6121 - val_f1score: 0.6266\n",
            "Epoch 52/100\n",
            "61797/61797 [==============================] - 5s 74us/step - loss: 0.6340 - acc: 0.6400 - precision: 0.6432 - recall: 0.6210 - f1score: 0.6302 - val_loss: 0.6343 - val_acc: 0.6405 - val_precision: 0.6408 - val_recall: 0.6329 - val_f1score: 0.6349\n",
            "Epoch 53/100\n",
            "61797/61797 [==============================] - 5s 80us/step - loss: 0.6336 - acc: 0.6395 - precision: 0.6425 - recall: 0.6216 - f1score: 0.6299 - val_loss: 0.6342 - val_acc: 0.6405 - val_precision: 0.6447 - val_recall: 0.6191 - val_f1score: 0.6296\n",
            "Epoch 54/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6340 - acc: 0.6415 - precision: 0.6453 - recall: 0.6216 - f1score: 0.6313 - val_loss: 0.6342 - val_acc: 0.6400 - val_precision: 0.6434 - val_recall: 0.6211 - val_f1score: 0.6302\n",
            "Epoch 55/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6330 - acc: 0.6393 - precision: 0.6429 - recall: 0.6187 - f1score: 0.6288 - val_loss: 0.6342 - val_acc: 0.6397 - val_precision: 0.6462 - val_recall: 0.6102 - val_f1score: 0.6257\n",
            "Epoch 56/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6334 - acc: 0.6412 - precision: 0.6457 - recall: 0.6187 - f1score: 0.6299 - val_loss: 0.6344 - val_acc: 0.6395 - val_precision: 0.6486 - val_recall: 0.6015 - val_f1score: 0.6221\n",
            "Epoch 57/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6327 - acc: 0.6426 - precision: 0.6469 - recall: 0.6209 - f1score: 0.6317 - val_loss: 0.6343 - val_acc: 0.6399 - val_precision: 0.6441 - val_recall: 0.6177 - val_f1score: 0.6286\n",
            "Epoch 58/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6327 - acc: 0.6405 - precision: 0.6435 - recall: 0.6216 - f1score: 0.6306 - val_loss: 0.6342 - val_acc: 0.6399 - val_precision: 0.6453 - val_recall: 0.6139 - val_f1score: 0.6273\n",
            "Epoch 59/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6332 - acc: 0.6406 - precision: 0.6450 - recall: 0.6182 - f1score: 0.6294 - val_loss: 0.6342 - val_acc: 0.6404 - val_precision: 0.6399 - val_recall: 0.6358 - val_f1score: 0.6360\n",
            "Epoch 60/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6331 - acc: 0.6414 - precision: 0.6443 - recall: 0.6241 - f1score: 0.6321 - val_loss: 0.6342 - val_acc: 0.6398 - val_precision: 0.6492 - val_recall: 0.6004 - val_f1score: 0.6219\n",
            "Epoch 61/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6331 - acc: 0.6425 - precision: 0.6456 - recall: 0.6249 - f1score: 0.6332 - val_loss: 0.6340 - val_acc: 0.6414 - val_precision: 0.6460 - val_recall: 0.6191 - val_f1score: 0.6303\n",
            "Epoch 62/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6326 - acc: 0.6416 - precision: 0.6454 - recall: 0.6210 - f1score: 0.6309 - val_loss: 0.6339 - val_acc: 0.6412 - val_precision: 0.6412 - val_recall: 0.6349 - val_f1score: 0.6362\n",
            "Epoch 63/100\n",
            "61797/61797 [==============================] - 5s 74us/step - loss: 0.6325 - acc: 0.6409 - precision: 0.6447 - recall: 0.6207 - f1score: 0.6306 - val_loss: 0.6339 - val_acc: 0.6412 - val_precision: 0.6410 - val_recall: 0.6354 - val_f1score: 0.6363\n",
            "Epoch 64/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6325 - acc: 0.6423 - precision: 0.6454 - recall: 0.6258 - f1score: 0.6334 - val_loss: 0.6339 - val_acc: 0.6410 - val_precision: 0.6450 - val_recall: 0.6203 - val_f1score: 0.6304\n",
            "Epoch 65/100\n",
            "61797/61797 [==============================] - 5s 74us/step - loss: 0.6318 - acc: 0.6419 - precision: 0.6451 - recall: 0.6233 - f1score: 0.6321 - val_loss: 0.6339 - val_acc: 0.6405 - val_precision: 0.6459 - val_recall: 0.6152 - val_f1score: 0.6282\n",
            "Epoch 66/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6321 - acc: 0.6421 - precision: 0.6459 - recall: 0.6228 - f1score: 0.6322 - val_loss: 0.6339 - val_acc: 0.6405 - val_precision: 0.6426 - val_recall: 0.6257 - val_f1score: 0.6321\n",
            "Epoch 67/100\n",
            "61797/61797 [==============================] - 5s 78us/step - loss: 0.6318 - acc: 0.6410 - precision: 0.6446 - recall: 0.6213 - f1score: 0.6307 - val_loss: 0.6339 - val_acc: 0.6405 - val_precision: 0.6460 - val_recall: 0.6154 - val_f1score: 0.6283\n",
            "Epoch 68/100\n",
            "61797/61797 [==============================] - 5s 82us/step - loss: 0.6325 - acc: 0.6422 - precision: 0.6460 - recall: 0.6221 - f1score: 0.6318 - val_loss: 0.6340 - val_acc: 0.6405 - val_precision: 0.6468 - val_recall: 0.6119 - val_f1score: 0.6269\n",
            "Epoch 69/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6315 - acc: 0.6430 - precision: 0.6467 - recall: 0.6238 - f1score: 0.6331 - val_loss: 0.6343 - val_acc: 0.6404 - val_precision: 0.6529 - val_recall: 0.5921 - val_f1score: 0.6190\n",
            "Epoch 70/100\n",
            "61797/61797 [==============================] - 5s 82us/step - loss: 0.6314 - acc: 0.6434 - precision: 0.6480 - recall: 0.6198 - f1score: 0.6316 - val_loss: 0.6339 - val_acc: 0.6399 - val_precision: 0.6390 - val_recall: 0.6364 - val_f1score: 0.6358\n",
            "Epoch 71/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6321 - acc: 0.6419 - precision: 0.6448 - recall: 0.6237 - f1score: 0.6321 - val_loss: 0.6340 - val_acc: 0.6412 - val_precision: 0.6499 - val_recall: 0.6053 - val_f1score: 0.6248\n",
            "Epoch 72/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6316 - acc: 0.6431 - precision: 0.6469 - recall: 0.6251 - f1score: 0.6336 - val_loss: 0.6338 - val_acc: 0.6404 - val_precision: 0.6421 - val_recall: 0.6278 - val_f1score: 0.6330\n",
            "Epoch 73/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6317 - acc: 0.6430 - precision: 0.6456 - recall: 0.6246 - f1score: 0.6334 - val_loss: 0.6338 - val_acc: 0.6411 - val_precision: 0.6445 - val_recall: 0.6227 - val_f1score: 0.6315\n",
            "Epoch 74/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6312 - acc: 0.6437 - precision: 0.6471 - recall: 0.6253 - f1score: 0.6341 - val_loss: 0.6338 - val_acc: 0.6409 - val_precision: 0.6406 - val_recall: 0.6359 - val_f1score: 0.6363\n",
            "Epoch 75/100\n",
            "61797/61797 [==============================] - 5s 86us/step - loss: 0.6311 - acc: 0.6437 - precision: 0.6460 - recall: 0.6285 - f1score: 0.6351 - val_loss: 0.6339 - val_acc: 0.6411 - val_precision: 0.6488 - val_recall: 0.6089 - val_f1score: 0.6262\n",
            "Epoch 76/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6313 - acc: 0.6416 - precision: 0.6448 - recall: 0.6241 - f1score: 0.6323 - val_loss: 0.6340 - val_acc: 0.6401 - val_precision: 0.6484 - val_recall: 0.6059 - val_f1score: 0.6243\n",
            "Epoch 77/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6315 - acc: 0.6429 - precision: 0.6461 - recall: 0.6256 - f1score: 0.6338 - val_loss: 0.6338 - val_acc: 0.6399 - val_precision: 0.6443 - val_recall: 0.6183 - val_f1score: 0.6290\n",
            "Epoch 78/100\n",
            "61797/61797 [==============================] - 5s 82us/step - loss: 0.6306 - acc: 0.6456 - precision: 0.6493 - recall: 0.6269 - f1score: 0.6358 - val_loss: 0.6338 - val_acc: 0.6399 - val_precision: 0.6428 - val_recall: 0.6236 - val_f1score: 0.6311\n",
            "Epoch 79/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6310 - acc: 0.6434 - precision: 0.6468 - recall: 0.6219 - f1score: 0.6323 - val_loss: 0.6339 - val_acc: 0.6406 - val_precision: 0.6387 - val_recall: 0.6412 - val_f1score: 0.6380\n",
            "Epoch 80/100\n",
            "61797/61797 [==============================] - 5s 86us/step - loss: 0.6306 - acc: 0.6444 - precision: 0.6475 - recall: 0.6259 - f1score: 0.6346 - val_loss: 0.6340 - val_acc: 0.6408 - val_precision: 0.6499 - val_recall: 0.6041 - val_f1score: 0.6240\n",
            "Epoch 81/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6313 - acc: 0.6443 - precision: 0.6487 - recall: 0.6251 - f1score: 0.6344 - val_loss: 0.6338 - val_acc: 0.6410 - val_precision: 0.6454 - val_recall: 0.6203 - val_f1score: 0.6306\n",
            "Epoch 82/100\n",
            "61797/61797 [==============================] - 5s 85us/step - loss: 0.6311 - acc: 0.6441 - precision: 0.6475 - recall: 0.6250 - f1score: 0.6343 - val_loss: 0.6340 - val_acc: 0.6408 - val_precision: 0.6494 - val_recall: 0.6056 - val_f1score: 0.6245\n",
            "Epoch 83/100\n",
            "61797/61797 [==============================] - 5s 80us/step - loss: 0.6306 - acc: 0.6454 - precision: 0.6498 - recall: 0.6240 - f1score: 0.6348 - val_loss: 0.6340 - val_acc: 0.6407 - val_precision: 0.6481 - val_recall: 0.6088 - val_f1score: 0.6257\n",
            "Epoch 84/100\n",
            "61797/61797 [==============================] - 5s 75us/step - loss: 0.6299 - acc: 0.6435 - precision: 0.6463 - recall: 0.6258 - f1score: 0.6343 - val_loss: 0.6341 - val_acc: 0.6408 - val_precision: 0.6497 - val_recall: 0.6043 - val_f1score: 0.6240\n",
            "Epoch 85/100\n",
            "61797/61797 [==============================] - 5s 83us/step - loss: 0.6294 - acc: 0.6451 - precision: 0.6496 - recall: 0.6230 - f1score: 0.6339 - val_loss: 0.6338 - val_acc: 0.6403 - val_precision: 0.6418 - val_recall: 0.6291 - val_f1score: 0.6334\n",
            "Epoch 86/100\n",
            "61797/61797 [==============================] - 5s 79us/step - loss: 0.6302 - acc: 0.6435 - precision: 0.6469 - recall: 0.6258 - f1score: 0.6342 - val_loss: 0.6337 - val_acc: 0.6414 - val_precision: 0.6448 - val_recall: 0.6232 - val_f1score: 0.6318\n",
            "Epoch 87/100\n",
            "61797/61797 [==============================] - 5s 85us/step - loss: 0.6302 - acc: 0.6436 - precision: 0.6466 - recall: 0.6245 - f1score: 0.6335 - val_loss: 0.6336 - val_acc: 0.6399 - val_precision: 0.6407 - val_recall: 0.6312 - val_f1score: 0.6339\n",
            "Epoch 88/100\n",
            "61797/61797 [==============================] - 5s 80us/step - loss: 0.6300 - acc: 0.6440 - precision: 0.6473 - recall: 0.6256 - f1score: 0.6344 - val_loss: 0.6338 - val_acc: 0.6413 - val_precision: 0.6455 - val_recall: 0.6202 - val_f1score: 0.6306\n",
            "Epoch 89/100\n",
            "61797/61797 [==============================] - 5s 76us/step - loss: 0.6301 - acc: 0.6456 - precision: 0.6487 - recall: 0.6264 - f1score: 0.6354 - val_loss: 0.6338 - val_acc: 0.6399 - val_precision: 0.6391 - val_recall: 0.6372 - val_f1score: 0.6361\n",
            "Epoch 90/100\n",
            "61797/61797 [==============================] - 5s 83us/step - loss: 0.6299 - acc: 0.6445 - precision: 0.6481 - recall: 0.6261 - f1score: 0.6349 - val_loss: 0.6339 - val_acc: 0.6409 - val_precision: 0.6491 - val_recall: 0.6073 - val_f1score: 0.6254\n",
            "Epoch 91/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6297 - acc: 0.6447 - precision: 0.6477 - recall: 0.6262 - f1score: 0.6348 - val_loss: 0.6337 - val_acc: 0.6405 - val_precision: 0.6423 - val_recall: 0.6285 - val_f1score: 0.6333\n",
            "Epoch 92/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6298 - acc: 0.6429 - precision: 0.6460 - recall: 0.6237 - f1score: 0.6328 - val_loss: 0.6337 - val_acc: 0.6396 - val_precision: 0.6427 - val_recall: 0.6233 - val_f1score: 0.6308\n",
            "Epoch 93/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6296 - acc: 0.6450 - precision: 0.6487 - recall: 0.6257 - f1score: 0.6349 - val_loss: 0.6337 - val_acc: 0.6396 - val_precision: 0.6419 - val_recall: 0.6259 - val_f1score: 0.6317\n",
            "Epoch 94/100\n",
            "61797/61797 [==============================] - 5s 83us/step - loss: 0.6304 - acc: 0.6447 - precision: 0.6485 - recall: 0.6249 - f1score: 0.6344 - val_loss: 0.6339 - val_acc: 0.6398 - val_precision: 0.6375 - val_recall: 0.6431 - val_f1score: 0.6383\n",
            "Epoch 95/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6290 - acc: 0.6447 - precision: 0.6477 - recall: 0.6277 - f1score: 0.6356 - val_loss: 0.6338 - val_acc: 0.6415 - val_precision: 0.6468 - val_recall: 0.6179 - val_f1score: 0.6299\n",
            "Epoch 96/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6293 - acc: 0.6450 - precision: 0.6492 - recall: 0.6248 - f1score: 0.6347 - val_loss: 0.6337 - val_acc: 0.6405 - val_precision: 0.6422 - val_recall: 0.6285 - val_f1score: 0.6332\n",
            "Epoch 97/100\n",
            "61797/61797 [==============================] - 5s 77us/step - loss: 0.6292 - acc: 0.6450 - precision: 0.6480 - recall: 0.6266 - f1score: 0.6352 - val_loss: 0.6338 - val_acc: 0.6405 - val_precision: 0.6460 - val_recall: 0.6157 - val_f1score: 0.6284\n",
            "Epoch 98/100\n",
            "61797/61797 [==============================] - 5s 82us/step - loss: 0.6293 - acc: 0.6459 - precision: 0.6499 - recall: 0.6259 - f1score: 0.6355 - val_loss: 0.6337 - val_acc: 0.6403 - val_precision: 0.6438 - val_recall: 0.6229 - val_f1score: 0.6311\n",
            "Epoch 99/100\n",
            "61797/61797 [==============================] - 5s 81us/step - loss: 0.6290 - acc: 0.6448 - precision: 0.6479 - recall: 0.6280 - f1score: 0.6357 - val_loss: 0.6338 - val_acc: 0.6408 - val_precision: 0.6475 - val_recall: 0.6125 - val_f1score: 0.6273\n",
            "Epoch 100/100\n",
            "61797/61797 [==============================] - 5s 74us/step - loss: 0.6287 - acc: 0.6455 - precision: 0.6492 - recall: 0.6270 - f1score: 0.6360 - val_loss: 0.6338 - val_acc: 0.6400 - val_precision: 0.6399 - val_recall: 0.6355 - val_f1score: 0.6356\n",
            "Test loss: 0.6355244357820967\n",
            "Test accuracy: 0.6398612261806131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDJNtM_n6iwd",
        "colab_type": "code",
        "outputId": "7f32d3c3-e6a0-4921-ea2c-3b9614273969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='lowere left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAEJCAYAAAAJnlldAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIIgeKz/Dy59GO9FzFHUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjVnDKnJ1zNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# activation = \"tanh\"\n",
        "# optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
        "# input_dim = train_x.shape[1]\n",
        "# batch_size = 128\n",
        "# epochs = 100\n",
        "activation = \"relu\"\n",
        "optimizer = keras.optimizers.Adam()\n",
        "input_dim = train_x.shape[1]\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPPmLKAGB1FL",
        "colab_type": "code",
        "outputId": "ace031dd-69dd-4764-a7dd-45237cef7094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session() # Tensorboard Callback error 방지를 위해 tensorboard의 session을 clear 해줌\n",
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "  model = Sequential()\n",
        "  # 첫 번째 Layer (Input layer)\n",
        "  model.add(Dense(input_dim=input_dim, init='glorot_uniform', output_dim=256))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
        "\n",
        "\n",
        "  # # 두 번째 Layer (Hidden layer 1)\n",
        "  model.add(Dense(output_dim=256))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
        "\n",
        "  # # 세 번째 Layer (Hidden layer 2)\n",
        "  model.add(Dense(output_dim=256))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
        "  \n",
        "  # Dense Layer (Output layer)\n",
        "  model.add(Dense(output_dim=1))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "  # Cost function 및 Optimizer 설정 # binary class 분류이므로 binary_crossentropy 사용 # Adam optimizer 사용\n",
        "  model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=True),  metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "  callbacks = [TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                          write_graph=True,\n",
        "                          write_grads=True,\n",
        "                          batch_size=batch_size,\n",
        "                          write_images=True),\n",
        "               keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                           patience=5),\n",
        "              keras.callbacks.ModelCheckpoint(filepath='best_model.h5',\n",
        "                                             monitor='val_loss',\n",
        "                                             save_best_only=True)]\n",
        "  \n",
        "  hist = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(val_x, val_y), callbacks=callbacks)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 61797 samples, validate on 15450 samples\n",
            "Epoch 1/100\n",
            "61797/61797 [==============================] - 7s 115us/step - loss: 0.7069 - acc: 0.5605 - precision: 0.5594 - recall: 0.5547 - f1score: 0.5554 - val_loss: 0.6548 - val_acc: 0.6164 - val_precision: 0.6370 - val_recall: 0.5378 - val_f1score: 0.5812\n",
            "Epoch 2/100\n",
            "61797/61797 [==============================] - 6s 98us/step - loss: 0.6673 - acc: 0.5938 - precision: 0.5955 - recall: 0.5779 - f1score: 0.5848 - val_loss: 0.6508 - val_acc: 0.6254 - val_precision: 0.6522 - val_recall: 0.5357 - val_f1score: 0.5861\n",
            "Epoch 3/100\n",
            "61797/61797 [==============================] - 7s 110us/step - loss: 0.6600 - acc: 0.6049 - precision: 0.6081 - recall: 0.5823 - f1score: 0.5934 - val_loss: 0.6475 - val_acc: 0.6293 - val_precision: 0.6539 - val_recall: 0.5462 - val_f1score: 0.5932\n",
            "Epoch 4/100\n",
            "61797/61797 [==============================] - 7s 106us/step - loss: 0.6554 - acc: 0.6126 - precision: 0.6147 - recall: 0.5964 - f1score: 0.6037 - val_loss: 0.6445 - val_acc: 0.6314 - val_precision: 0.6584 - val_recall: 0.5431 - val_f1score: 0.5932\n",
            "Epoch 5/100\n",
            "61797/61797 [==============================] - 6s 104us/step - loss: 0.6521 - acc: 0.6170 - precision: 0.6215 - recall: 0.5921 - f1score: 0.6045 - val_loss: 0.6426 - val_acc: 0.6306 - val_precision: 0.6563 - val_recall: 0.5459 - val_f1score: 0.5938\n",
            "Epoch 6/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6498 - acc: 0.6213 - precision: 0.6248 - recall: 0.6008 - f1score: 0.6109 - val_loss: 0.6411 - val_acc: 0.6313 - val_precision: 0.6552 - val_recall: 0.5507 - val_f1score: 0.5962\n",
            "Epoch 7/100\n",
            "61797/61797 [==============================] - 6s 103us/step - loss: 0.6482 - acc: 0.6248 - precision: 0.6293 - recall: 0.6020 - f1score: 0.6136 - val_loss: 0.6397 - val_acc: 0.6337 - val_precision: 0.6530 - val_recall: 0.5665 - val_f1score: 0.6046\n",
            "Epoch 8/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6471 - acc: 0.6242 - precision: 0.6287 - recall: 0.6001 - f1score: 0.6125 - val_loss: 0.6390 - val_acc: 0.6332 - val_precision: 0.6520 - val_recall: 0.5673 - val_f1score: 0.6047\n",
            "Epoch 9/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6454 - acc: 0.6281 - precision: 0.6321 - recall: 0.6071 - f1score: 0.6177 - val_loss: 0.6388 - val_acc: 0.6330 - val_precision: 0.6544 - val_recall: 0.5587 - val_f1score: 0.6008\n",
            "Epoch 10/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6452 - acc: 0.6278 - precision: 0.6330 - recall: 0.6013 - f1score: 0.6153 - val_loss: 0.6377 - val_acc: 0.6353 - val_precision: 0.6494 - val_recall: 0.5839 - val_f1score: 0.6128\n",
            "Epoch 11/100\n",
            "61797/61797 [==============================] - 6s 104us/step - loss: 0.6447 - acc: 0.6271 - precision: 0.6317 - recall: 0.6022 - f1score: 0.6151 - val_loss: 0.6376 - val_acc: 0.6339 - val_precision: 0.6527 - val_recall: 0.5672 - val_f1score: 0.6049\n",
            "Epoch 12/100\n",
            "61797/61797 [==============================] - 6s 104us/step - loss: 0.6431 - acc: 0.6301 - precision: 0.6347 - recall: 0.6070 - f1score: 0.6189 - val_loss: 0.6370 - val_acc: 0.6342 - val_precision: 0.6508 - val_recall: 0.5741 - val_f1score: 0.6079\n",
            "Epoch 13/100\n",
            "61797/61797 [==============================] - 6s 104us/step - loss: 0.6419 - acc: 0.6310 - precision: 0.6366 - recall: 0.6048 - f1score: 0.6187 - val_loss: 0.6367 - val_acc: 0.6353 - val_precision: 0.6513 - val_recall: 0.5779 - val_f1score: 0.6102\n",
            "Epoch 14/100\n",
            "61797/61797 [==============================] - 6s 102us/step - loss: 0.6421 - acc: 0.6315 - precision: 0.6364 - recall: 0.6080 - f1score: 0.6203 - val_loss: 0.6366 - val_acc: 0.6351 - val_precision: 0.6545 - val_recall: 0.5671 - val_f1score: 0.6054\n",
            "Epoch 15/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6411 - acc: 0.6328 - precision: 0.6381 - recall: 0.6074 - f1score: 0.6208 - val_loss: 0.6362 - val_acc: 0.6362 - val_precision: 0.6519 - val_recall: 0.5796 - val_f1score: 0.6114\n",
            "Epoch 16/100\n",
            "61797/61797 [==============================] - 6s 94us/step - loss: 0.6406 - acc: 0.6330 - precision: 0.6381 - recall: 0.6083 - f1score: 0.6213 - val_loss: 0.6360 - val_acc: 0.6370 - val_precision: 0.6522 - val_recall: 0.5816 - val_f1score: 0.6127\n",
            "Epoch 17/100\n",
            "61797/61797 [==============================] - 6s 95us/step - loss: 0.6398 - acc: 0.6335 - precision: 0.6393 - recall: 0.6068 - f1score: 0.6210 - val_loss: 0.6358 - val_acc: 0.6368 - val_precision: 0.6539 - val_recall: 0.5771 - val_f1score: 0.6108\n",
            "Epoch 18/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6400 - acc: 0.6320 - precision: 0.6369 - recall: 0.6088 - f1score: 0.6207 - val_loss: 0.6356 - val_acc: 0.6370 - val_precision: 0.6504 - val_recall: 0.5879 - val_f1score: 0.6154\n",
            "Epoch 19/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6401 - acc: 0.6339 - precision: 0.6397 - recall: 0.6081 - f1score: 0.6219 - val_loss: 0.6355 - val_acc: 0.6373 - val_precision: 0.6513 - val_recall: 0.5866 - val_f1score: 0.6151\n",
            "Epoch 20/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6399 - acc: 0.6327 - precision: 0.6374 - recall: 0.6105 - f1score: 0.6219 - val_loss: 0.6357 - val_acc: 0.6379 - val_precision: 0.6540 - val_recall: 0.5808 - val_f1score: 0.6130\n",
            "Epoch 21/100\n",
            "61797/61797 [==============================] - 6s 105us/step - loss: 0.6392 - acc: 0.6375 - precision: 0.6425 - recall: 0.6135 - f1score: 0.6260 - val_loss: 0.6354 - val_acc: 0.6383 - val_precision: 0.6508 - val_recall: 0.5918 - val_f1score: 0.6177\n",
            "Epoch 22/100\n",
            "61797/61797 [==============================] - 6s 97us/step - loss: 0.6385 - acc: 0.6346 - precision: 0.6390 - recall: 0.6120 - f1score: 0.6237 - val_loss: 0.6352 - val_acc: 0.6385 - val_precision: 0.6506 - val_recall: 0.5939 - val_f1score: 0.6188\n",
            "Epoch 23/100\n",
            "61797/61797 [==============================] - 6s 94us/step - loss: 0.6377 - acc: 0.6337 - precision: 0.6382 - recall: 0.6113 - f1score: 0.6228 - val_loss: 0.6352 - val_acc: 0.6372 - val_precision: 0.6519 - val_recall: 0.5846 - val_f1score: 0.6142\n",
            "Epoch 24/100\n",
            "61797/61797 [==============================] - 6s 98us/step - loss: 0.6386 - acc: 0.6344 - precision: 0.6403 - recall: 0.6085 - f1score: 0.6222 - val_loss: 0.6351 - val_acc: 0.6377 - val_precision: 0.6508 - val_recall: 0.5897 - val_f1score: 0.6165\n",
            "Epoch 25/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6388 - acc: 0.6342 - precision: 0.6392 - recall: 0.6098 - f1score: 0.6227 - val_loss: 0.6348 - val_acc: 0.6394 - val_precision: 0.6494 - val_recall: 0.6010 - val_f1score: 0.6221\n",
            "Epoch 26/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6375 - acc: 0.6376 - precision: 0.6430 - recall: 0.6145 - f1score: 0.6266 - val_loss: 0.6349 - val_acc: 0.6377 - val_precision: 0.6510 - val_recall: 0.5890 - val_f1score: 0.6163\n",
            "Epoch 27/100\n",
            "61797/61797 [==============================] - 6s 95us/step - loss: 0.6382 - acc: 0.6368 - precision: 0.6424 - recall: 0.6110 - f1score: 0.6246 - val_loss: 0.6349 - val_acc: 0.6384 - val_precision: 0.6507 - val_recall: 0.5935 - val_f1score: 0.6185\n",
            "Epoch 28/100\n",
            "61797/61797 [==============================] - 6s 97us/step - loss: 0.6377 - acc: 0.6371 - precision: 0.6428 - recall: 0.6123 - f1score: 0.6255 - val_loss: 0.6348 - val_acc: 0.6385 - val_precision: 0.6509 - val_recall: 0.5930 - val_f1score: 0.6184\n",
            "Epoch 29/100\n",
            "61797/61797 [==============================] - 6s 96us/step - loss: 0.6365 - acc: 0.6360 - precision: 0.6407 - recall: 0.6140 - f1score: 0.6254 - val_loss: 0.6346 - val_acc: 0.6389 - val_precision: 0.6508 - val_recall: 0.5948 - val_f1score: 0.6193\n",
            "Epoch 30/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6369 - acc: 0.6380 - precision: 0.6437 - recall: 0.6130 - f1score: 0.6262 - val_loss: 0.6345 - val_acc: 0.6390 - val_precision: 0.6512 - val_recall: 0.5942 - val_f1score: 0.6192\n",
            "Epoch 31/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6371 - acc: 0.6368 - precision: 0.6418 - recall: 0.6135 - f1score: 0.6256 - val_loss: 0.6346 - val_acc: 0.6390 - val_precision: 0.6503 - val_recall: 0.5956 - val_f1score: 0.6197\n",
            "Epoch 32/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6363 - acc: 0.6376 - precision: 0.6429 - recall: 0.6142 - f1score: 0.6266 - val_loss: 0.6347 - val_acc: 0.6384 - val_precision: 0.6526 - val_recall: 0.5871 - val_f1score: 0.6159\n",
            "Epoch 33/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6375 - acc: 0.6365 - precision: 0.6423 - recall: 0.6101 - f1score: 0.6242 - val_loss: 0.6345 - val_acc: 0.6387 - val_precision: 0.6499 - val_recall: 0.5966 - val_f1score: 0.6199\n",
            "Epoch 34/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6367 - acc: 0.6378 - precision: 0.6427 - recall: 0.6151 - f1score: 0.6269 - val_loss: 0.6346 - val_acc: 0.6388 - val_precision: 0.6524 - val_recall: 0.5889 - val_f1score: 0.6168\n",
            "Epoch 35/100\n",
            "61797/61797 [==============================] - 6s 97us/step - loss: 0.6359 - acc: 0.6378 - precision: 0.6425 - recall: 0.6161 - f1score: 0.6275 - val_loss: 0.6343 - val_acc: 0.6393 - val_precision: 0.6489 - val_recall: 0.6030 - val_f1score: 0.6229\n",
            "Epoch 36/100\n",
            "61797/61797 [==============================] - 6s 102us/step - loss: 0.6360 - acc: 0.6372 - precision: 0.6428 - recall: 0.6119 - f1score: 0.6253 - val_loss: 0.6343 - val_acc: 0.6390 - val_precision: 0.6505 - val_recall: 0.5959 - val_f1score: 0.6199\n",
            "Epoch 37/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6355 - acc: 0.6394 - precision: 0.6450 - recall: 0.6162 - f1score: 0.6282 - val_loss: 0.6342 - val_acc: 0.6393 - val_precision: 0.6500 - val_recall: 0.5990 - val_f1score: 0.6213\n",
            "Epoch 38/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6355 - acc: 0.6378 - precision: 0.6417 - recall: 0.6181 - f1score: 0.6281 - val_loss: 0.6341 - val_acc: 0.6390 - val_precision: 0.6494 - val_recall: 0.5997 - val_f1score: 0.6214\n",
            "Epoch 39/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6357 - acc: 0.6385 - precision: 0.6439 - recall: 0.6151 - f1score: 0.6275 - val_loss: 0.6343 - val_acc: 0.6401 - val_precision: 0.6521 - val_recall: 0.5954 - val_f1score: 0.6203\n",
            "Epoch 40/100\n",
            "61797/61797 [==============================] - 6s 97us/step - loss: 0.6353 - acc: 0.6386 - precision: 0.6441 - recall: 0.6145 - f1score: 0.6273 - val_loss: 0.6342 - val_acc: 0.6396 - val_precision: 0.6501 - val_recall: 0.5995 - val_f1score: 0.6216\n",
            "Epoch 41/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6346 - acc: 0.6399 - precision: 0.6440 - recall: 0.6201 - f1score: 0.6303 - val_loss: 0.6341 - val_acc: 0.6403 - val_precision: 0.6511 - val_recall: 0.5992 - val_f1score: 0.6219\n",
            "Epoch 42/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6354 - acc: 0.6391 - precision: 0.6437 - recall: 0.6177 - f1score: 0.6288 - val_loss: 0.6340 - val_acc: 0.6404 - val_precision: 0.6506 - val_recall: 0.6013 - val_f1score: 0.6228\n",
            "Epoch 43/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6348 - acc: 0.6404 - precision: 0.6455 - recall: 0.6164 - f1score: 0.6292 - val_loss: 0.6340 - val_acc: 0.6403 - val_precision: 0.6502 - val_recall: 0.6018 - val_f1score: 0.6229\n",
            "Epoch 44/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6353 - acc: 0.6394 - precision: 0.6441 - recall: 0.6167 - f1score: 0.6285 - val_loss: 0.6339 - val_acc: 0.6411 - val_precision: 0.6508 - val_recall: 0.6041 - val_f1score: 0.6244\n",
            "Epoch 45/100\n",
            "61797/61797 [==============================] - 6s 97us/step - loss: 0.6349 - acc: 0.6384 - precision: 0.6433 - recall: 0.6174 - f1score: 0.6281 - val_loss: 0.6340 - val_acc: 0.6406 - val_precision: 0.6511 - val_recall: 0.6004 - val_f1score: 0.6226\n",
            "Epoch 46/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6346 - acc: 0.6406 - precision: 0.6455 - recall: 0.6176 - f1score: 0.6296 - val_loss: 0.6338 - val_acc: 0.6405 - val_precision: 0.6480 - val_recall: 0.6099 - val_f1score: 0.6262\n",
            "Epoch 47/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6344 - acc: 0.6401 - precision: 0.6451 - recall: 0.6177 - f1score: 0.6295 - val_loss: 0.6338 - val_acc: 0.6414 - val_precision: 0.6502 - val_recall: 0.6070 - val_f1score: 0.6257\n",
            "Epoch 48/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6346 - acc: 0.6400 - precision: 0.6442 - recall: 0.6195 - f1score: 0.6301 - val_loss: 0.6339 - val_acc: 0.6402 - val_precision: 0.6518 - val_recall: 0.5970 - val_f1score: 0.6210\n",
            "Epoch 49/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6339 - acc: 0.6403 - precision: 0.6448 - recall: 0.6191 - f1score: 0.6300 - val_loss: 0.6338 - val_acc: 0.6409 - val_precision: 0.6484 - val_recall: 0.6103 - val_f1score: 0.6266\n",
            "Epoch 50/100\n",
            "61797/61797 [==============================] - 6s 98us/step - loss: 0.6340 - acc: 0.6409 - precision: 0.6447 - recall: 0.6222 - f1score: 0.6317 - val_loss: 0.6337 - val_acc: 0.6411 - val_precision: 0.6499 - val_recall: 0.6060 - val_f1score: 0.6251\n",
            "Epoch 51/100\n",
            "61797/61797 [==============================] - 6s 98us/step - loss: 0.6337 - acc: 0.6412 - precision: 0.6444 - recall: 0.6244 - f1score: 0.6326 - val_loss: 0.6337 - val_acc: 0.6417 - val_precision: 0.6512 - val_recall: 0.6048 - val_f1score: 0.6250\n",
            "Epoch 52/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6342 - acc: 0.6413 - precision: 0.6450 - recall: 0.6233 - f1score: 0.6322 - val_loss: 0.6337 - val_acc: 0.6414 - val_precision: 0.6503 - val_recall: 0.6058 - val_f1score: 0.6251\n",
            "Epoch 53/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6336 - acc: 0.6399 - precision: 0.6441 - recall: 0.6196 - f1score: 0.6297 - val_loss: 0.6337 - val_acc: 0.6405 - val_precision: 0.6497 - val_recall: 0.6040 - val_f1score: 0.6238\n",
            "Epoch 54/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6340 - acc: 0.6405 - precision: 0.6454 - recall: 0.6205 - f1score: 0.6309 - val_loss: 0.6338 - val_acc: 0.6412 - val_precision: 0.6518 - val_recall: 0.6010 - val_f1score: 0.6232\n",
            "Epoch 55/100\n",
            "61797/61797 [==============================] - 6s 97us/step - loss: 0.6330 - acc: 0.6417 - precision: 0.6472 - recall: 0.6179 - f1score: 0.6306 - val_loss: 0.6337 - val_acc: 0.6410 - val_precision: 0.6489 - val_recall: 0.6092 - val_f1score: 0.6263\n",
            "Epoch 56/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6337 - acc: 0.6420 - precision: 0.6464 - recall: 0.6216 - f1score: 0.6321 - val_loss: 0.6336 - val_acc: 0.6405 - val_precision: 0.6473 - val_recall: 0.6114 - val_f1score: 0.6267\n",
            "Epoch 57/100\n",
            "61797/61797 [==============================] - 6s 98us/step - loss: 0.6336 - acc: 0.6416 - precision: 0.6459 - recall: 0.6221 - f1score: 0.6320 - val_loss: 0.6336 - val_acc: 0.6418 - val_precision: 0.6500 - val_recall: 0.6084 - val_f1score: 0.6264\n",
            "Epoch 58/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6339 - acc: 0.6404 - precision: 0.6447 - recall: 0.6212 - f1score: 0.6312 - val_loss: 0.6337 - val_acc: 0.6417 - val_precision: 0.6504 - val_recall: 0.6070 - val_f1score: 0.6258\n",
            "Epoch 59/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6347 - acc: 0.6400 - precision: 0.6450 - recall: 0.6189 - f1score: 0.6299 - val_loss: 0.6338 - val_acc: 0.6422 - val_precision: 0.6522 - val_recall: 0.6041 - val_f1score: 0.6250\n",
            "Epoch 60/100\n",
            "61797/61797 [==============================] - 6s 98us/step - loss: 0.6331 - acc: 0.6411 - precision: 0.6457 - recall: 0.6197 - f1score: 0.6308 - val_loss: 0.6337 - val_acc: 0.6417 - val_precision: 0.6511 - val_recall: 0.6050 - val_f1score: 0.6250\n",
            "Epoch 61/100\n",
            "61797/61797 [==============================] - 6s 99us/step - loss: 0.6334 - acc: 0.6409 - precision: 0.6449 - recall: 0.6219 - f1score: 0.6315 - val_loss: 0.6336 - val_acc: 0.6414 - val_precision: 0.6504 - val_recall: 0.6060 - val_f1score: 0.6253\n",
            "Epoch 62/100\n",
            "61797/61797 [==============================] - 7s 107us/step - loss: 0.6330 - acc: 0.6407 - precision: 0.6447 - recall: 0.6208 - f1score: 0.6309 - val_loss: 0.6336 - val_acc: 0.6419 - val_precision: 0.6494 - val_recall: 0.6114 - val_f1score: 0.6277\n",
            "Epoch 63/100\n",
            "61797/61797 [==============================] - 6s 103us/step - loss: 0.6324 - acc: 0.6418 - precision: 0.6471 - recall: 0.6200 - f1score: 0.6315 - val_loss: 0.6336 - val_acc: 0.6421 - val_precision: 0.6516 - val_recall: 0.6056 - val_f1score: 0.6256\n",
            "Epoch 64/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6325 - acc: 0.6414 - precision: 0.6458 - recall: 0.6206 - f1score: 0.6315 - val_loss: 0.6336 - val_acc: 0.6425 - val_precision: 0.6524 - val_recall: 0.6046 - val_f1score: 0.6254\n",
            "Epoch 65/100\n",
            "61797/61797 [==============================] - 6s 97us/step - loss: 0.6318 - acc: 0.6424 - precision: 0.6456 - recall: 0.6248 - f1score: 0.6334 - val_loss: 0.6334 - val_acc: 0.6413 - val_precision: 0.6474 - val_recall: 0.6149 - val_f1score: 0.6285\n",
            "Epoch 66/100\n",
            "61797/61797 [==============================] - 6s 102us/step - loss: 0.6330 - acc: 0.6397 - precision: 0.6444 - recall: 0.6171 - f1score: 0.6290 - val_loss: 0.6336 - val_acc: 0.6423 - val_precision: 0.6519 - val_recall: 0.6055 - val_f1score: 0.6257\n",
            "Epoch 67/100\n",
            "61797/61797 [==============================] - 6s 102us/step - loss: 0.6325 - acc: 0.6405 - precision: 0.6448 - recall: 0.6207 - f1score: 0.6309 - val_loss: 0.6336 - val_acc: 0.6419 - val_precision: 0.6513 - val_recall: 0.6043 - val_f1score: 0.6249\n",
            "Epoch 68/100\n",
            "61797/61797 [==============================] - 6s 102us/step - loss: 0.6320 - acc: 0.6420 - precision: 0.6461 - recall: 0.6228 - f1score: 0.6326 - val_loss: 0.6335 - val_acc: 0.6421 - val_precision: 0.6502 - val_recall: 0.6092 - val_f1score: 0.6269\n",
            "Epoch 69/100\n",
            "61797/61797 [==============================] - 6s 101us/step - loss: 0.6325 - acc: 0.6408 - precision: 0.6449 - recall: 0.6217 - f1score: 0.6314 - val_loss: 0.6335 - val_acc: 0.6421 - val_precision: 0.6510 - val_recall: 0.6063 - val_f1score: 0.6258\n",
            "Epoch 70/100\n",
            "61797/61797 [==============================] - 6s 100us/step - loss: 0.6315 - acc: 0.6413 - precision: 0.6455 - recall: 0.6214 - f1score: 0.6316 - val_loss: 0.6335 - val_acc: 0.6426 - val_precision: 0.6503 - val_recall: 0.6107 - val_f1score: 0.6278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSHDoGQ7mUz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "427d6e26-bb51-4e43-a7e1-68cd10e83c04"
      },
      "source": [
        "model_best = keras.models.load_model('best_model.h5', custom_objects={'precision': precision, 'recall':recall, 'f1score':f1score})\n",
        "\n",
        "score = model_best.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6353110674500169\n",
            "Test accuracy: 0.6406897265948633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKInc95vwjsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "5cb5f634-764c-4bd2-ac75-3bc0d2ab5d8b"
      },
      "source": [
        "pred_y_dl = model_best.predict(test_x)\n",
        "pred_y_dl = (pred_y_dl>0.5)\n",
        "print(\"Accuracy: {:.5f}\".format(accuracy_score(test_y, pred_y_dl)))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_y, pred_y_dl))\n",
        "print(\"Classification Report Matrix: \\n\", classification_report(test_y, pred_y_dl))\n",
        "\n",
        "roc_auc_dl1 = roc_auc_score(test_y, pred_y_dl)\n",
        "print(\"roc_auc score is : \", roc_auc_dl1)\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(test_y, pred_y_dl)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "auc_graph(roc_auc, fpr, tpr)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.64069\n",
            "Confusion Matrix: \n",
            " [[6434 3198]\n",
            " [3741 5939]]\n",
            "Classification Report Matrix: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.67      0.65      9632\n",
            "         1.0       0.65      0.61      0.63      9680\n",
            "\n",
            "    accuracy                           0.64     19312\n",
            "   macro avg       0.64      0.64      0.64     19312\n",
            "weighted avg       0.64      0.64      0.64     19312\n",
            "\n",
            "roc_auc score is :  [[ True]\n",
            " [False]\n",
            " [ True]\n",
            " ...\n",
            " [ True]\n",
            " [False]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4mkzKfqTFE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "a6cac88c-ec64-4040-f3a9-c6551558c95c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAEMCAYAAABZU8juAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyQmCIAjt1v8H59a/+IjrWS4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDqc08606kkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}