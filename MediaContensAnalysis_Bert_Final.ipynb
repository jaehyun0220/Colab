{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MediaContensAnalysis_Bert_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65a35ef082d84df1ace7b555acdd44de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a4d70d7a1424d789b59e9d2d8b6eff1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f07d22ddfd84ba08bcd43e64067734a",
              "IPY_MODEL_72ec37f65eff40b4837e18b04d3a1a86"
            ]
          }
        },
        "6a4d70d7a1424d789b59e9d2d8b6eff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f07d22ddfd84ba08bcd43e64067734a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04a3c7cf318a4dcfa5bb34624da4a60f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d66eeee0c0054840958dfe900a16ae3e"
          }
        },
        "72ec37f65eff40b4837e18b04d3a1a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_594dde5a4eec45b7b8f28c6848862459",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 28/28 [00:11&lt;00:00,  3.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa8e4780fb03498492304cfedbfd4708"
          }
        },
        "04a3c7cf318a4dcfa5bb34624da4a60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d66eeee0c0054840958dfe900a16ae3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "594dde5a4eec45b7b8f28c6848862459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa8e4780fb03498492304cfedbfd4708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b82a891d294841d690c77cf7b51fcd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08495f42901a4386a20d52aa4057573a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56229042bca84cf9901b32436aae5837",
              "IPY_MODEL_d1249ec65e534447bdba6127fb08bdbc"
            ]
          }
        },
        "08495f42901a4386a20d52aa4057573a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56229042bca84cf9901b32436aae5837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55c752164113442ba9abed1057db88c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7a3532638f8495b8ebae847f17c5bfe"
          }
        },
        "d1249ec65e534447bdba6127fb08bdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62acd621f90e4676b7b4a21ceb17f8bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 3/3 [10:41&lt;00:00, 213.79s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e152d484afe44446987a24d70499c01d"
          }
        },
        "55c752164113442ba9abed1057db88c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7a3532638f8495b8ebae847f17c5bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62acd621f90e4676b7b4a21ceb17f8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e152d484afe44446987a24d70499c01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfdf6753bfd74d70a740c5995de4af2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d0113fa52cc47ca81286ca27c58b683",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0afef0a4b29345459f671331e73fbb63",
              "IPY_MODEL_f8b1fe1b0f1b46d8856ba3249c25d5c6"
            ]
          }
        },
        "0d0113fa52cc47ca81286ca27c58b683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0afef0a4b29345459f671331e73fbb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c049c831dcb54a9ca25bffd5957e279b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 510,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 510,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6115c6c0d054bd1af7a3bfb3ff36c44"
          }
        },
        "f8b1fe1b0f1b46d8856ba3249c25d5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63db040923b54db486b703fa075246d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 510/510 [03:33&lt;00:00,  2.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a8cf3932ce744b38ac02174eef73b22"
          }
        },
        "c049c831dcb54a9ca25bffd5957e279b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6115c6c0d054bd1af7a3bfb3ff36c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63db040923b54db486b703fa075246d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a8cf3932ce744b38ac02174eef73b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f68b0068e972454eb9a55e5a895c5d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e11587f39a34997b4a8f38f28c90d8c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9780320b8e7a46c5a952b0e31dc1933f",
              "IPY_MODEL_c4683b9fdd9f45b3b38f9a47165ec97d"
            ]
          }
        },
        "4e11587f39a34997b4a8f38f28c90d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9780320b8e7a46c5a952b0e31dc1933f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_213f8800c81a42a3a236a81b61b1e6dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 510,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 510,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3663a8d901ac4f0095df857665be0f37"
          }
        },
        "c4683b9fdd9f45b3b38f9a47165ec97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4faae460a0b940d4871457f4fbb152ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 510/510 [03:33&lt;00:00,  2.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9174ddcefbc041c883e6617024c21082"
          }
        },
        "213f8800c81a42a3a236a81b61b1e6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3663a8d901ac4f0095df857665be0f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4faae460a0b940d4871457f4fbb152ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9174ddcefbc041c883e6617024c21082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8958302985d640d889664d3ebcf49954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a56d0923d4a4998a55280ce1768f1be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be33d2720c134dc98ef5294ea48da272",
              "IPY_MODEL_d60343f878b447eaa669cf4f012d1108"
            ]
          }
        },
        "6a56d0923d4a4998a55280ce1768f1be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be33d2720c134dc98ef5294ea48da272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd94700162fe4bf6acf01efeb180839a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 510,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 510,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72c8ca62ee794faa835f87fe5ea65f99"
          }
        },
        "d60343f878b447eaa669cf4f012d1108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f18d4e297cd140ea872f229bee96ae7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 510/510 [03:33&lt;00:00,  2.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47f170c70a164ffb95268e8de656af09"
          }
        },
        "cd94700162fe4bf6acf01efeb180839a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72c8ca62ee794faa835f87fe5ea65f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f18d4e297cd140ea872f229bee96ae7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47f170c70a164ffb95268e8de656af09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun0220/Colab/blob/master/MediaContensAnalysis_Bert_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmdavC_fLDrU",
        "colab_type": "text"
      },
      "source": [
        "#10조. 네이버 댓글 분석을 통한 상위, 하위 클립 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcnHnotA2oRX",
        "colab_type": "text"
      },
      "source": [
        "### #1. 구글 인증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnLbyZflC1R1",
        "colab_type": "code",
        "outputId": "a134938e-0f9f-4fa3-812b-c48300836a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Auth 인증 및 Google Drive 활용 Data load\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNICcJFm2hm7",
        "colab_type": "text"
      },
      "source": [
        "### #2. 입력 데이터셋 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5oQGfjLC-Jb",
        "colab_type": "code",
        "outputId": "e46a8bf8-3779-4c8b-9f79-b0553a129683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!ls ../gdrive/My\\ Drive/output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_ep10.csv\t file_ep16.csv\tfile_ep22.csv  file_ep4.csv\n",
            "file_ep11.csv\t file_ep17.csv\tfile_ep23.csv  file_ep5.csv\n",
            "file_ep12.csv\t file_ep18.csv\tfile_ep24.csv  file_ep6.csv\n",
            "file_ep13.csv\t file_ep19.csv\tfile_ep25.csv  file_ep7.csv\n",
            "file_ep14_1.csv  file_ep1.csv\tfile_ep26.csv  file_ep8.csv\n",
            "file_ep14.csv\t file_ep20.csv\tfile_ep2.csv   file_ep9.csv\n",
            "file_ep15.csv\t file_ep21.csv\tfile_ep3.csv   TheLastEmpress.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bdQCRGv7AX6",
        "colab_type": "code",
        "outputId": "d7f5ae03-7c95-483c-de01-7a14b30c2d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "!pip install regex\n",
        "# Okt, Kkma 등의 형태소 분석기 활용을 위한 설치\n",
        "# !pip install konlpy\n",
        "# Bert 사용을 위한 설치\n",
        "!pip install sacremoses sentencepiece "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609173 sha256=fb90561bfc3d30bc3ccae16ad2561029f67ea5921b391910bbd7126758791482\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
            "Successfully built regex\n",
            "Installing collected packages: regex\n",
            "Successfully installed regex-2019.12.9\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 2.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.28.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=2489c01b058418cee7f0bc6fa6638d1335e74c193fb7fbe9f237464e7d86af3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece\n",
            "Successfully installed sacremoses-0.0.35 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEGh8u0qDI6h",
        "colab_type": "code",
        "outputId": "0821779c-f0e1-4d5f-9f7d-5987bdd4f50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "# 기본 라이브러리 로드\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import regex as re\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm_notebook, trange\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터 전처리 관련 라이브러리 로드\n",
        "from sklearn import preprocessing\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "#모델 평가를 위한 라이브러리 로드\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\n",
        "\n",
        "#데이터 분리를 위한 라이브러리 로드\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#수학 & 통계 관련 라이브러리 로드\n",
        "import scipy.stats as st\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl  # 기본 설정 만지는 용도\n",
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도\n",
        "\n",
        "\n",
        "#Configure Visualization Defaults\n",
        "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
        "%matplotlib inline\n",
        "mpl.style.use('ggplot')\n",
        "sns.set_style('white')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Ink4z2DVoG",
        "colab_type": "code",
        "outputId": "a28af90b-171a-4616-cdc9-ddcb679cf528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469,
          "referenced_widgets": [
            "65a35ef082d84df1ace7b555acdd44de",
            "6a4d70d7a1424d789b59e9d2d8b6eff1",
            "5f07d22ddfd84ba08bcd43e64067734a",
            "72ec37f65eff40b4837e18b04d3a1a86",
            "04a3c7cf318a4dcfa5bb34624da4a60f",
            "d66eeee0c0054840958dfe900a16ae3e",
            "594dde5a4eec45b7b8f28c6848862459",
            "fa8e4780fb03498492304cfedbfd4708"
          ]
        }
      },
      "source": [
        "# 입력으로 활용할 데이터셋 List 확인\n",
        "filelist = os.listdir('../gdrive/My Drive/output')\n",
        "\n",
        "# 총 26회차 491개 하이라이트 클립 존재 (전체 재생수 = 107,221,654 / 클립 당 평균 재생수 = 218,374), \n",
        "# 이 중에서 예고편, 미공개, 인터뷰 등 클립 제외하고 총 422회 클립 대상\n",
        "df_title = pd.read_csv('../gdrive/My Drive/output/TheLastEmpress.csv', encoding = 'euc-kr')\n",
        "df_title.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "\n",
        "# 조회수 분포를 고려하여 각 회차별로 조회수 상위 4개, 하위 4개 클립을 샘플링 - 총 208개 클립\n",
        "# 좋아요수, 댓글 수, 댓글 내용, 댓글 작성자 정보 (웹크롤링 통한 추출)\n",
        "\n",
        "df_ep_tot = pd.DataFrame()\n",
        "\n",
        "# 상위 하위 클립을 나누어 조회수 내림차순으로 rank를 매김 (1~4는 상위 클립, 5~8은 하위 클립)\n",
        "for i in tqdm_notebook(filelist):\n",
        "  if (i[:4] == 'file'):\n",
        "    df_ep_temp = pd.read_csv('../gdrive/My Drive/output/'+i)\n",
        "    df_ep_temp['play'] = df_ep_temp['play'].apply(lambda x: int(re.sub(',','', x[4:])))\n",
        "    df_ep_temp['rank'] = df_ep_temp['play'].rank(method='dense', ascending=False)\n",
        "    df_ep_tot = df_ep_tot.append(df_ep_temp)\n",
        "\n",
        "# 크롤링 한 데이터에서 불필요한 열 삭제\n",
        "df_ep_tot.drop(columns='Unnamed: 0', inplace=True)\n",
        "\n",
        "# 상위 클립은 1로 하위 클립은 0으로 분류\n",
        "df_ep_tot['target'] = np.where(df_ep_tot['rank']<=4,1,0)\n",
        "df_ep_tot"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65a35ef082d84df1ace7b555acdd44de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nick</th>\n",
              "      <th>contents</th>\n",
              "      <th>recomm</th>\n",
              "      <th>unrecomm</th>\n",
              "      <th>title</th>\n",
              "      <th>play</th>\n",
              "      <th>like</th>\n",
              "      <th>reple_count</th>\n",
              "      <th>episode</th>\n",
              "      <th>rank</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rosi****</td>\n",
              "      <td>ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>핑크에메랄드</td>\n",
              "      <td>왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>서지안</td>\n",
              "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>경</td>\n",
              "      <td>ㅏ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홍홍</td>\n",
              "      <td>이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>Major</td>\n",
              "      <td>와 ㅅㅂ...피지컬봐....</td>\n",
              "      <td>550</td>\n",
              "      <td>1</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842</th>\n",
              "      <td>스폰지밥</td>\n",
              "      <td>이쁘십니다 할때 나만설렜냐,,,,,,,</td>\n",
              "      <td>691</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1843</th>\n",
              "      <td>박한별</td>\n",
              "      <td>반했네</td>\n",
              "      <td>372</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1844</th>\n",
              "      <td>김민정</td>\n",
              "      <td>죄송하지만 이 분 이용합시다 ! 어쨌든 좋은게 좋은거죠 ..</td>\n",
              "      <td>593</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>블링블링</td>\n",
              "      <td>우빈이한테 전부 들이대는군</td>\n",
              "      <td>338</td>\n",
              "      <td>3</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40935 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          nick                                           contents  ...  rank  target\n",
              "0     rosi****  ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...  ...   1.0       1\n",
              "1       핑크에메랄드  왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...  ...   1.0       1\n",
              "2          서지안                                           ㅋㅋㅋㅋㅋㅋㅋㅋ  ...   1.0       1\n",
              "3            경                                                  ㅏ  ...   1.0       1\n",
              "4           홍홍            이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발  ...   1.0       1\n",
              "...        ...                                                ...  ...   ...     ...\n",
              "1841     Major                                    와 ㅅㅂ...피지컬봐....  ...   8.0       0\n",
              "1842      스폰지밥                              이쁘십니다 할때 나만설렜냐,,,,,,,  ...   8.0       0\n",
              "1843       박한별                                                반했네  ...   8.0       0\n",
              "1844       김민정                  죄송하지만 이 분 이용합시다 ! 어쨌든 좋은게 좋은거죠 ..  ...   8.0       0\n",
              "1845      블링블링                                     우빈이한테 전부 들이대는군  ...   8.0       0\n",
              "\n",
              "[40935 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MxLLtPX7gN",
        "colab_type": "text"
      },
      "source": [
        "### #3. 데이터 정제 - 댓글 중 분석 대상이 되는 contens 내 null data 삭제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cA7gB0gV3HF",
        "colab_type": "code",
        "outputId": "019d182c-2667-4cba-84db-21d3642a0452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df_ep_sample = df_ep_tot.copy()\n",
        "df_ep_sample.dropna(how='any', inplace=True)\n",
        "df_ep_sample.info()\n",
        "df_ep_sample['target'].value_counts() # 3:1 imbalanced dataset (조회수가 많은 클립에 댓글이 많기 때문임))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 40801 entries, 0 to 1845\n",
            "Data columns (total 11 columns):\n",
            "nick           40801 non-null object\n",
            "contents       40801 non-null object\n",
            "recomm         40801 non-null int64\n",
            "unrecomm       40801 non-null int64\n",
            "title          40801 non-null object\n",
            "play           40801 non-null int64\n",
            "like           40801 non-null object\n",
            "reple_count    40801 non-null object\n",
            "episode        40801 non-null int64\n",
            "rank           40801 non-null float64\n",
            "target         40801 non-null int64\n",
            "dtypes: float64(1), int64(5), object(5)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    30632\n",
              "0    10169\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbDda80F4Spl",
        "colab_type": "text"
      },
      "source": [
        "### #4. 데이터 길이 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qHvTttUYJQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import konlpy\n",
        "# from konlpy.tag import Kkma\n",
        "# from konlpy.utils import pprint\n",
        "\n",
        "# kkma = Kkma()\n",
        "\n",
        "# def morphs_kkma(x):\n",
        "#   res = kkma.morphs(x)\n",
        "#   if len(res) >= 1:\n",
        "#     res = [re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) for i in range(len(res)) if re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) != '' and len(res[i]) >= 1]\n",
        "#   else:\n",
        "#     res = ''\n",
        "#   res = '' if not res else res\n",
        "#   return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1xNEIOX4bxo",
        "colab_type": "text"
      },
      "source": [
        "#### #4-1. 데이터 정제 - 정규식 & 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyG91a40YN8M",
        "colab_type": "code",
        "outputId": "f3d87f88-8847-444a-9107-2d6a868205d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df_ep_sample['contents'] = df_ep_sample['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "df_ep_sample.dropna(how='any', inplace=True)\n",
        "# df_sample_final = df_ep_sample.sample(frac=1).copy()\n",
        "df_sample_final = pd.concat([df_ep_sample[df_ep_sample['target']==1].sample(n=10000), df_ep_sample[df_ep_sample['target']==0].sample(n=10000)])\n",
        "df_sample_final.sample(frac=1).reset_index(drop=True)\n",
        "df_sample_final['target'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    10000\n",
              "0    10000\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyS88sBUT_Tk",
        "colab_type": "text"
      },
      "source": [
        "## 공통 영역: Word Embedding을 위한 Hyper parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT_z_0uNV8fp",
        "colab_type": "code",
        "outputId": "58e9b196-4d1d-46b9-92c8-7811f015abe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Hyper Param setting\n",
        "\n",
        "# token의 Histogram 분포를 바탕으로 대부분의 단어 길이 cover 가능한 단어 개수 찾기\n",
        "# # 신경망 학습을 위한 input 벡터 길이로 사용 - 적정 길이는 tokenizng 이후 분포를 보고 결정(코드 하단)\n",
        "# totalLenSent = [len(x) for x in df_ep_sample['kkma_token']] # 각 document의 단어 길이를 check\n",
        "# plt.hist(totalLenSent,bins = np.arange(0,max(totalLenSent),max(totalLenSent)/20))\n",
        "\n",
        "# print(np.percentile(totalLenSent, 95)) # 95%를 커버하는 수치는 41\n",
        "\n",
        "# MAX_LEN = int(np.percentile(totalLenSent, 95)) but bert는 128 embedding 사용\n",
        "MAX_LEN = 64\n",
        "print(MAX_LEN)\n",
        "\n",
        "# pre-trained Embedding을 몇 개 사용할 지 결정\n",
        "# NUM_MODELS = 1\n",
        "\n",
        "# # input data 원문에서 보존할 최대 단어 개수 \n",
        "# # 전체 데이터셋에서 나타나는 unique 한 단어 수(넉넉하게 백단위 올림하여 setting)\n",
        "# from itertools import chain\n",
        "\n",
        "# sum_lists = list(chain.from_iterable(df_ep_sample['okt_token']))\n",
        "# totalCntWords = int(math.ceil(len(set(sum_lists))/100)*100)\n",
        "\n",
        "# MAX_FEATURES = 37000\n",
        "# MAX_FEATURES = totalCntWords\n",
        "# print(len(set(sum_lists)), MAX_FEATURES)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj1Ha87bTXIE",
        "colab_type": "code",
        "outputId": "728de0de-5c66-40c1-e876-63b15a69f6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Bert 친화 형식으로 변경\n",
        "\n",
        "all_df_bert = pd.DataFrame({\n",
        "    'id':range(len(df_sample_final)),\n",
        "    'label':df_sample_final['target'],\n",
        "    'alpha':['a']*df_sample_final.shape[0],\n",
        "    'text': df_sample_final['contents'].replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "display(all_df_bert.head())\n",
        "\n",
        "# train_df_bert = pd.DataFrame({\n",
        "#     'id':range(len(train_df)),\n",
        "#     'label':train_df['target'],\n",
        "#     'alpha':['a']*train_df.shape[0],\n",
        "#     'text': train_df['contents'].replace(r'\\n', ' ', regex=True)\n",
        "# })\n",
        "\n",
        "# display(train_df_bert.head())\n",
        "\n",
        "# dev_df_bert = pd.DataFrame({\n",
        "#     'id':range(len(test_df)),\n",
        "#     'label':test_df['target'],\n",
        "#     'alpha':['a']*test_df.shape[0],\n",
        "#     'text': test_df['contents'].replace(r'\\n', ' ', regex=True)\n",
        "# })\n",
        "\n",
        "# display(dev_df_bert.head())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>에후</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>황후랑 안되는걸 알면서도 지켜준다는거네 보면볼수록 짠하다 이혁  ㅜㅜ 이혁도 행복했으면</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>아역인데 연기변화 보소 초반에 홍시홍시 했는데 아리캐릭 확실해서 홍시가 생각이 안나</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>빠른대처감사해요</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  label alpha                                              text\n",
              "688    0      1     a                                                  \n",
              "1290   1      1     a                                                에후\n",
              "1261   2      1     a  황후랑 안되는걸 알면서도 지켜준다는거네 보면볼수록 짠하다 이혁  ㅜㅜ 이혁도 행복했으면\n",
              "616    3      1     a    아역인데 연기변화 보소 초반에 홍시홍시 했는데 아리캐릭 확실해서 홍시가 생각이 안나\n",
              "1818   4      1     a                                          빠른대처감사해요"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhuYsAsyTcMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_df_bert.to_csv('../gdrive/My Drive/data/bert/all.tsv', sep='\\t', index=False, header=False)\n",
        "# train_df_bert.to_csv('../gdrive/My Drive/data/bert/train.tsv', sep='\\t', index=False, header=False)\n",
        "# dev_df_bert.to_csv('../gdrive/My Drive/data/bert/test.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwIUNatxUKw0",
        "colab_type": "text"
      },
      "source": [
        "## Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmeQZzzfTxFH",
        "colab_type": "text"
      },
      "source": [
        "### 데이터를 불러와 Tokenizing 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hebZp9cZTmcv",
        "colab_type": "code",
        "outputId": "63ce03f6-f5f6-463f-9820-d288e76310b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "# Create sentence and label lists\n",
        "df_all = pd.read_csv(\"../gdrive/My Drive/data/bert/all.tsv\", delimiter='\\t', header=None, names = ['id', 'label', 'alpha', 'text'])\n",
        "print(df_all.shape)\n",
        "df_all.sample(5)\n",
        "# df_train = pd.read_csv(\"../gdrive/My Drive/data/bert/train.tsv\", delimiter='\\t', header=None, names = ['id', 'label', 'alpha', 'text'])\n",
        "# df_test = pd.read_csv(\"../gdrive/My Drive/data/bert/test.tsv\", delimiter='\\t', header=None, names = ['id', 'label', 'alpha', 'text'])\n",
        "# print(df_train.shape, df_test.shape)\n",
        "# df_train.sample(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14247</th>\n",
              "      <td>14247</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>그래 찰떡같이 붙어있으란 말야 ㅋㅋㅋ 늘 화원갈때마다 불안함</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>886</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>신박한 막장 저녁 드라마의 장을 열것 같네요 ㅎㅎㅎ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11230</th>\n",
              "      <td>11230</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>이혁최고야</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>823</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>나는 삐뚤어진 집착을 제대로 보여준거 같아서 좋게 봤는데 억지로라도 옆에 꼭 두고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4319</th>\n",
              "      <td>4319</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>아 그냥 소진공주랑 천우빈이랑 이어지게 해달라구요</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  label alpha                                               text\n",
              "14247  14247      0     a                  그래 찰떡같이 붙어있으란 말야 ㅋㅋㅋ 늘 화원갈때마다 불안함\n",
              "886      886      1     a                       신박한 막장 저녁 드라마의 장을 열것 같네요 ㅎㅎㅎ\n",
              "11230  11230      0     a                                              이혁최고야\n",
              "823      823      1     a  나는 삐뚤어진 집착을 제대로 보여준거 같아서 좋게 봤는데 억지로라도 옆에 꼭 두고 ...\n",
              "4319    4319      1     a                        아 그냥 소진공주랑 천우빈이랑 이어지게 해달라구요"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcQH9CZ3Ts_-",
        "colab_type": "code",
        "outputId": "62958bc5-77b3-4bdd-aa60-9f01e0ca6576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentences = df_all.text.values\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "labels = df_all.label.values\n",
        "len(sentences)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-xt5s3WE7P_O"
      },
      "source": [
        "### Pytorch 환경 내에서 BERT를 사용하기 위한 BERT 관련 Library Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dJuak78KBqh",
        "colab_type": "code",
        "outputId": "a34822a3-6388-410e-802c-aa735d0b9442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
            "\r\u001b[K     |█                               | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1O_Gd40m7P_U",
        "colab": {}
      },
      "source": [
        "import sacremoses\n",
        "import sentencepiece\n",
        "\n",
        "import pickle\n",
        "import shutil\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn # for neural net\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # jupyter에서 마지막 값만 출력하는게 아니라 모든 출력값을 매번 연속적으로 출력\n",
        "InteractiveShell.ast_node_interactivity = \"all\" # all, last, last_expr, none (기본값은 'last_expr')\n",
        "\n",
        "# from transformers import convert_tf_checkpoint_to_pytorch\n",
        "from transformers import convert_bert_original_tf_checkpoint_to_pytorch\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, BertModel, BertPreTrainedModel, BertConfig\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "\n",
        "from transformers import BertConfig # This is the Bert configuration file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2CnZbkMT3-5",
        "colab_type": "code",
        "outputId": "f7cc9fbb-13ba-4f9f-86d3-90fa7ec4e7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuE9j3fXVgry",
        "colab_type": "text"
      },
      "source": [
        "### Bert 학습을 위한 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJOgiUFK7P_T",
        "colab": {}
      },
      "source": [
        "!mkdir ./bert_work/\n",
        "PATH_PRETRAINED = \"../gdrive/My Drive/data/bert/multi_cased_L-12_H-768_A-12/\"\n",
        "PATH_TORCH_PRETRAINED = \"../gdrive/My Drive/data/bert/bert-base-multilingual-cased/\"\n",
        "PATH_WORK = './bert_work/'\n",
        "sys.path.append(PATH_PRETRAINED)\n",
        "sys.path.append(PATH_WORK)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO5H1ezGVpqy",
        "colab_type": "text"
      },
      "source": [
        "### Bert 학습을 위한 pretrained model을 pytorch 형태로 변환하여 work 경로로 복사"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zchSpZM97tdM",
        "colab_type": "code",
        "outputId": "66365866-5c4e-4ed2-ef32-6187826e1104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# convert_bert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
        "#     PATH_PRETRAINED + 'bert_model.ckpt',\n",
        "#     PATH_PRETRAINED + 'bert_config.json',\n",
        "#     PATH_TORCH_PRETRAINED + 'pytorch_model.bin')\n",
        "\n",
        "# # 읽어온 BERT_MODEL_PATH bert_config.json file의 설정을 PATH_TORCH_PRETRAINED에 쓰고 복사 후 PATH_WORK의 bert_config.json이라는 이름으로 저장\n",
        "# shutil.copyfile(PATH_PRETRAINED + 'bert_config.json', PATH_TORCH_PRETRAINED + 'config.json')\n",
        "# shutil.copyfile(PATH_TORCH_PRETRAINED + 'config.json', PATH_WORK + 'config.json')\n",
        "# shutil.copyfile(PATH_TORCH_PRETRAINED + 'pytorch_model.bin', PATH_WORK + 'pytorch_model.bin')\n",
        "# # 읽어온 BERT_MODEL_PATH vocab.txt file의 설정을 그대로 PATH_WORK의 vocab.txt라는 이름으로 저장\n",
        "# shutil.copyfile(PATH_PRETRAINED + 'vocab.txt', PATH_TORCH_PRETRAINED + 'vocab.txt')\n",
        "# shutil.copyfile(PATH_TORCH_PRETRAINED + 'vocab.txt', PATH_WORK + 'vocab.txt')\n",
        "\n",
        "# 상기 내용 1회 시행 이후는 그냥 PATH_PRETRAINED의 변환 된 파일들을 PATH_WORK로만 복사\n",
        "shutil.copyfile(PATH_TORCH_PRETRAINED + 'config.json', PATH_WORK + 'config.json')\n",
        "shutil.copyfile(PATH_TORCH_PRETRAINED + 'pytorch_model.bin', PATH_WORK + 'pytorch_model.bin')\n",
        "shutil.copyfile(PATH_TORCH_PRETRAINED + 'vocab.txt', PATH_WORK + 'vocab.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./bert_work/config.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k_BWb1wy7d9y"
      },
      "source": [
        "### BERT 사용 관련 Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngE4dova7d91",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "MAX_SEQ_LEN = MAX_LEN # token분포 바탕으로 128 선정 (대부분의 단어 길이 cover)\n",
        "\n",
        "NUM_LABELS = len(df_sample_final['target'].unique()) #2 If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy)\n",
        "training_epochs = 3\n",
        "lr = 2e-5\n",
        "batch_size = 64\n",
        "\n",
        "FILE_VOCAB = PATH_WORK+'vocab.txt'\n",
        "bert_model_config = PATH_WORK+'config.json'\n",
        "\n",
        "bert_model = 'bert-base-multilingual-cased'\n",
        "do_lower_case = 'uncased' in bert_model\n",
        "device = torch.device('cuda') # GPU 사용 setting\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGQSs3C29ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=do_lower_case)\n",
        "# ['니', '##는', '[UNK]', '황', '##후', '##는', '이', '##짓', '##하면', '##안', '##돼', '##냐', '진', '##실을', '말', '##한', '##것', '뿐', '##인', '##데']\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(os.path.join(PATH_WORK, 'vocab.txt'), cache_dir=None, do_lower_case=do_lower_case, do_basic_tokenize=False)\n",
        "# ['니', '##는', '[UNK]', '황', '##후', '##는', '이', '##짓', '##하면', '##안', '##돼', '##냐', '진', '##실을', '말', '##한', '##것', '뿐', '##인', '##데']\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(FILE_VOCAB, cache_dir=None, do_lower_case=do_lower_case)\n",
        "\n",
        "for i in range(0, len(sentences), 2000):\n",
        "  sentence = sentences[i:(i+2000)] \n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentence]\n",
        "  \n",
        "  # 2000번에 한개씩 결과 출ㄹ력 \n",
        "  if (i % 2000) == 0:\n",
        "    print(tokenized_texts)\n",
        "    \n",
        "  input_ids_tmp = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids_tmp = pad_sequences(input_ids_tmp, maxlen=MAX_LEN, dtype=\"long\", truncating='post', padding='post')\n",
        "  if i==0:\n",
        "    input_ids = input_ids_tmp\n",
        "    print(i)\n",
        "  else:\n",
        "    input_ids = np.vstack((input_ids, input_ids_tmp))\n",
        "    print(i, '완료', input_ids.shape, input_ids_tmp.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZVcfVqNYdk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('wordpiece_tokenize_128.npy', input_ids)\n",
        "input_ids = np.load('wordpiece_tokenize_128.npy')\n",
        "print(input_ids.shape)\n",
        "input_ids[:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiiWnV-UYlxA",
        "colab_type": "text"
      },
      "source": [
        "## 분류에 사용할 클래스 Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uaF3knUfY_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = input_ids\n",
        "Y = labels\n",
        "\n",
        "# Train & Test Set 분리\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SndvcbAGY7Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DZFwNyQ1Q0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset을 상속한 TensorDataset은 train data x와 레이블 y를 묶어놓은 컨테이너로 tensor만 전달 가능함\n",
        "# X는 torch.long 형태의 텐서로, y는 torch.float 타입의 텐서로 입력하여 pytorch에서 연산할 수 있는 기본 구조로 변경하여 train_dataset으로 할당\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_x,dtype=torch.long), torch.tensor(train_y,dtype=torch.long))\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_x,dtype=torch.long), torch.tensor(test_y,dtype=torch.long))\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2--Gr8kLFyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "\n",
        "# Train 함수\n",
        "def bert_train_net(net, train_loader, optimizer, device=\"cuda\"):\n",
        "  tq = tqdm_notebook(range(training_epochs))\n",
        "\n",
        "  for epoch in tq:\n",
        "    tr_loss = 0.\n",
        "    nb_tr_examples, nb_tr_steps = 0,0\n",
        "\n",
        "    # 신경망을 훈련 모드로 설정\n",
        "    net.train()\n",
        "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
        "    \n",
        "    # iteration 1회에 train_loader의 batch_size (여기서는 64)만큼씩 읽어와 한꺼번에 batch처리 batch_size * i (여기서는 i = ) 가 전체 train data set의 크기가 될때까지 loop\n",
        "    for i,(x, y) in tk0:\n",
        "      x=x.to(device) # len(x)는 batch_size\n",
        "      y=y.to(device)\n",
        "\n",
        "      loss, logit = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=y)  # forward\n",
        "\n",
        "      optimizer.zero_grad() # step과 zero_grad는 쌍을 이루는 것이라고 생각하면 됨 # optimizer의 gradient를 0으로 초기화\n",
        "      \n",
        "      if (i%200) == 0:\n",
        "        print(\"loss ... \", loss, type(loss))\n",
        "        print(\"logit ... \", logit, type(logit))\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "      loss.backward() # backpropagation\n",
        "      optimizer.step() # update gradients\n",
        "\n",
        "      # update tracking variables\n",
        "      tr_loss += loss.item()\n",
        "      nb_tr_examples += x.size(0)\n",
        "      nb_tr_steps += 1\n",
        "      # running_loss += loss.item() # loss calculate\n",
        "\n",
        "      train_losses.append(tr_loss/nb_tr_steps)\n",
        "\n",
        "    print(\"epoch: {}/{} | train_loss: {:.4f} \".format(epoch, training_epochs, tr_loss/nb_tr_steps))\n",
        "    # train_losses.append(running_loss/len(train_loader))\n",
        "    # torch.save(model.state_dict(), output_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCFAzJb6ZUwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls ./bert_work"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMkB5nm7GoA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BertForSequenceClassification is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. \n",
        "# As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "\n",
        "CACHE_DIR = 'cache/'\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(bert_model, cache_dir=CACHE_DIR, num_labels=NUM_LABELS)\n",
        "# model = BertForSequenceClassification.from_pretrained(CACHE_DIR + 'cased_base_bert_pytorch.tar.gz', cache_dir=CACHE_DIR, num_labels=num_labels)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "### In Transformers, optimizer and schedules are splitted and instantiated like this:\n",
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilfBP85R8hME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls ../gdrive/My\\ Drive/data/bert/huggingface"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twe-4xUHvIwk",
        "colab_type": "code",
        "outputId": "877ebbe8-8ba7-4969-d124-88be932fb00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b82a891d294841d690c77cf7b51fcd58",
            "08495f42901a4386a20d52aa4057573a",
            "56229042bca84cf9901b32436aae5837",
            "d1249ec65e534447bdba6127fb08bdbc",
            "55c752164113442ba9abed1057db88c1",
            "a7a3532638f8495b8ebae847f17c5bfe",
            "62acd621f90e4676b7b4a21ceb17f8bf",
            "e152d484afe44446987a24d70499c01d",
            "cfdf6753bfd74d70a740c5995de4af2c",
            "0d0113fa52cc47ca81286ca27c58b683",
            "0afef0a4b29345459f671331e73fbb63",
            "f8b1fe1b0f1b46d8856ba3249c25d5c6",
            "c049c831dcb54a9ca25bffd5957e279b",
            "e6115c6c0d054bd1af7a3bfb3ff36c44",
            "63db040923b54db486b703fa075246d3",
            "2a8cf3932ce744b38ac02174eef73b22",
            "f68b0068e972454eb9a55e5a895c5d14",
            "4e11587f39a34997b4a8f38f28c90d8c",
            "9780320b8e7a46c5a952b0e31dc1933f",
            "c4683b9fdd9f45b3b38f9a47165ec97d",
            "213f8800c81a42a3a236a81b61b1e6dc",
            "3663a8d901ac4f0095df857665be0f37",
            "4faae460a0b940d4871457f4fbb152ea",
            "9174ddcefbc041c883e6617024c21082",
            "8958302985d640d889664d3ebcf49954",
            "6a56d0923d4a4998a55280ce1768f1be",
            "be33d2720c134dc98ef5294ea48da272",
            "d60343f878b447eaa669cf4f012d1108",
            "cd94700162fe4bf6acf01efeb180839a",
            "72c8ca62ee794faa835f87fe5ea65f99",
            "f18d4e297cd140ea872f229bee96ae7c",
            "47f170c70a164ffb95268e8de656af09"
          ]
        }
      },
      "source": [
        "model.to(device) # GPU 연산을 위해 cuda로 전송\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "bert_train_net(model, train_loader, optimizer, device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b82a891d294841d690c77cf7b51fcd58",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfdf6753bfd74d70a740c5995de4af2c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=510), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "loss ...  tensor(0.7124, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[ 0.0439,  0.1064],\n",
            "        [ 0.1863,  0.1502],\n",
            "        [ 0.1013,  0.0510],\n",
            "        [ 0.1256,  0.0933],\n",
            "        [ 0.1721,  0.0575],\n",
            "        [ 0.1779, -0.0784],\n",
            "        [ 0.1466,  0.0192],\n",
            "        [ 0.2254,  0.0131],\n",
            "        [ 0.1454,  0.1470],\n",
            "        [ 0.1857,  0.2412],\n",
            "        [ 0.0081,  0.0374],\n",
            "        [ 0.1050,  0.0173],\n",
            "        [ 0.0566,  0.2168],\n",
            "        [ 0.1401,  0.0932],\n",
            "        [ 0.0245,  0.1312],\n",
            "        [-0.0883,  0.0270],\n",
            "        [ 0.1037,  0.1317],\n",
            "        [ 0.1425,  0.1006],\n",
            "        [ 0.0414,  0.1184],\n",
            "        [ 0.0917,  0.0609],\n",
            "        [ 0.2820,  0.0197],\n",
            "        [ 0.0578,  0.0661],\n",
            "        [ 0.2298,  0.0974],\n",
            "        [ 0.0675,  0.0404],\n",
            "        [ 0.0931,  0.1033],\n",
            "        [ 0.1830,  0.0096],\n",
            "        [ 0.1264, -0.0536],\n",
            "        [ 0.1623,  0.1582],\n",
            "        [ 0.1186,  0.0569],\n",
            "        [ 0.1094, -0.0016],\n",
            "        [ 0.1313,  0.0716],\n",
            "        [ 0.1823,  0.0193],\n",
            "        [ 0.2321, -0.0326],\n",
            "        [ 0.0719,  0.0608],\n",
            "        [ 0.1436,  0.0506],\n",
            "        [ 0.1202,  0.0978],\n",
            "        [ 0.1323,  0.0401],\n",
            "        [ 0.1215,  0.1189],\n",
            "        [ 0.0856, -0.0417],\n",
            "        [ 0.0398,  0.0379],\n",
            "        [ 0.0545,  0.0791],\n",
            "        [ 0.2484,  0.0639],\n",
            "        [ 0.0821,  0.0585],\n",
            "        [ 0.1436,  0.0433],\n",
            "        [ 0.1940,  0.0878],\n",
            "        [ 0.0254,  0.0319],\n",
            "        [ 0.0829,  0.0783],\n",
            "        [ 0.0024,  0.0952],\n",
            "        [ 0.0879,  0.0775],\n",
            "        [ 0.1773,  0.0296],\n",
            "        [ 0.1079, -0.0267],\n",
            "        [ 0.2357,  0.0767],\n",
            "        [ 0.1069,  0.0609],\n",
            "        [ 0.0324,  0.0460],\n",
            "        [ 0.2401,  0.1783],\n",
            "        [ 0.1970,  0.0715],\n",
            "        [ 0.0206,  0.0937],\n",
            "        [ 0.0697, -0.0157],\n",
            "        [ 0.1017,  0.0862],\n",
            "        [-0.0308,  0.0829],\n",
            "        [ 0.0742,  0.0846],\n",
            "        [ 0.0803,  0.0368],\n",
            "        [ 0.3151,  0.2619],\n",
            "        [ 0.1626,  0.0364]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "loss ...  tensor(0.5135, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.4192,  0.5558],\n",
            "        [-0.4661,  0.5094],\n",
            "        [-0.4089,  0.5620],\n",
            "        [-0.4280,  0.5652],\n",
            "        [-0.3775,  0.5116],\n",
            "        [-0.4445,  0.5010],\n",
            "        [-0.5334,  0.5271],\n",
            "        [-0.4815,  0.5511],\n",
            "        [-0.4726,  0.4909],\n",
            "        [-0.4098,  0.5697],\n",
            "        [-0.4373,  0.4903],\n",
            "        [-0.4825,  0.5609],\n",
            "        [-0.4878,  0.5945],\n",
            "        [-0.4765,  0.5966],\n",
            "        [-0.4208,  0.4496],\n",
            "        [-0.4827,  0.5776],\n",
            "        [-0.4511,  0.5044],\n",
            "        [-0.4738,  0.5248],\n",
            "        [-0.4204,  0.5339],\n",
            "        [-0.5137,  0.5155],\n",
            "        [-0.4698,  0.5006],\n",
            "        [-0.3865,  0.5262],\n",
            "        [-0.3952,  0.5525],\n",
            "        [-0.3937,  0.5336],\n",
            "        [-0.4323,  0.5529],\n",
            "        [-0.4782,  0.4991],\n",
            "        [-0.3733,  0.5886],\n",
            "        [-0.5109,  0.5636],\n",
            "        [-0.4768,  0.5814],\n",
            "        [-0.5001,  0.4821],\n",
            "        [-0.4398,  0.4777],\n",
            "        [-0.5041,  0.5240],\n",
            "        [-0.5377,  0.4693],\n",
            "        [-0.4332,  0.5767],\n",
            "        [-0.4228,  0.4858],\n",
            "        [-0.4540,  0.5394],\n",
            "        [-0.2587,  0.4635],\n",
            "        [-0.4286,  0.5512],\n",
            "        [-0.5295,  0.5223],\n",
            "        [-0.3971,  0.5493],\n",
            "        [-0.4817,  0.5583],\n",
            "        [-0.4462,  0.5036],\n",
            "        [-0.5081,  0.5398],\n",
            "        [-0.4526,  0.5161],\n",
            "        [-0.4374,  0.5500],\n",
            "        [-0.4642,  0.5138],\n",
            "        [-0.5580,  0.4640],\n",
            "        [-0.5108,  0.5780],\n",
            "        [-0.4290,  0.4765],\n",
            "        [-0.4897,  0.4877],\n",
            "        [-0.4573,  0.5358],\n",
            "        [-0.3694,  0.4627],\n",
            "        [-0.4843,  0.6349],\n",
            "        [-0.4538,  0.4545],\n",
            "        [-0.3996,  0.5922],\n",
            "        [-0.4208,  0.5245],\n",
            "        [-0.5493,  0.5557],\n",
            "        [-0.4848,  0.5108],\n",
            "        [-0.4339,  0.4724],\n",
            "        [-0.4908,  0.5710],\n",
            "        [-0.5266,  0.5631],\n",
            "        [-0.3766,  0.4470],\n",
            "        [-0.4366,  0.4562],\n",
            "        [-0.4284,  0.5274]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "loss ...  tensor(0.6389, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.4591,  0.5185],\n",
            "        [-0.4378,  0.4577],\n",
            "        [-0.3781,  0.4388],\n",
            "        [-0.3924,  0.4098],\n",
            "        [-0.3796,  0.4713],\n",
            "        [-0.3902,  0.5125],\n",
            "        [-0.3955,  0.4830],\n",
            "        [-0.4680,  0.4082],\n",
            "        [-0.3972,  0.6016],\n",
            "        [-0.4757,  0.5128],\n",
            "        [-0.4390,  0.5144],\n",
            "        [-0.3659,  0.5702],\n",
            "        [-0.4779,  0.5996],\n",
            "        [-0.4291,  0.4358],\n",
            "        [-0.4051,  0.5755],\n",
            "        [-0.3834,  0.5930],\n",
            "        [-0.4735,  0.4507],\n",
            "        [-0.4288,  0.4486],\n",
            "        [-0.3701,  0.4807],\n",
            "        [-0.3696,  0.4313],\n",
            "        [-0.3933,  0.5347],\n",
            "        [-0.4633,  0.5060],\n",
            "        [-0.4677,  0.4728],\n",
            "        [-0.3912,  0.4440],\n",
            "        [-0.4189,  0.5631],\n",
            "        [-0.4282,  0.6120],\n",
            "        [-0.4690,  0.5828],\n",
            "        [-0.4544,  0.5920],\n",
            "        [-0.4557,  0.4898],\n",
            "        [-0.5102,  0.4867],\n",
            "        [-0.3780,  0.4544],\n",
            "        [-0.5005,  0.5231],\n",
            "        [-0.4796,  0.5333],\n",
            "        [-0.4657,  0.5533],\n",
            "        [-0.4038,  0.5270],\n",
            "        [-0.4034,  0.5767],\n",
            "        [-0.4719,  0.5273],\n",
            "        [-0.3824,  0.4929],\n",
            "        [-0.3381,  0.5528],\n",
            "        [-0.3017,  0.4995],\n",
            "        [-0.3689,  0.5074],\n",
            "        [-0.4566,  0.5313],\n",
            "        [-0.3840,  0.5787],\n",
            "        [-0.3941,  0.5330],\n",
            "        [-0.3662,  0.5065],\n",
            "        [-0.3362,  0.5457],\n",
            "        [-0.4575,  0.5073],\n",
            "        [-0.3856,  0.5518],\n",
            "        [-0.4874,  0.5642],\n",
            "        [-0.4586,  0.5819],\n",
            "        [-0.5044,  0.3891],\n",
            "        [-0.5371,  0.5075],\n",
            "        [-0.5089,  0.5168],\n",
            "        [-0.4642,  0.4592],\n",
            "        [-0.3004,  0.5114],\n",
            "        [-0.3202,  0.5219],\n",
            "        [-0.4943,  0.5551],\n",
            "        [-0.4524,  0.5452],\n",
            "        [-0.4024,  0.4690],\n",
            "        [-0.2935,  0.5306],\n",
            "        [-0.4580,  0.5256],\n",
            "        [-0.4065,  0.4783],\n",
            "        [-0.4585,  0.5757],\n",
            "        [-0.3305,  0.5891]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "epoch: 0/3 | train_loss: 0.5658 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f68b0068e972454eb9a55e5a895c5d14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=510), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "loss ...  tensor(0.5062, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.6043,  0.7398],\n",
            "        [-0.5936,  0.6822],\n",
            "        [-0.6067,  0.7863],\n",
            "        [-0.6455,  0.7367],\n",
            "        [-0.6690,  0.6746],\n",
            "        [-0.6539,  0.6874],\n",
            "        [-0.6509,  0.6609],\n",
            "        [-0.6409,  0.7360],\n",
            "        [-0.4908,  0.6227],\n",
            "        [-0.6394,  0.7153],\n",
            "        [-0.5923,  0.6276],\n",
            "        [-0.6324,  0.6325],\n",
            "        [-0.6641,  0.6518],\n",
            "        [-0.5166,  0.7247],\n",
            "        [-0.5524,  0.6894],\n",
            "        [-0.6562,  0.7420],\n",
            "        [-0.6348,  0.7249],\n",
            "        [-0.6275,  0.7198],\n",
            "        [-0.6499,  0.7134],\n",
            "        [-0.6629,  0.7299],\n",
            "        [-0.6189,  0.6779],\n",
            "        [-0.5393,  0.6068],\n",
            "        [-0.6132,  0.7279],\n",
            "        [-0.6545,  0.6970],\n",
            "        [-0.6334,  0.7641],\n",
            "        [-0.6042,  0.6505],\n",
            "        [-0.5664,  0.6569],\n",
            "        [-0.6497,  0.6718],\n",
            "        [-0.5584,  0.7040],\n",
            "        [-0.6582,  0.6289],\n",
            "        [-0.5833,  0.6868],\n",
            "        [-0.6194,  0.7223],\n",
            "        [-0.6139,  0.7595],\n",
            "        [-0.5677,  0.7409],\n",
            "        [-0.6001,  0.6339],\n",
            "        [-0.6798,  0.6892],\n",
            "        [-0.6215,  0.6258],\n",
            "        [-0.7310,  0.7176],\n",
            "        [-0.5823,  0.6174],\n",
            "        [-0.6985,  0.6719],\n",
            "        [-0.6297,  0.5945],\n",
            "        [-0.6455,  0.6071],\n",
            "        [-0.5892,  0.7453],\n",
            "        [-0.5028,  0.6112],\n",
            "        [-0.6803,  0.6332],\n",
            "        [-0.6846,  0.5725],\n",
            "        [-0.6189,  0.6121],\n",
            "        [-0.5626,  0.7593],\n",
            "        [-0.6381,  0.7165],\n",
            "        [-0.6747,  0.7254],\n",
            "        [-0.5873,  0.7018],\n",
            "        [-0.6346,  0.7109],\n",
            "        [-0.5690,  0.6408],\n",
            "        [-0.5925,  0.6960],\n",
            "        [-0.5445,  0.6142],\n",
            "        [-0.5894,  0.6394],\n",
            "        [-0.6198,  0.6616],\n",
            "        [-0.5767,  0.6687],\n",
            "        [-0.6053,  0.8067],\n",
            "        [-0.6918,  0.7165],\n",
            "        [-0.6328,  0.7268],\n",
            "        [-0.5659,  0.6321],\n",
            "        [-0.5970,  0.6720],\n",
            "        [-0.5726,  0.7044]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "loss ...  tensor(0.6344, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.4626,  0.5970],\n",
            "        [-0.5533,  0.5388],\n",
            "        [-0.5376,  0.6308],\n",
            "        [-0.4899,  0.5729],\n",
            "        [-0.5115,  0.5497],\n",
            "        [-0.5375,  0.6178],\n",
            "        [-0.5863,  0.6294],\n",
            "        [-0.4192,  0.5760],\n",
            "        [-0.4237,  0.6066],\n",
            "        [-0.5356,  0.6695],\n",
            "        [-0.5646,  0.6305],\n",
            "        [-0.4749,  0.5592],\n",
            "        [-0.4498,  0.5813],\n",
            "        [-0.4933,  0.5740],\n",
            "        [-0.5100,  0.6275],\n",
            "        [-0.5342,  0.6457],\n",
            "        [-0.4862,  0.5842],\n",
            "        [-0.5110,  0.5534],\n",
            "        [-0.4429,  0.5280],\n",
            "        [-0.4640,  0.5510],\n",
            "        [-0.4408,  0.5977],\n",
            "        [-0.4128,  0.5208],\n",
            "        [-0.4736,  0.5880],\n",
            "        [-0.4863,  0.6527],\n",
            "        [-0.5137,  0.5844],\n",
            "        [-0.5066,  0.5318],\n",
            "        [-0.4584,  0.5059],\n",
            "        [-0.4396,  0.5435],\n",
            "        [-0.5020,  0.6139],\n",
            "        [-0.4737,  0.6108],\n",
            "        [-0.5863,  0.5949],\n",
            "        [-0.4243,  0.6499],\n",
            "        [-0.4580,  0.5660],\n",
            "        [-0.5169,  0.5741],\n",
            "        [-0.4935,  0.5966],\n",
            "        [-0.5719,  0.5710],\n",
            "        [-0.4603,  0.6097],\n",
            "        [-0.3974,  0.5413],\n",
            "        [-0.5188,  0.5441],\n",
            "        [-0.5205,  0.5056],\n",
            "        [-0.4984,  0.5130],\n",
            "        [-0.4775,  0.5786],\n",
            "        [-0.4691,  0.6360],\n",
            "        [-0.4265,  0.6254],\n",
            "        [-0.4677,  0.5606],\n",
            "        [-0.4561,  0.6768],\n",
            "        [-0.4329,  0.6201],\n",
            "        [-0.5565,  0.6169],\n",
            "        [-0.4421,  0.6244],\n",
            "        [-0.4423,  0.6499],\n",
            "        [-0.5118,  0.5482],\n",
            "        [-0.4358,  0.5641],\n",
            "        [-0.4877,  0.5868],\n",
            "        [-0.4903,  0.5991],\n",
            "        [-0.4619,  0.5467],\n",
            "        [-0.5145,  0.6065],\n",
            "        [-0.4184,  0.5627],\n",
            "        [-0.4575,  0.5387],\n",
            "        [-0.4634,  0.5295],\n",
            "        [-0.5240,  0.5709],\n",
            "        [-0.5291,  0.6208],\n",
            "        [-0.4631,  0.6025],\n",
            "        [-0.5025,  0.6120],\n",
            "        [-0.5597,  0.6184]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "loss ...  tensor(0.5839, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.4212,  0.5312],\n",
            "        [-0.4530,  0.5164],\n",
            "        [-0.4640,  0.5376],\n",
            "        [-0.4757,  0.5679],\n",
            "        [-0.4069,  0.5539],\n",
            "        [-0.4650,  0.5699],\n",
            "        [-0.4988,  0.6003],\n",
            "        [-0.4579,  0.6088],\n",
            "        [-0.5079,  0.5770],\n",
            "        [-0.4447,  0.4993],\n",
            "        [-0.3691,  0.5751],\n",
            "        [-0.5055,  0.5670],\n",
            "        [-0.3962,  0.5278],\n",
            "        [-0.5156,  0.5278],\n",
            "        [-0.5263,  0.6083],\n",
            "        [-0.5470,  0.5755],\n",
            "        [-0.4207,  0.5536],\n",
            "        [-0.4870,  0.5581],\n",
            "        [-0.4795,  0.6121],\n",
            "        [-0.4606,  0.5480],\n",
            "        [-0.4683,  0.5493],\n",
            "        [-0.4287,  0.5500],\n",
            "        [-0.4680,  0.6140],\n",
            "        [-0.4842,  0.5573],\n",
            "        [-0.4286,  0.5654],\n",
            "        [-0.4454,  0.5855],\n",
            "        [-0.4914,  0.5683],\n",
            "        [-0.4406,  0.5869],\n",
            "        [-0.4601,  0.5143],\n",
            "        [-0.4837,  0.6108],\n",
            "        [-0.4111,  0.6127],\n",
            "        [-0.4783,  0.5480],\n",
            "        [-0.4497,  0.5628],\n",
            "        [-0.5391,  0.5776],\n",
            "        [-0.4346,  0.4829],\n",
            "        [-0.5252,  0.6194],\n",
            "        [-0.4391,  0.5710],\n",
            "        [-0.4233,  0.5042],\n",
            "        [-0.4015,  0.5369],\n",
            "        [-0.4932,  0.5137],\n",
            "        [-0.4685,  0.5634],\n",
            "        [-0.5025,  0.6033],\n",
            "        [-0.4711,  0.5545],\n",
            "        [-0.4604,  0.5327],\n",
            "        [-0.4618,  0.5881],\n",
            "        [-0.4477,  0.5393],\n",
            "        [-0.4471,  0.4881],\n",
            "        [-0.5195,  0.5523],\n",
            "        [-0.4895,  0.5754],\n",
            "        [-0.4691,  0.6411],\n",
            "        [-0.3782,  0.5392],\n",
            "        [-0.4841,  0.5675],\n",
            "        [-0.4028,  0.5481],\n",
            "        [-0.4414,  0.5597],\n",
            "        [-0.5076,  0.5760],\n",
            "        [-0.4016,  0.5523],\n",
            "        [-0.4461,  0.5324],\n",
            "        [-0.5383,  0.5603],\n",
            "        [-0.5055,  0.6179],\n",
            "        [-0.4948,  0.4979],\n",
            "        [-0.4694,  0.5526],\n",
            "        [-0.5020,  0.5318],\n",
            "        [-0.4737,  0.5599],\n",
            "        [-0.3869,  0.4814]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "epoch: 1/3 | train_loss: 0.5641 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8958302985d640d889664d3ebcf49954",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=510), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "loss ...  tensor(0.6618, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.3736,  0.4449],\n",
            "        [-0.4753,  0.5553],\n",
            "        [-0.3805,  0.5743],\n",
            "        [-0.3883,  0.5972],\n",
            "        [-0.3880,  0.6348],\n",
            "        [-0.3875,  0.5418],\n",
            "        [-0.4090,  0.5881],\n",
            "        [-0.3821,  0.5391],\n",
            "        [-0.4332,  0.5195],\n",
            "        [-0.3987,  0.4849],\n",
            "        [-0.4177,  0.5525],\n",
            "        [-0.4756,  0.5486],\n",
            "        [-0.4926,  0.6106],\n",
            "        [-0.3686,  0.5038],\n",
            "        [-0.4447,  0.4976],\n",
            "        [-0.4178,  0.5404],\n",
            "        [-0.4222,  0.5648],\n",
            "        [-0.4479,  0.5488],\n",
            "        [-0.4226,  0.5058],\n",
            "        [-0.4329,  0.5677],\n",
            "        [-0.4429,  0.5434],\n",
            "        [-0.4673,  0.5496],\n",
            "        [-0.4021,  0.5763],\n",
            "        [-0.4818,  0.5989],\n",
            "        [-0.3967,  0.6360],\n",
            "        [-0.4111,  0.5457],\n",
            "        [-0.4623,  0.5473],\n",
            "        [-0.4388,  0.5493],\n",
            "        [-0.3401,  0.5171],\n",
            "        [-0.4300,  0.5679],\n",
            "        [-0.4698,  0.5889],\n",
            "        [-0.3714,  0.4175],\n",
            "        [-0.4209,  0.6619],\n",
            "        [-0.4070,  0.5908],\n",
            "        [-0.4151,  0.5835],\n",
            "        [-0.4403,  0.5479],\n",
            "        [-0.4711,  0.5620],\n",
            "        [-0.3953,  0.5508],\n",
            "        [-0.4147,  0.5987],\n",
            "        [-0.4407,  0.5653],\n",
            "        [-0.4072,  0.5734],\n",
            "        [-0.4215,  0.6020],\n",
            "        [-0.5230,  0.5469],\n",
            "        [-0.4250,  0.5122],\n",
            "        [-0.2939,  0.6178],\n",
            "        [-0.4660,  0.5931],\n",
            "        [-0.3576,  0.5311],\n",
            "        [-0.4658,  0.5428],\n",
            "        [-0.3841,  0.5292],\n",
            "        [-0.3829,  0.5332],\n",
            "        [-0.4486,  0.4962],\n",
            "        [-0.4743,  0.5355],\n",
            "        [-0.4116,  0.6090],\n",
            "        [-0.3738,  0.5375],\n",
            "        [-0.4083,  0.5080],\n",
            "        [-0.3766,  0.4969],\n",
            "        [-0.4113,  0.6227],\n",
            "        [-0.3863,  0.5866],\n",
            "        [-0.3915,  0.6149],\n",
            "        [-0.4123,  0.5449],\n",
            "        [-0.4177,  0.5583],\n",
            "        [-0.4557,  0.6177],\n",
            "        [-0.4528,  0.5664],\n",
            "        [-0.4627,  0.5909]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "loss ...  tensor(0.7329, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.3963,  0.4678],\n",
            "        [-0.4241,  0.5166],\n",
            "        [-0.4980,  0.5753],\n",
            "        [-0.4208,  0.5838],\n",
            "        [-0.4905,  0.6424],\n",
            "        [-0.4955,  0.4837],\n",
            "        [-0.4993,  0.5386],\n",
            "        [-0.4279,  0.5798],\n",
            "        [-0.4773,  0.5957],\n",
            "        [-0.4677,  0.6053],\n",
            "        [-0.4564,  0.5183],\n",
            "        [-0.4855,  0.5560],\n",
            "        [-0.4546,  0.5812],\n",
            "        [-0.4089,  0.5505],\n",
            "        [-0.4921,  0.6288],\n",
            "        [-0.5102,  0.6048],\n",
            "        [-0.4443,  0.5761],\n",
            "        [-0.3912,  0.5725],\n",
            "        [-0.4545,  0.5650],\n",
            "        [-0.4715,  0.5923],\n",
            "        [-0.4422,  0.5584],\n",
            "        [-0.4509,  0.6557],\n",
            "        [-0.5379,  0.5584],\n",
            "        [-0.4774,  0.5908],\n",
            "        [-0.4199,  0.6039],\n",
            "        [-0.3270,  0.5933],\n",
            "        [-0.5021,  0.5675],\n",
            "        [-0.4762,  0.5760],\n",
            "        [-0.4733,  0.5864],\n",
            "        [-0.4617,  0.5982],\n",
            "        [-0.5057,  0.6066],\n",
            "        [-0.4613,  0.5718],\n",
            "        [-0.4005,  0.5868],\n",
            "        [-0.4525,  0.5515],\n",
            "        [-0.5157,  0.5962],\n",
            "        [-0.4897,  0.5292],\n",
            "        [-0.5156,  0.6223],\n",
            "        [-0.5145,  0.6225],\n",
            "        [-0.4523,  0.5725],\n",
            "        [-0.4728,  0.5857],\n",
            "        [-0.5326,  0.5608],\n",
            "        [-0.4715,  0.4918],\n",
            "        [-0.4189,  0.4894],\n",
            "        [-0.4641,  0.6210],\n",
            "        [-0.4752,  0.6058],\n",
            "        [-0.4277,  0.6103],\n",
            "        [-0.4371,  0.5406],\n",
            "        [-0.4763,  0.5305],\n",
            "        [-0.3984,  0.5728],\n",
            "        [-0.4801,  0.6098],\n",
            "        [-0.4310,  0.5667],\n",
            "        [-0.4914,  0.5662],\n",
            "        [-0.4335,  0.5725],\n",
            "        [-0.4315,  0.5123],\n",
            "        [-0.3810,  0.6666],\n",
            "        [-0.4408,  0.5935],\n",
            "        [-0.5285,  0.5947],\n",
            "        [-0.5536,  0.5609],\n",
            "        [-0.5172,  0.5818],\n",
            "        [-0.4514,  0.5719],\n",
            "        [-0.4758,  0.5888],\n",
            "        [-0.4639,  0.5533],\n",
            "        [-0.4509,  0.6169],\n",
            "        [-0.4942,  0.5970]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "loss ...  tensor(0.4360, device='cuda:0', grad_fn=<NllLossBackward>) <class 'torch.Tensor'>\n",
            "logit ...  tensor([[-0.4683,  0.5577],\n",
            "        [-0.4535,  0.5630],\n",
            "        [-0.4427,  0.5600],\n",
            "        [-0.4293,  0.5172],\n",
            "        [-0.4733,  0.5790],\n",
            "        [-0.4059,  0.5226],\n",
            "        [-0.4085,  0.5174],\n",
            "        [-0.4561,  0.5143],\n",
            "        [-0.3634,  0.5800],\n",
            "        [-0.3710,  0.4778],\n",
            "        [-0.4676,  0.4792],\n",
            "        [-0.4797,  0.5997],\n",
            "        [-0.4298,  0.5115],\n",
            "        [-0.4236,  0.5133],\n",
            "        [-0.5117,  0.5808],\n",
            "        [-0.4424,  0.5358],\n",
            "        [-0.3910,  0.6321],\n",
            "        [-0.3961,  0.5613],\n",
            "        [-0.4669,  0.6089],\n",
            "        [-0.4198,  0.5550],\n",
            "        [-0.4858,  0.6209],\n",
            "        [-0.5066,  0.4753],\n",
            "        [-0.4220,  0.5904],\n",
            "        [-0.4818,  0.5732],\n",
            "        [-0.4517,  0.5614],\n",
            "        [-0.4522,  0.5603],\n",
            "        [-0.4412,  0.5571],\n",
            "        [-0.4829,  0.6098],\n",
            "        [-0.3718,  0.5506],\n",
            "        [-0.4386,  0.5599],\n",
            "        [-0.4540,  0.5970],\n",
            "        [-0.4175,  0.5189],\n",
            "        [-0.4346,  0.5592],\n",
            "        [-0.4476,  0.6087],\n",
            "        [-0.3731,  0.4769],\n",
            "        [-0.4593,  0.6229],\n",
            "        [-0.4648,  0.6496],\n",
            "        [-0.5385,  0.5799],\n",
            "        [-0.4313,  0.5618],\n",
            "        [-0.4793,  0.5576],\n",
            "        [-0.4787,  0.5669],\n",
            "        [-0.4830,  0.5507],\n",
            "        [-0.5184,  0.5724],\n",
            "        [-0.4224,  0.6026],\n",
            "        [-0.4640,  0.5579],\n",
            "        [-0.5074,  0.4843],\n",
            "        [-0.5476,  0.5539],\n",
            "        [-0.5133,  0.5485],\n",
            "        [-0.3652,  0.4681],\n",
            "        [-0.4596,  0.5913],\n",
            "        [-0.5006,  0.5839],\n",
            "        [-0.4456,  0.6093],\n",
            "        [-0.4456,  0.5482],\n",
            "        [-0.4366,  0.5673],\n",
            "        [-0.4823,  0.5842],\n",
            "        [-0.4331,  0.5416],\n",
            "        [-0.4820,  0.5571],\n",
            "        [-0.4042,  0.6496],\n",
            "        [-0.5046,  0.5998],\n",
            "        [-0.4759,  0.5032],\n",
            "        [-0.3765,  0.5584],\n",
            "        [-0.4517,  0.5137],\n",
            "        [-0.4998,  0.5769],\n",
            "        [-0.4267,  0.5571]], device='cuda:0', grad_fn=<AddmmBackward>) <class 'torch.Tensor'>\n",
            "epoch: 2/3 | train_loss: 0.5644 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr6ddOojQOy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "3a490951-ad0e-4de9-c7f5-1a552f60baa8"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_losses)\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Batch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f206d009710>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAH0CAYAAACD2iiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAgIUQAgEAAADAQgiBAAAAAGAh/wETI8d4BDhZxgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKU6jC1k9fLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "labels = []\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(y_preds, real_ys):\n",
        "    pred_flat = np.argmax(y_preds, axis=1).flatten()\n",
        "    labels_flat = real_ys.flatten()\n",
        "    print(\"pred_flat is \", pred_flat)\n",
        "    print(\"labels_flat is \", labels_flat)\n",
        "    preds.append(pred_flat)\n",
        "    labels.append(labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzJUqt5G9HEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 평가 헬퍼 함수\n",
        "def bert_eval_net(net, data_loader, device=\"cuda\"):\n",
        "  # Dropout 및 BatchNorm 무효화\n",
        "  net.eval()\n",
        "\n",
        "  eval_acc = 0\n",
        "  nb_eval_examples, nb_eval_steps = 0,0\n",
        "\n",
        "  for x, y in data_loader:\n",
        "    x=x.to(device)\n",
        "    y=y.to(device)\n",
        "    with torch.no_grad():\n",
        "      y_preds = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=None)  # forward\n",
        "\n",
        "    #Move logits and labels to CPU\n",
        "    y_preds = y_preds[0].detach().cpu().numpy()\n",
        "    real_ys = y.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(y_preds, real_ys)\n",
        "    print(\"tmp_eval_accuracy : \", tmp_eval_accuracy)\n",
        "\n",
        "    eval_acc += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_acc/nb_eval_steps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmmhDse9IMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ff98a05-1ae6-40ee-d942-f243d19e3eb5"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "bert_eval_net(model, test_loader, device)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.828125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.828125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1\n",
            " 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.671875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.828125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.671875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1\n",
            " 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.671875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.828125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1\n",
            " 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.65625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.640625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.671875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1\n",
            " 1 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.671875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.828125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.828125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1\n",
            " 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.828125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.71875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.734375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0]\n",
            "tmp_eval_accuracy :  0.78125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.8125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.90625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0]\n",
            "tmp_eval_accuracy :  0.65625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0]\n",
            "tmp_eval_accuracy :  0.84375\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1]\n",
            "tmp_eval_accuracy :  0.796875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "tmp_eval_accuracy :  0.75\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.765625\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1]\n",
            "tmp_eval_accuracy :  0.703125\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1]\n",
            "tmp_eval_accuracy :  0.6875\n",
            "pred_flat is  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "labels_flat is  [0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1]\n",
            "tmp_eval_accuracy :  0.696969696969697\n",
            "Validation Accuracy: 0.7559333570075758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Biqhy-l-StT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def result_summary(pred_y, real_y):\n",
        "  print(\"Accuracy: {:.4f}\".format(accuracy_score(real_y, pred_y)))\n",
        "  print(\"Confusion Matrix: \\n\", confusion_matrix(real_y, pred_y))\n",
        "  print(\"Classification Report Matrix: \\n\", classification_report(real_y, pred_y, digits=3))\n",
        "\n",
        "  roc_auc = roc_auc_score(real_y, pred_y)\n",
        "  print(\"roc_auc score is : {:.4f}\".format(roc_auc))\n",
        "\n",
        "  fpr, tpr, threshold = roc_curve(real_y, pred_y)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  auc_graph(roc_auc, fpr, tpr)\n",
        "\n",
        "def auc_graph(roc_auc, fpr, tpr):\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyFWv6Z3-Ui8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "outputId": "69bd330e-628e-4640-9d84-ddbe8e624982"
      },
      "source": [
        "import itertools\n",
        "preds_flat = list(itertools.chain(*preds))\n",
        "labels_flat = list(itertools.chain(*labels))\n",
        "\n",
        "result_summary(preds_flat, labels_flat)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7562\n",
            "Confusion Matrix: \n",
            " [[   0 1990]\n",
            " [   0 6171]]\n",
            "Classification Report Matrix: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000      1990\n",
            "           1      0.756     1.000     0.861      6171\n",
            "\n",
            "    accuracy                          0.756      8161\n",
            "   macro avg      0.378     0.500     0.431      8161\n",
            "weighted avg      0.572     0.756     0.651      8161\n",
            "\n",
            "roc_auc score is : 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyCRpCCGECJkkDSGEECGTpCGEECJkfwEUBPAJ6tFSJwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QMVH-Ei_Yl0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}