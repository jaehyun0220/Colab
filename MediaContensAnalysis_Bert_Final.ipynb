{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MediaContensAnalysis_Bert_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bcca814deb44a169eea803611d667cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65a5976e2b53492da84085554d82e217",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a457b67cfc40492d853c7baa310e6acb",
              "IPY_MODEL_1dffade1ded94e27823b9d8f25e212ac"
            ]
          }
        },
        "65a5976e2b53492da84085554d82e217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a457b67cfc40492d853c7baa310e6acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4888fe4847304934812fed4107e473f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3041eaf35e14700b8bc34d661d184b2"
          }
        },
        "1dffade1ded94e27823b9d8f25e212ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a2c2542a2884a87b2c1fb3632c64183",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 28/28 [00:10&lt;00:00,  3.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3eff39b649ef4b1e87f7d92134175c85"
          }
        },
        "4888fe4847304934812fed4107e473f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3041eaf35e14700b8bc34d661d184b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a2c2542a2884a87b2c1fb3632c64183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3eff39b649ef4b1e87f7d92134175c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00906dd2976e4f538f97482f1f0d5ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9499f7958e24c0a9c70cedf8a9b1ccf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3814e75a793d4921911e0513f54d7bf5",
              "IPY_MODEL_68630a12c40c4f94bdb4a889e28be0ad"
            ]
          }
        },
        "b9499f7958e24c0a9c70cedf8a9b1ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3814e75a793d4921911e0513f54d7bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_696035d79cda42ae8faa138eb5497cad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 40801,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40801,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c5845891ed64a47889db8de15eb416a"
          }
        },
        "68630a12c40c4f94bdb4a889e28be0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25055603531c4f21b5368a269ca58786",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 40801/40801 [00:09&lt;00:00, 4148.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e939c5b593343dfa744e664be9c6abb"
          }
        },
        "696035d79cda42ae8faa138eb5497cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c5845891ed64a47889db8de15eb416a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25055603531c4f21b5368a269ca58786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e939c5b593343dfa744e664be9c6abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f076629e8cf47a2bbdfab4c982307c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_109326caa756480baa08a23fc02e78b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c018e47ab994303b38a5c27b0b2c27d",
              "IPY_MODEL_8f06a8d73ee949708bf5d8cdd8fe4c7f"
            ]
          }
        },
        "109326caa756480baa08a23fc02e78b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c018e47ab994303b38a5c27b0b2c27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_489c98abaaa74ee2956ff22b5d898a5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_026a577d79504bf68520f6b211925a02"
          }
        },
        "8f06a8d73ee949708bf5d8cdd8fe4c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99a783c65d4e4d889665686ad0ba7031",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0% 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f454e4a6aec941debd9ef47cc331a7d9"
          }
        },
        "489c98abaaa74ee2956ff22b5d898a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "026a577d79504bf68520f6b211925a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99a783c65d4e4d889665686ad0ba7031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f454e4a6aec941debd9ef47cc331a7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d397dde0793c45b7b4ddb4fa3d35a7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c113c5be9f014cd28b7db724f2ebc048",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65e62fe9b15746e6be0ae0f3b17f7b3b",
              "IPY_MODEL_ae5d582acb5e401fbca6bedf9423f3d0"
            ]
          }
        },
        "c113c5be9f014cd28b7db724f2ebc048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65e62fe9b15746e6be0ae0f3b17f7b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4212e8e64df943bbb9a15cc8ee2c84dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 1020,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 98,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af49113768b140868905bb6b7d7d0b30"
          }
        },
        "ae5d582acb5e401fbca6bedf9423f3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9675e226dbcd40488db79f14fb051561",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10% 97/1020 [02:10&lt;20:55,  1.36s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b1213054f164637bc4a0479423f325e"
          }
        },
        "4212e8e64df943bbb9a15cc8ee2c84dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af49113768b140868905bb6b7d7d0b30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9675e226dbcd40488db79f14fb051561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b1213054f164637bc4a0479423f325e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun0220/Colab/blob/master/MediaContensAnalysis_Bert_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmdavC_fLDrU",
        "colab_type": "text"
      },
      "source": [
        "#10조. 네이버 댓글 분석을 통한 상위, 하위 클립 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcnHnotA2oRX",
        "colab_type": "text"
      },
      "source": [
        "### #1. 구글 인증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnLbyZflC1R1",
        "colab_type": "code",
        "outputId": "2a61f6d1-cf2d-4db4-c6e6-2e53814e61fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Auth 인증 및 Google Drive 활용 Data load\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNICcJFm2hm7",
        "colab_type": "text"
      },
      "source": [
        "### #2. 입력 데이터셋 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5oQGfjLC-Jb",
        "colab_type": "code",
        "outputId": "e886bc61-926e-4610-ec96-6f1dca424e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!ls ../gdrive/My\\ Drive/output"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_ep10.csv\t file_ep16.csv\tfile_ep22.csv  file_ep4.csv\n",
            "file_ep11.csv\t file_ep17.csv\tfile_ep23.csv  file_ep5.csv\n",
            "file_ep12.csv\t file_ep18.csv\tfile_ep24.csv  file_ep6.csv\n",
            "file_ep13.csv\t file_ep19.csv\tfile_ep25.csv  file_ep7.csv\n",
            "file_ep14_1.csv  file_ep1.csv\tfile_ep26.csv  file_ep8.csv\n",
            "file_ep14.csv\t file_ep20.csv\tfile_ep2.csv   file_ep9.csv\n",
            "file_ep15.csv\t file_ep21.csv\tfile_ep3.csv   TheLastEmpress.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bdQCRGv7AX6",
        "colab_type": "code",
        "outputId": "83bd591b-57fa-45c4-de6c-fe2456a65dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "!pip install regex\n",
        "# Okt, Kkma 등의 형태소 분석기 활용을 위한 설치\n",
        "!pip install konlpy\n",
        "# Bert 사용을 위한 설치\n",
        "!pip install sacremoses sentencepiece "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.9)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.35)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.83)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEGh8u0qDI6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기본 라이브러리 로드\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import regex as re\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터 전처리 관련 라이브러리 로드\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#모델 평가를 위한 라이브러리 로드\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\n",
        "\n",
        "#데이터 분리를 위한 라이브러리 로드\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#수학 & 통계 관련 라이브러리 로드\n",
        "import scipy.stats as st\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl  # 기본 설정 만지는 용도\n",
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도\n",
        "\n",
        "\n",
        "#Configure Visualization Defaults\n",
        "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
        "%matplotlib inline\n",
        "mpl.style.use('ggplot')\n",
        "sns.set_style('white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpUzHCYqMYp1",
        "colab_type": "code",
        "outputId": "fdd8cc2e-2486-4b90-cd3d-82cc3e6c52a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "# 입력으로 활용할 데이터셋 List 확인\n",
        "filelist = os.listdir('../gdrive/My Drive/output')\n",
        "filelist"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['file_ep1.csv',\n",
              " 'file_ep16.csv',\n",
              " 'file_ep17.csv',\n",
              " 'file_ep10.csv',\n",
              " 'file_ep14.csv',\n",
              " 'file_ep12.csv',\n",
              " 'file_ep11.csv',\n",
              " 'file_ep14_1.csv',\n",
              " 'file_ep15.csv',\n",
              " 'file_ep13.csv',\n",
              " 'file_ep18.csv',\n",
              " 'file_ep19.csv',\n",
              " 'file_ep21.csv',\n",
              " 'file_ep20.csv',\n",
              " 'file_ep2.csv',\n",
              " 'file_ep22.csv',\n",
              " 'file_ep23.csv',\n",
              " 'file_ep25.csv',\n",
              " 'file_ep24.csv',\n",
              " 'file_ep26.csv',\n",
              " 'file_ep3.csv',\n",
              " 'file_ep4.csv',\n",
              " 'file_ep5.csv',\n",
              " 'file_ep6.csv',\n",
              " 'file_ep9.csv',\n",
              " 'file_ep7.csv',\n",
              " 'TheLastEmpress.csv',\n",
              " 'file_ep8.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Ink4z2DVoG",
        "colab_type": "code",
        "outputId": "7564bf8d-e8c9-4054-e612-4fcb05593ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469,
          "referenced_widgets": [
            "0bcca814deb44a169eea803611d667cc",
            "65a5976e2b53492da84085554d82e217",
            "a457b67cfc40492d853c7baa310e6acb",
            "1dffade1ded94e27823b9d8f25e212ac",
            "4888fe4847304934812fed4107e473f7",
            "e3041eaf35e14700b8bc34d661d184b2",
            "3a2c2542a2884a87b2c1fb3632c64183",
            "3eff39b649ef4b1e87f7d92134175c85"
          ]
        }
      },
      "source": [
        "# 총 26회차 491개 하이라이트 클립 존재 (전체 재생수 = 107,221,654 / 클립 당 평균 재생수 = 218,374), \n",
        "# 이 중에서 예고편, 미공개, 인터뷰 등 클립 제외하고 총 422회 클립 대상\n",
        "df_title = pd.read_csv('../gdrive/My Drive/output/TheLastEmpress.csv', encoding = 'euc-kr')\n",
        "df_title.rename(columns=lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》 ]', '', x), inplace=True)\n",
        "\n",
        "# 조회수 분포를 고려하여 각 회차별로 조회수 상위 4개, 하위 4개 클립을 샘플링 - 총 208개 클립\n",
        "# 좋아요수, 댓글 수, 댓글 내용, 댓글 작성자 정보 (웹크롤링 통한 추출)\n",
        "\n",
        "df_ep_tot = pd.DataFrame()\n",
        "\n",
        "# 상위 하위 클립을 나누어 조회수 내림차순으로 rank를 매김 (1~4는 상위 클립, 5~8은 하위 클립)\n",
        "for i in tqdm_notebook(filelist):\n",
        "  if (i[:4] == 'file'):\n",
        "    df_ep_temp = pd.read_csv('../gdrive/My Drive/output/'+i)\n",
        "    df_ep_temp['play'] = df_ep_temp['play'].apply(lambda x: int(re.sub(',','', x[4:])))\n",
        "    df_ep_temp['rank'] = df_ep_temp['play'].rank(method='dense', ascending=False)\n",
        "    df_ep_tot = df_ep_tot.append(df_ep_temp)\n",
        "\n",
        "# 크롤링 한 데이터에서 불필요한 열 삭제\n",
        "df_ep_tot.drop(columns='Unnamed: 0', inplace=True)\n",
        "\n",
        "# 상위 클립은 1로 하위 클립은 0으로 분류\n",
        "df_ep_tot['target'] = np.where(df_ep_tot['rank']<=4,1,0)\n",
        "df_ep_tot"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bcca814deb44a169eea803611d667cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nick</th>\n",
              "      <th>contents</th>\n",
              "      <th>recomm</th>\n",
              "      <th>unrecomm</th>\n",
              "      <th>title</th>\n",
              "      <th>play</th>\n",
              "      <th>like</th>\n",
              "      <th>reple_count</th>\n",
              "      <th>episode</th>\n",
              "      <th>rank</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rosi****</td>\n",
              "      <td>ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>핑크에메랄드</td>\n",
              "      <td>왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>서지안</td>\n",
              "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>경</td>\n",
              "      <td>ㅏ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홍홍</td>\n",
              "      <td>이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>신은경, 핸드폰 너머 이엘리야의 의도적 신음에 ‘분노 폭발’</td>\n",
              "      <td>474498</td>\n",
              "      <td>842</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>Major</td>\n",
              "      <td>와 ㅅㅂ...피지컬봐....</td>\n",
              "      <td>550</td>\n",
              "      <td>1</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842</th>\n",
              "      <td>스폰지밥</td>\n",
              "      <td>이쁘십니다 할때 나만설렜냐,,,,,,,</td>\n",
              "      <td>691</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1843</th>\n",
              "      <td>박한별</td>\n",
              "      <td>반했네</td>\n",
              "      <td>372</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1844</th>\n",
              "      <td>김민정</td>\n",
              "      <td>죄송하지만 이 분 이용합시다 ! 어쨌든 좋은게 좋은거죠 ..</td>\n",
              "      <td>593</td>\n",
              "      <td>4</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>블링블링</td>\n",
              "      <td>우빈이한테 전부 들이대는군</td>\n",
              "      <td>338</td>\n",
              "      <td>3</td>\n",
              "      <td>이희진, 근육남 최진혁에 공주표 애교 “마이 아포”</td>\n",
              "      <td>155236</td>\n",
              "      <td>645</td>\n",
              "      <td>173</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40935 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          nick                                           contents  ...  rank  target\n",
              "0     rosi****  ㅅㅂ옷입고 목욕탕 들어가는거 ㅈㄴ웃기넼ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ저거 명품일 텐데ㅋㅋㅋㅋ...  ...   1.0       1\n",
              "1       핑크에메랄드  왠지 선황제가 바람은 못폈을거 같다는 생각이 든다 태후가 황후로 있는한 감히 생각도...  ...   1.0       1\n",
              "2          서지안                                           ㅋㅋㅋㅋㅋㅋㅋㅋ  ...   1.0       1\n",
              "3            경                                                  ㅏ  ...   1.0       1\n",
              "4           홍홍            이게 나라냐? 방송에서 이딴수위가 나오고 지랄이야 진짜 개좃헬조선 시발  ...   1.0       1\n",
              "...        ...                                                ...  ...   ...     ...\n",
              "1841     Major                                    와 ㅅㅂ...피지컬봐....  ...   8.0       0\n",
              "1842      스폰지밥                              이쁘십니다 할때 나만설렜냐,,,,,,,  ...   8.0       0\n",
              "1843       박한별                                                반했네  ...   8.0       0\n",
              "1844       김민정                  죄송하지만 이 분 이용합시다 ! 어쨌든 좋은게 좋은거죠 ..  ...   8.0       0\n",
              "1845      블링블링                                     우빈이한테 전부 들이대는군  ...   8.0       0\n",
              "\n",
              "[40935 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MxLLtPX7gN",
        "colab_type": "text"
      },
      "source": [
        "### #3. 데이터 정제 - 댓글 중 분석 대상이 되는 contens 내 null data 삭제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cA7gB0gV3HF",
        "colab_type": "code",
        "outputId": "af3e4a70-bd19-4ef0-ff28-3dfda3b6938c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df_ep_sample = df_ep_tot.copy()\n",
        "df_ep_sample.dropna(how='any', inplace=True)\n",
        "df_ep_sample.info()\n",
        "df_ep_sample['target'].value_counts() # 3:1 imbalanced dataset (조회수가 많은 클립에 댓글이 많기 때문임))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 40801 entries, 0 to 1845\n",
            "Data columns (total 11 columns):\n",
            "nick           40801 non-null object\n",
            "contents       40801 non-null object\n",
            "recomm         40801 non-null int64\n",
            "unrecomm       40801 non-null int64\n",
            "title          40801 non-null object\n",
            "play           40801 non-null int64\n",
            "like           40801 non-null object\n",
            "reple_count    40801 non-null object\n",
            "episode        40801 non-null int64\n",
            "rank           40801 non-null float64\n",
            "target         40801 non-null int64\n",
            "dtypes: float64(1), int64(5), object(5)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    30632\n",
              "0    10169\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbDda80F4Spl",
        "colab_type": "text"
      },
      "source": [
        "### #4. 데이터 길이 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qHvTttUYJQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.utils import pprint\n",
        "\n",
        "kkma = Kkma()\n",
        "\n",
        "def morphs_kkma(x):\n",
        "  res = kkma.morphs(x)\n",
        "  if len(res) >= 1:\n",
        "    res = [re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) for i in range(len(res)) if re.sub('[ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣ ]', '', res[i]) != '' and len(res[i]) >= 1]\n",
        "  else:\n",
        "    res = ''\n",
        "  res = '' if not res else res\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1xNEIOX4bxo",
        "colab_type": "text"
      },
      "source": [
        "#### #4-1. 데이터 정제 - 정규식 & 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyG91a40YN8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ep_sample['contents'] = df_ep_sample['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "df_ep_sample.dropna(how='any', inplace=True)\n",
        "df_sample_final = df_ep_sample.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyS88sBUT_Tk",
        "colab_type": "text"
      },
      "source": [
        "## 공통 영역: Word Embedding을 위한 Hyper parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT_z_0uNV8fp",
        "colab_type": "code",
        "outputId": "026f547d-b445-4e2b-c800-015fc15031f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Hyper Param setting\n",
        "\n",
        "# token의 Histogram 분포를 바탕으로 대부분의 단어 길이 cover 가능한 단어 개수 찾기\n",
        "# # 신경망 학습을 위한 input 벡터 길이로 사용 - 적정 길이는 tokenizng 이후 분포를 보고 결정(코드 하단)\n",
        "# totalLenSent = [len(x) for x in df_ep_sample['kkma_token']] # 각 document의 단어 길이를 check\n",
        "# plt.hist(totalLenSent,bins = np.arange(0,max(totalLenSent),max(totalLenSent)/20))\n",
        "\n",
        "# print(np.percentile(totalLenSent, 95)) # 95%를 커버하는 수치는 41\n",
        "\n",
        "# MAX_LEN = int(np.percentile(totalLenSent, 95)) but bert는 128 embedding 사용\n",
        "MAX_LEN = 128\n",
        "print(MAX_LEN)\n",
        "\n",
        "# pre-trained Embedding을 몇 개 사용할 지 결정\n",
        "NUM_MODELS = 1\n",
        "\n",
        "# # input data 원문에서 보존할 최대 단어 개수 \n",
        "# # 전체 데이터셋에서 나타나는 unique 한 단어 수(넉넉하게 백단위 올림하여 setting)\n",
        "# from itertools import chain\n",
        "\n",
        "# sum_lists = list(chain.from_iterable(df_ep_sample['okt_token']))\n",
        "# totalCntWords = int(math.ceil(len(set(sum_lists))/100)*100)\n",
        "\n",
        "MAX_FEATURES = 37000\n",
        "# MAX_FEATURES = totalCntWords\n",
        "# print(len(set(sum_lists)), MAX_FEATURES)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwIUNatxUKw0",
        "colab_type": "text"
      },
      "source": [
        "## Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-xt5s3WE7P_O"
      },
      "source": [
        "### Pytorch 환경 내에서 BERT를 사용하기 위한 BERT 관련 Library Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dJuak78KBqh",
        "colab_type": "code",
        "outputId": "57245a8a-2dff-404b-961f-c9475223466c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
            "\r\u001b[K     |█                               | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJOgiUFK7P_T",
        "colab": {}
      },
      "source": [
        "!mkdir ../bert_work/\n",
        "PATH_PRETRAINED = \"../gdrive/My Drive/data/bert/multi_cased_L-12_H-768_A-12/\"\n",
        "PATH_WORK = '../bert_work/'\n",
        "\n",
        "FILE_VOCAB = \"../gdrive/My Drive/data/bert/bert-base-multilingual-cased/bert-base-multilingual-cased-vocab.txt\"\n",
        "OUTPUT_MODEL_PATH = \"../gdrive/My Drive/data/bert/cust_model_save/\"\n",
        "\n",
        "sys.path.append(PATH_PRETRAINED)\n",
        "sys.path.append(PATH_WORK)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1O_Gd40m7P_U",
        "colab": {}
      },
      "source": [
        "import sacremoses\n",
        "import sentencepiece\n",
        "\n",
        "import pickle\n",
        "import shutil\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn # for neural net\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # jupyter에서 마지막 값만 출력하는게 아니라 모든 출력값을 매번 연속적으로 출력\n",
        "InteractiveShell.ast_node_interactivity = \"all\" # all, last, last_expr, none (기본값은 'last_expr')\n",
        "\n",
        "# from transformers import convert_tf_checkpoint_to_pytorch\n",
        "from transformers import convert_bert_original_tf_checkpoint_to_pytorch\n",
        "\n",
        "# from transformers import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from transformers import BertTokenizer, AdamW, BertModel, BertPreTrainedModel, BertConfig\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "\n",
        "from transformers import BertConfig # This is the Bert configuration file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k_BWb1wy7d9y"
      },
      "source": [
        "### BERT 사용 관련 Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngE4dova7d91",
        "outputId": "4a4595ce-abe4-4107-ac4c-c13202c3d58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seed = 42\n",
        "MAX_SEQ_LEN = MAX_LEN # token분포 바탕으로 128 선정 (대부분의 단어 길이 cover)\n",
        "\n",
        "NUM_LABELS = len(df_sample_final['target'].unique()) #2 If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy)\n",
        "training_epochs = 2\n",
        "lr = 2e-5\n",
        "batch_size = 32\n",
        "\n",
        "bert_model_config = PATH_PRETRAINED+'bert_config.json'\n",
        "\n",
        "bert_model = 'bert-base-multilingual-cased'\n",
        "do_lower_case = 'uncased' in bert_model\n",
        "device = torch.device('cuda') # GPU 사용 setting\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe5a5c47e30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM54ZY3SYMGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification(BertPreTrainedModel):\n",
        "    r\"\"\"\n",
        "        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n",
        "            Labels for computing the sequence classification/regression loss.\n",
        "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "            If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n",
        "            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n",
        "    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "            Classification (or regression if config.num_labels==1) loss.\n",
        "        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n",
        "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
        "        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "            of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
        "            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "    Examples::\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
        "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
        "                position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
        "\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids,\n",
        "                            position_ids=position_ids,\n",
        "                            head_mask=head_mask,\n",
        "                            inputs_embeds=inputs_embeds)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSKjJZl_IzLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the lines to BERT format # do token-convert-to-ids\n",
        "def convert_bert_token(example, max_seq_length,tokenizer):\n",
        "    max_seq_length -=2\n",
        "    all_tokens = []\n",
        "    longer = 0\n",
        "    for text in tqdm_notebook(example):\n",
        "        tokens_a = tokenizer.tokenize(text)\n",
        "        # print(\"tokens_a : \", tokens_a)\n",
        "        if len(tokens_a)>max_seq_length:  #token의 길이가 max_seq_length보다 길면 max_seq_length 뒤로는 잘라내고, longer 변수를 1증가 시킴\n",
        "            tokens_a = tokens_a[:max_seq_length]\n",
        "            longer += 1\n",
        "        # token의 앞 뒤에 [CLS]와 [SEP]을 추가 시키고 남는자리는 zero padding\n",
        "        # print(\"max_seq_length: \", max_seq_length, \"len(tokens_a): \", len(tokens_a), \"max_seq_length - len(tokens_a) : \", max_seq_length - len(tokens_a))\n",
        "\n",
        "        # \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+ [0] * int(max_seq_length - len(tokens_a)) # token을 vocab을 이용하여 id로 convert\n",
        "        all_tokens.append(one_token) # all_tokens에 추가\n",
        "    return np.array(all_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zchSpZM97tdM",
        "colab_type": "code",
        "outputId": "e62a2033-feb7-42b3-db14-bedd0ae3081f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "convert_bert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
        "    PATH_PRETRAINED + 'bert_model.ckpt',\n",
        "    PATH_PRETRAINED + 'bert_config.json',\n",
        "    PATH_WORK + 'pytorch_model.bin')\n",
        "\n",
        "# 읽어온 BERT_MODEL_PATH bert_config.json file의 설정을 그대로 WORK_DIR의 bert_config.json이라는 이름으로 저장\n",
        "shutil.copyfile(PATH_PRETRAINED + 'bert_config.json', PATH_WORK + 'config.json')\n",
        "# shutil.copyfile(PATH_PRETRAINED + 'vocab.txt', PATH_WORK + 'vocab.txt')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building PyTorch model from configuration: {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_bert:Converting TensorFlow checkpoint from /gdrive/My Drive/data/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/embeddings/word_embeddings with shape [119547, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/pooler/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight cls/predictions/output_bias with shape [119547]\n",
            "INFO:transformers.modeling_bert:Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n",
            "INFO:transformers.modeling_bert:Loading TF weight cls/seq_relationship/output_bias with shape [2]\n",
            "INFO:transformers.modeling_bert:Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n",
            "INFO:transformers.modeling_bert:Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Save PyTorch model to ../bert_work/pytorch_model.bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'../bert_work/config.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGQSs3C29ki",
        "colab_type": "code",
        "outputId": "ce13eab6-ed2b-42d0-eff3-8e7313416881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "00906dd2976e4f538f97482f1f0d5ac2",
            "b9499f7958e24c0a9c70cedf8a9b1ccf",
            "3814e75a793d4921911e0513f54d7bf5",
            "68630a12c40c4f94bdb4a889e28be0ad",
            "696035d79cda42ae8faa138eb5497cad",
            "1c5845891ed64a47889db8de15eb416a",
            "25055603531c4f21b5368a269ca58786",
            "5e939c5b593343dfa744e664be9c6abb"
          ]
        }
      },
      "source": [
        "# OKT로 Tokenize 한 데이터를 string으로 붙인 뒤 이를 다시 bert 형태로 tokenizing\n",
        "\n",
        "%%time\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=do_lower_case)\n",
        "# ['니', '##는', '[UNK]', '황', '##후', '##는', '이', '##짓', '##하면', '##안', '##돼', '##냐', '진', '##실을', '말', '##한', '##것', '뿐', '##인', '##데']\n",
        "# ['정', '##말', '잘', '##하', '##셨', '##사', '##옵', '##니다', '태', '##태', '##마', '##마', '시', '##원', '##하게', '묵', '##은', '체', '##증', '##을', '날', '##리는', '듯', '하', '##셨', '##어', '##요', '민', '##유', '##라', '##한', '##테', '연속', '따', '##귀', '##를', '세', '##게', '갈', '##기는', '것', '##도', '모', '##자', '##라', '이', '##혁', '##한', '##테', '##도', '[UNK]', '까', '##지', '냈', '##으', '##니', '[UNK]', '진', '##짜', '끝', '##판', '##대', '##장이', '##시', '##다']\n",
        "# ['진', '##짜', '이름을', '되', '찾', '##을', '수', '있', '##었', '##어', '##요']\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(os.path.join(PATH_WORK, 'vocab.txt'), cache_dir=None, do_lower_case=do_lower_case, do_basic_tokenize=False)\n",
        "# ['니', '##는', '[UNK]', '황', '##후', '##는', '이', '##짓', '##하면', '##안', '##돼', '##냐', '진', '##실을', '말', '##한', '##것', '뿐', '##인', '##데']\n",
        "# ['정', '##말', '잘', '##하', '##셨', '##사', '##옵', '##니다', '태', '##태', '##마', '##마', '시', '##원', '##하게', '묵', '##은', '체', '##증', '##을', '날', '##리는', '듯', '하', '##셨', '##어', '##요', '민', '##유', '##라', '##한', '##테', '연속', '따', '##귀', '##를', '세', '##게', '갈', '##기는', '것', '##도', '모', '##자', '##라', '이', '##혁', '##한', '##테', '##도', '[UNK]', '까', '##지', '냈', '##으', '##니', '[UNK]', '진', '##짜', '끝', '##판', '##대', '##장이', '##시', '##다']\n",
        "# ['진', '##짜', '이름을', '되', '찾', '##을', '수', '있', '##었', '##어', '##요']\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(FILE_VOCAB, cache_dir=None, do_lower_case=do_lower_case)\n",
        "\n",
        "# train_df의 \"comment_text\"에서 na를 \"DUMMY_VALUE\"로 채우고, 최대 MAX_SEQUENCE_LENGTH 만큼 잘라냄\n",
        "sequences = convert_bert_token(df_sample_final[\"contents\"].fillna(\"DUMMY_VALUE\"),MAX_SEQ_LEN, tokenizer)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.tokenization_utils:Model name '../gdrive/My Drive/data/bert/bert-base-multilingual-cased/bert-base-multilingual-cased-vocab.txt' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming '../gdrive/My Drive/data/bert/bert-base-multilingual-cased/bert-base-multilingual-cased-vocab.txt' is a path or url to a directory containing tokenizer files.\n",
            "INFO:transformers.tokenization_utils:Didn't find file ../gdrive/My Drive/data/bert/bert-base-multilingual-cased/added_tokens.json. We won't load it.\n",
            "INFO:transformers.tokenization_utils:Didn't find file ../gdrive/My Drive/data/bert/bert-base-multilingual-cased/special_tokens_map.json. We won't load it.\n",
            "INFO:transformers.tokenization_utils:Didn't find file ../gdrive/My Drive/data/bert/bert-base-multilingual-cased/tokenizer_config.json. We won't load it.\n",
            "INFO:transformers.tokenization_utils:loading file ../gdrive/My Drive/data/bert/bert-base-multilingual-cased/bert-base-multilingual-cased-vocab.txt\n",
            "INFO:transformers.tokenization_utils:loading file None\n",
            "INFO:transformers.tokenization_utils:loading file None\n",
            "INFO:transformers.tokenization_utils:loading file None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00906dd2976e4f538f97482f1f0d5ac2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=40801), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 9.99 s, sys: 48 ms, total: 10 s\n",
            "Wall time: 10.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uaF3knUfY_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = sequences\n",
        "Y = df_sample_final['target'].to_numpy()\n",
        "\n",
        "# Train & Test Set 분리\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
        "# train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.15, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DZFwNyQ1Q0I",
        "colab_type": "code",
        "outputId": "0990d7d5-7892-4e66-b764-7d0522b0458a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Dataset을 상속한 TensorDataset은 train data x와 레이블 y를 묶어놓은 컨테이너로 tensor만 전달 가능함\n",
        "# X는 torch.long 형태의 텐서로, y는 torch.float 타입의 텐서로 입력하여 pytorch에서 연산할 수 있는 기본 구조로 변경하여 train_dataset으로 할당\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_x,dtype=torch.long), torch.tensor(train_y,dtype=torch.long))\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_x,dtype=torch.long), torch.tensor(test_y,dtype=torch.long))\n",
        "# train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_x), torch.tensor(train_y))\n",
        "# test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_x), torch.tensor(test_y))\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32640, 128)\n",
            "(32640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2--Gr8kLFyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "\n",
        "# Train 함수\n",
        "def bert_train_net(net, train_loader, optimizer, device=\"cuda\"):\n",
        "  tq = tqdm_notebook(range(training_epochs))\n",
        "\n",
        "  for epoch in tq:\n",
        "    tr_loss = 0.\n",
        "    nb_tr_examples, nb_tr_steps = 0,0\n",
        "\n",
        "    # 신경망을 훈련 모드로 설정\n",
        "    net.train()\n",
        "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
        "    \n",
        "    # iteration 1회에 train_loader의 batch_size (여기서는 64)만큼씩 읽어와 한꺼번에 batch처리 batch_size * i (여기서는 i = ) 가 전체 train data set의 크기가 될때까지 loop\n",
        "    for i,(x, y) in tk0:\n",
        "      x=x.to(device) # len(x)는 batch_size\n",
        "      y=y.to(device)\n",
        "\n",
        "      # y_pred = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=None)  # forward\n",
        "      # loss = F.binary_cross_entropy_with_logits(y_pred.view_as(y),y)\n",
        "      # loss = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=y) \n",
        "      # print(loss)\n",
        "      optimizer.zero_grad() # step과 zero_grad는 쌍을 이루는 것이라고 생각하면 됨 # optimizer의 gradient를 0으로 초기화\n",
        "      loss, logit = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=y)  # forward\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "      # print(\"loss ... \", loss, type(loss))\n",
        "      loss.backward() # backpropagation\n",
        "      optimizer.step() # update gradients\n",
        "\n",
        "      # update tracking variables\n",
        "      tr_loss += loss.item()\n",
        "      nb_tr_examples += x.size(0)\n",
        "      nb_tr_steps += 1\n",
        "      # running_loss += loss.item() # loss calculate\n",
        "\n",
        "      train_losses.append(tr_loss/nb_tr_steps)\n",
        "\n",
        "    print(\"epoch: {}/{} | train_loss: {:.4f} \".format(epoch, training_epochs, tr_loss/nb_tr_steps))\n",
        "    \n",
        "    torch.save(net.state_dict(), OUTPUT_MODEL_PATH + 'media_bert_model_'+epoch+'.bin')\n",
        "    \n",
        "    # train_losses.append(running_loss/len(train_loader))\n",
        "    # torch.save(model.state_dict(), output_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMkB5nm7GoA9",
        "colab_type": "code",
        "outputId": "09953d71-8903-40b5-971d-93146a98d062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# BertForSequenceClassification is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. \n",
        "# As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
        "\n",
        "bert_config = BertConfig.from_json_file(bert_model_config)\n",
        "bert_config.num_labels = NUM_LABELS\n",
        "\n",
        "# load pre-trained BERT model's weight in ../\n",
        "model = BertForSequenceClassification.from_pretrained(PATH_WORK, config=bert_config)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "### In Transformers, optimizer and schedules are splitted and instantiated like this:\n",
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:loading weights file ../bert_work/pytorch_model.bin\n",
            "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twe-4xUHvIwk",
        "colab_type": "code",
        "outputId": "f5e76ead-02cd-4bae-d6f5-8e865bdf5d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2f076629e8cf47a2bbdfab4c982307c3",
            "109326caa756480baa08a23fc02e78b7",
            "1c018e47ab994303b38a5c27b0b2c27d",
            "8f06a8d73ee949708bf5d8cdd8fe4c7f",
            "489c98abaaa74ee2956ff22b5d898a5e",
            "026a577d79504bf68520f6b211925a02",
            "99a783c65d4e4d889665686ad0ba7031",
            "f454e4a6aec941debd9ef47cc331a7d9",
            "d397dde0793c45b7b4ddb4fa3d35a7fd",
            "c113c5be9f014cd28b7db724f2ebc048",
            "65e62fe9b15746e6be0ae0f3b17f7b3b",
            "ae5d582acb5e401fbca6bedf9423f3d0",
            "4212e8e64df943bbb9a15cc8ee2c84dd",
            "af49113768b140868905bb6b7d7d0b30",
            "9675e226dbcd40488db79f14fb051561",
            "7b1213054f164637bc4a0479423f325e"
          ]
        }
      },
      "source": [
        "model.to(device) # GPU 연산을 위해 cuda로 전송\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "bert_train_net(model, train_loader, optimizer, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f076629e8cf47a2bbdfab4c982307c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d397dde0793c45b7b4ddb4fa3d35a7fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=1020), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr6ddOojQOy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKU6jC1k9fLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "labels = []\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(y_preds, real_ys):\n",
        "    pred_flat = np.argmax(y_preds, axis=1).flatten()\n",
        "    labels_flat = real_ys.flatten()\n",
        "    print(\"pred_flat is \", pred_flat)\n",
        "    print(\"labels_flat is \", labels_flat)\n",
        "    preds.append(pred_flat)\n",
        "    labels.append(labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzJUqt5G9HEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 평가 헬퍼 함수\n",
        "def bert_eval_net(net, data_loader, device=\"cuda\"):\n",
        "  # Dropout 및 BatchNorm 무효화\n",
        "  net.eval()\n",
        "\n",
        "  eval_acc = 0\n",
        "  nb_eval_examples, nb_eval_steps = 0,0\n",
        "\n",
        "  for x, y in data_loader:\n",
        "    x=x.to(device)\n",
        "    y=y.to(device)\n",
        "    with torch.no_grad():\n",
        "      y_preds = net(x, token_type_ids=None, attention_mask=(x>0).to(device), labels=None)  # forward\n",
        "\n",
        "    #Move logits and labels to CPU\n",
        "    y_preds = y_preds[0].detach().cpu().numpy()\n",
        "    real_ys = y.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(y_preds, real_ys)\n",
        "    print(\"tmp_eval_accuracy : \", tmp_eval_accuracy)\n",
        "\n",
        "    eval_acc += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_acc/nb_eval_steps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmmhDse9IMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model.load_state_dict(torch.load(OUTPUT_MODEL_PATH + 'media_bert_model_'+training_epochs+'.bin'))\n",
        "model.to(device)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "bert_eval_net(model, test_loader, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Biqhy-l-StT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def result_summary(pred_y, real_y):\n",
        "  print(\"Accuracy: {:.4f}\".format(accuracy_score(real_y, pred_y)))\n",
        "  print(\"Confusion Matrix: \\n\", confusion_matrix(real_y, pred_y))\n",
        "  print(\"Classification Report Matrix: \\n\", classification_report(real_y, pred_y, digits=3))\n",
        "\n",
        "  roc_auc = roc_auc_score(real_y, pred_y)\n",
        "  print(\"roc_auc score is : {:.4f}\".format(roc_auc))\n",
        "\n",
        "  fpr, tpr, threshold = roc_curve(real_y, pred_y)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  auc_graph(roc_auc, fpr, tpr)\n",
        "\n",
        "def auc_graph(roc_auc, fpr, tpr):\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyFWv6Z3-Ui8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "preds_flat = list(itertools.chain(*preds))\n",
        "labels_flat = list(itertools.chain(*labels))\n",
        "\n",
        "result_summary(preds_flat, labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QMVH-Ei_Yl0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}